[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "数据分析",
    "section": "",
    "text": "主页 || 课程 || 视频 || 推文 || 资料",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>数据分析</span>"
    ]
  },
  {
    "objectID": "body/_home.html",
    "href": "body/_home.html",
    "title": "2  关于我们",
    "section": "",
    "text": "2.1 连享会小课堂：在线视频课程\n连享会 由中山大学连玉君老师团队创办，定期分享各类实证分析经验，主要栏目如下：",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>关于我们</span>"
    ]
  },
  {
    "objectID": "body/_home.html#连享会小课堂在线视频课程",
    "href": "body/_home.html#连享会小课堂在线视频课程",
    "title": "2  关于我们",
    "section": "",
    "text": "\\({\\color{red}{NEW}}\\) 连享会在线课堂：lianxh-class.cn\n\n\n连玉君，Stata 33 讲，观看量超过 100 万人次的 Stata 入门课\n连玉君，直击面板数据模型，2 小时，公开课\nStata 软件及计量基础, 五次课，Stata 入门必备\n因果推断：控制变量如何选？，2 小时, 9.9 元\n因果推断：反事实架构及主流计量方法, 2 小时, 9.9 元\n我的特斯拉-实证研究设计，2.4 小时\n连玉君，我的甲壳虫-论文精讲与重现，两次课，共 6 小时\n连玉君，动态面板数据模型，2.2 小时，理论+实操 ……",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>关于我们</span>"
    ]
  },
  {
    "objectID": "body/_home.html#资源分享",
    "href": "body/_home.html#资源分享",
    "title": "2  关于我们",
    "section": "2.2 资源分享",
    "text": "2.2 资源分享\n\n详情：主页 - 资料分享\n\n\n2.2.1 Data\n\nCSMAR-国泰安 | Wind-万德 | Resset-锐思\n常用数据库 | 人文社科数据库\n\n\n\n2.2.2 论文复现\n\n论文重现网站大全\n\n\nDiscover Mendeley Data\nICPSR Data\nHarvard Dataverse\nFind Economic Articles with Data\n\n包含 9000 多篇经济金融论文，可检索软件类型、期刊名称等。\n\nReplication in the social sciences\n\n\n\n2.2.3 推文\n\nStata 教程 | 资料 | 新命令 | 结果输出 | 绘图 | 数据处理 | 程序\n回归分析 | 面板数据 | 交乘项-调节 | IV-GMM | Logit | 空间计量\n因果推断 | DID | RDD | PSM | 合成控制 | 文本分析\nMarkdown | 工具软件 | 机器学习 | 其它\nPDF 合集",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>关于我们</span>"
    ]
  },
  {
    "objectID": "body/_home.html#联系我们",
    "href": "body/_home.html#联系我们",
    "title": "2  关于我们",
    "section": "2.3 联系我们",
    "text": "2.3 联系我们\n\nE-mail： StataChina@163.com\n微信公众号： lianxh_cn (连享会)\n\n\n2.3.1 数字连享会\n截至 2024.12.18，连享会 共发布推文 1351 篇，累积阅读量 13,043,554 次。篇均阅读次数为 9654。连享会 知乎账号 回答了 1360 个经济、管理领域的问题，发布推文 1036 篇，累积阅读量为 58,564,198 次。\n\n\n2.3.2 欢迎赐稿\n\n推文风格：参见 分类推文。\n录用 2 篇 以上，即可 免费 获得一期 Stata 现场培训资格\n投稿信箱: StataChina@163.com / arlionn@163.com 。\n邮件标题：推文投稿-姓名：推文标题。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>关于我们</span>"
    ]
  },
  {
    "objectID": "body/00_intro.html",
    "href": "body/00_intro.html",
    "title": "3  前言",
    "section": "",
    "text": "3.1 Python 语言简介\nPython 由 Guido van Rossum 于 1991 年创建，至今已有三十多年历史。起初只是作为一种脚本语言，用于自动化简单任务。由于其语法简洁、易于扩展，并能与 C/C++ 等语言良好集成，Python 很快成为著名的「胶水语言」（glue language），广泛应用于数据分析、Web 开发、机器学习等领域。\n近年来，随着数据科学和人工智能的发展，Python 凭借其丰富的生态系统和社区支持，已成为最受欢迎的编程语言之一。根据 Stack Overflow Developer Survey 和 TIOBE 指数，Python 多年位居榜首。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "body/00_intro.html#python-语言简介",
    "href": "body/00_intro.html#python-语言简介",
    "title": "3  前言",
    "section": "",
    "text": "3.1.1 Python 的主要特点\n\n解释型语言：不需要预编译，Python 解释器（interpreter）逐行执行代码。\n动态类型：变量类型在运行时确定，无需显式声明。\n多范式支持：\n\n面向对象编程（OOP）：支持类和对象。\n过程式编程（Procedural）：支持传统函数调用结构。\n函数式编程（Functional）：支持部分函数式特性（如 map、lambda、生成器等）。\n\n跨平台：Python 程序在不同操作系统中运行一致。\nGIL（Global Interpreter Lock）：标准 CPython 实现中采用全局解释器锁，限制了多线程的并行性，适合 IO 密集型任务，不适合重度 CPU 密集型并行任务。\n\n\n\n3.1.2 使用场景与优势\nPython 的语法简洁、学习曲线平缓，特别适合以下场景：\n\n数据分析与探索性编程（如：Jupyter Notebook）\n自动化脚本与任务调度\n爬虫、文本处理、API 调用等 IO 密集型任务\n快速原型开发与教学演示\n与 C/C++/Java 等语言的接口开发，作为胶水语言集成系统\n\n虽然 Python 的执行效率不如 C/C++，但开发效率高、社区包丰富，能大幅减少开发时间。在多数实际应用中，程序员时间往往比机器运行时间更宝贵。若需要兼顾性能，可使用 Python 编写框架，重计算部分可用 C/C++ 或 Julia 编写，并通过 Python 调用。\n\n\n3.1.3 Python 之禅（The Zen of Python）\nPython 的设计哲学追求：\n\nBeautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. ——《The Zen of Python》\n\n可以在交互式终端中输入 import this 亲自体验。\n这些哲学使得 Python 鼓励「一种最好且明确的方法来完成一件事情」，避免花哨、歧义性强的语法，从而提高代码的可读性和可维护性。\n如需进一步了解 Python，推荐阅读：\n\n官方文档：https://docs.python.org/3/\n中文教程：廖雪峰的 Python 教程\n快速参考手册：Python Cheatsheet",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "body/00_intro.html#参考资料",
    "href": "body/00_intro.html#参考资料",
    "title": "3  前言",
    "section": "3.2 参考资料",
    "text": "3.2 参考资料\n\n3.2.1 Python 语言\n\nJohansson, R., 2024, Numerical Python: Scientific Computing and Data Science Applications with Numpy, SciPy and Matplotlib. Apress Berkeley, CA. Link, PDF (需要用校园 ID 登录), github\n\nPython 入门，绘图，科学计算，偏微分方程，统计和机器学习初步\nCHAPTER 4 Plotting and Visualization, 介绍绘图的基本元素.\n\n\n\n\n3.2.2 数据分析\n\nWes McKinney, 2023. Python for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter (3E). Online-Read, github, gitee-码云\n\n专注于数据处理，讲的比较细致\n\n🍎 PDSH   VanderPlas, 2023. Python Data Science Handbook, github, Online-Read, PDF-2E\n\n数据分析 + 可视化 + 机器学习\n提供了 Colab版本，可以无需安装 Python，直接在线运行\n本地已经下载：VanderPlas_2023_PDSH_Python_Data_Science_Handbook-2E.pdf\n\n\n\n\n3.2.3 金融\n\nScheuch, C., Voigt, S., Weiss, P., & Frey, C. (2024). Tidy Finance with Python (1st ed.). Chapman and Hall/CRC, Online-Read, github\n\ntidyfinance package\n股票回报, CAPM, 投资组合, Fama-French 因子模型等\n整体上比较简单，依赖于作者开发的 tidyfinance 扩展包。\n\nHilpisch Y., Python for Finance. 2019. -PDF-, github\n\n\n\n3.2.4 因果推断和机器学习\n\nAlves, Matheus Facure. 2022, Causal Inference for The Brave and True. Online Read, -github-\n\n基本上覆盖了目前文献中使用多的多数因果推断方法，包括 IV, DID, SDID, PSM, Matching, Panel, SCM, RDD\n提供了完整的 Python 代码，可以 Fork -github- 仓库，然后在本地运行 .ipynb 文档 (Jupyter Notebook)\n书中使用了 causalml 和 dowhy 两个包，前者是作者开发的一个包，后者是微软开发的一个包\n\n🍎 ISLP   James, G., D. Witten, T. Hastie, R. Tibshirani. An introduction to statistical learning: with Applications in Python (ISLP)[M]. Springer, 2023, website, Resources, github, -PDF-\n\nISLP documentation：书中数据文件的详细说明\n各章 Python 实操部分\ngithub-Notebooks  |  Excercises and Solultions\n\nTatsat, H., Puri, S., & Lookabaugh, B. (2020). Machine Learning and Data Science Blueprints for Finance. O’Reilly Media. -PDF-, github-2022, githu-new-2024\n\n分成监督学习和非监督学习两大部分，包含了常用的机器学习方法\n13 cases，涉及债券市场，股票市场分析等\n书里边的所有案例对应的 Python 代码可以不用本地安装，而在作者提供的 在线平台 上直接运行。\n用的 Jupyter Notebook",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "body/00_intro.html#数据",
    "href": "body/00_intro.html#数据",
    "title": "3  前言",
    "section": "3.3 数据",
    "text": "3.3 数据\n\n3.3.1 数据科学平台和搜索引擎\n\nKDNuggets - datasets\n\n数据科学和机器学习领域的知名网站，提供了大量的资源和信息。\n\nKaggle Datasets\n\n全球知名的数据科学与机器学习社区，用户可以在平台上获取数据集、参与竞赛、分享与学习代码、交流讨论。\n\nUCI Machine Learning Repository\n\n机器学习领域最经典的数据集仓库，涵盖分类、回归、聚类等多种任务，适合教学和算法测试。\n\nGoogle Dataset Search\n\n谷歌推出的专用数据集搜索引擎，聚合全球各类开放数据集，支持多语言检索，便于快速定位所需数据。\n\nAWS Public Datasets\n\n亚马逊云平台提供的开放数据集，涵盖气象、基因组、卫星影像等大规模数据，适合云端分析和机器学习。\n\nMicrosoft Azure Open Datasets\n\n微软云平台提供的开放数据集，聚焦天气、健康、金融等领域，便于在 Azure 上直接调用和分析。\n\nOpen Data Portal by European Union\n\n欧盟官方开放数据门户，收录成员国及欧盟机构的各类统计、经济、社会等数据，支持多语种访问。\n\nWorld Bank Open Data\n\n世界银行开放数据平台，提供全球各国经济、社会、发展等宏观数据，适合国际比较和经济研究。\n\nData.gov\n\n美国政府开放数据平台，涵盖农业、气候、教育、能源等众多领域，数据权威且更新及时。\n\nawesome-public-datasets\n\nGitHub 开放数据集列表\n\n\n\n\n3.3.2 学校图书馆\n\n中大图书馆-统计类数据库\n\n\nCSMAR (国泰安数据库-公司金融-股票-债券):\n\n🍎 https://data.csmar.com/\n\nEPS数据平台\nWind资讯金融终端\n中经网产业数据\n\n国内宏观层面的数据基本上都能够找到。Excel → Python/Stata\n例：宏观数据\n\n中经网统计数据库\nEMIS—Emerging Markets Information Service（新兴市场动态及商务信息数据库）\n\n新闻，股指，最新统计数据等\nChina - Financial markest\n\n\nRESSET系列数据库\n\nRESSET系列数据库 | RESSET企业大数据平台\n\n需要输入账号和密码\n1、中山大学校园网IP范围内，直接点击访问。\n2、官方网站访问： http://www.resset.cn，点击页面“快速登录”右边的“企业大数据平台”链接后输入对应的用户名及密码进行登录。用户名：sysu和密码：sysu1903。\n3、校外不限IP访问，通过CARSI平台访问登陆，访问地址：http://db.resset.com/，点击页面的：CARIS 平台登陆，选择学校，然后输入验证身份信息后登陆使用。\n\n\n\n\n3.3.3 公开数据\n\n全球数据\n\n连小白, 2025, GMD：最新全球宏观数据库-243个国家46个宏观变量, 连享会 No.1559.\n\nGMD 主页\n\n\n各国、各级政府的统计局：\n\n美国人口调查局\n中国国家统计局\n中国证监会\n中国人民银行\n\n国际国内各类组织机构\n\n世界银行\n美国疾病预防控制中心\n国际货币基金组织\n美国联邦储备银行",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>前言</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_intro.html",
    "href": "body/00_py_with_AI_intro.html",
    "title": "4  借助 AI 写代码",
    "section": "",
    "text": "4.1 AI 工具",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>借助 AI 写代码</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_intro.html#ai-工具",
    "href": "body/00_py_with_AI_intro.html#ai-工具",
    "title": "4  借助 AI 写代码",
    "section": "",
    "text": "通用工具\n\nChatGPT - 由 OpenAI 开发的聊天机器人，基于 GPT-3.5 架构。可以用于编写代码、回答问题、生成文本等。\nChatGPT Plus - 付费版本的 ChatGPT，提供更快的响应时间和更高的可用性。\nDeepSeek - 国内访问顺畅，整体表现不错，但结果的稳定性欠佳。\n豆包 - 更适合文字编排、翻译等。\nkimi - 与豆包相当。\n\n编程工具 (这些都是 VScode 中的插件)\n\nGitHub Copilot: VScode 插件，可以在编写代码时提供实时建议和补全。首月免费，后续 $10/月。\nTabnine: 代码补全工具，支持多种编程语言。\nclint: 代码补全工具，支持多种编程语言。\nCodeium: 代码补全工具，支持多种编程语言。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>借助 AI 写代码</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_intro.html#理念",
    "href": "body/00_py_with_AI_intro.html#理念",
    "title": "4  借助 AI 写代码",
    "section": "4.2 理念",
    "text": "4.2 理念\n\n自然语言编程 vs. 传统编程\n\n\n「自然语言编程」与 Python、C++ 等传统编程本质上都是向计算机发出指令，要求其执行特定操作\n区别在于：\n\n传统编程语言（如 Python、C++）有严格的语法和结构\n自然语言编程则用人类语言（如中文、英文）描述操作\n\n\n\n思维方式与沟通能力\n\n\n初学时，自然语言编程似乎更简单\n真正发挥其潜力，关键在于思维方式和沟通方式（如何提问）\n学习曲线很陡峭：\n\n知识广度：你要知道很多东西以及他们的关联，才能提出好的问题\n知识深度：基本概念、核心理论、核心算法\n逻辑思维：界定问题、拆解问题、追问（横向 v.s. 纵向）\n语言表达：简洁、准确、清晰\n\n\n\n最核心的理念转变\n\n\n提示词 = 自然语言的”代码”\n写好提示词，就像写好 Python/C++ 代码一样重要\n许多高校已开设「提示词工程」课程，「Prompt 工程师」将成为热门职业\n\n\n推荐学习资料\n\n\nPrompt Engineering Guide\n吴恩达老师的 ChatGPT Prompt Engineering for Developers",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>借助 AI 写代码</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_intro.html#提示词",
    "href": "body/00_py_with_AI_intro.html#提示词",
    "title": "4  借助 AI 写代码",
    "section": "4.3 提示词",
    "text": "4.3 提示词\n\nTips\n\n\n先粗后细 e.g. 生成讲义 v.s 先细后粗\n顺藤摸瓜-迁移 e.g. 各种抽样方法\n虚构角色 e.g. 你是一个资深的英文经济学期刊的编辑 → 推文\n\n\n收集整理自己的提示词\n\n\nChatGPT Prompting Cheat Sheet\nThe Complete ChatGPT Cheat Sheet 2025!\nPrompt工作手册 - 方法篇",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>借助 AI 写代码</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_intro.html#我的使用经验",
    "href": "body/00_py_with_AI_intro.html#我的使用经验",
    "title": "4  借助 AI 写代码",
    "section": "4.4 我的使用经验",
    "text": "4.4 我的使用经验\n\n我常用的提示词\n\n\nhttps://github.com/arlionn/UseChatGPT\nhttps://gitee.com/arlionn/UseChatGPT (码云版)\n\n\n借助 AI 找 IV：连玉君的实战经验\n\n\n帮我找 20 个 IV\n寻找 IV 的提示词如何写？\n\n\n4.4.1 实例：使用 AI 写一篇完整的论文推介\n\nDu-2024-EE-中文精要生成过程\n\n核心提示词： 参见 连玉君的 Prompts\n\n\n\n\n\n\n提示词\n\n\n\nPrompt 1:\n{先上传论文的 PDF 版本给 ChatGPT，然后输入以下提示词：}\n“写一篇论文推介，介绍附件中的论文。先列个提纲给我。”\nPrompt 2:\n分批次输出吧：\n\n计量模型的证明和详细推导过程可以省略，但要补充简单直白的语言来解释模型和参数的经济含义\n把数学符号和公式都采用 Latex 格式来写，以保证输出美观\n行内公式采用 $f=x$ 格式，单行公式采用 $$f=x$$ 格式\n所有括号都用半角模式，中英文混排注意加空格\n不要添加任何表情符号\n按 ‘## 1. xxx’，‘### 1.1 xxx’，‘#### xxx’(不编号) 的格式来分 Section, Subsection, Subsubsection\n参考文献格式：\n\nxxx, xxx, xxx. (2023). xxx. Journal of xxx, 1(1), 1-10. [Link](https://doi.org/{DOI}), [-PDF-](http://sci-hub.ren/{DOI}), [Google](&lt;https://scholar.google.com/scholar?q={Title of the Paper}&gt;).\n\n注意：每次生成答案时，都在首行按如下格式添加 label，以便我追问时定位：‘mylabel-01’，‘mylabel-02’，……\n\nPrompt 3:\n连续输出，中间无需停顿\nPrompt 4:\n详细介绍一下 4.4 模型四：部分线性函数系数面板模型（PLFC）中的模型设定和估计方法\nPrompt 5:\n补充一个 Subsection，添加如下内容： - 为没有任何非参数估计基础的读者解释一下样条基函数（Sieve Estimation） - 再补充一个 subsection，解释一下边际效应的置信区间是如何计算的",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>借助 AI 写代码</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_pic.html",
    "href": "body/00_py_with_AI_pic.html",
    "title": "5  Ansome Python + AI",
    "section": "",
    "text": "5.1 画一幅图\n有了 AI 的协助，我们可以在只掌握少量编程知识的情况下，用 Python 实现各种复杂的功能。本章例举一些实例，旨在改变大家对「编程」的认知。\n最终你会发现，Python 只是我们完成某些分析和研究任务的工具而已。AI 的作用是让我们使用「自然语言」来编程。此时的编程主要包括如下几个要点：\n我在 R for Data Science 书中看到了一幅不错的图形，想要绘制出来。这幅图不算复杂：\n于是，我把图片发给了 AI 工具，配上提示词：\n我把相同的问题同时发给了 ChatGPT，DeepSeek 和 豆包。最终，豆包给出的图形效果最好：\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.table import Table\nfrom matplotlib.patches import FancyArrowPatch\n\n# 原始数据\ndata1 = {\n    'id': ['A', 'B'],\n    'x_1': [1, 5],\n    'x_2': [2, 6],\n    'y_1': [3, 7],\n    'y_2': [4, 8]\n}\ndf1 = pd.DataFrame(data1)\n\n# 转换后数据\ndata2 = {\n    'id': ['A', 'A', 'B', 'B'],\n    'x': [1, 2, 5, 6],\n    'y': [3, 4, 7, 8],\n    'num': [1, 2, 1, 2]\n}\ndf2 = pd.DataFrame(data2)\n\n# 定义颜色映射\ncolor_mapping = {\n    'x_1': 'lightblue',\n    'x_2': 'plum',\n    'y_1': 'lightgreen',\n    'y_2': 'lightgreen',\n    'x': 'lightblue',\n    'y': 'lightgreen',\n    'num': ['orange', 'violet']\n}\n\n# 创建图形和子图\nfig, ax = plt.subplots(figsize=(10, 4))\nax.axis('off')\n\n# 绘制原始表格\n# 绘制原始表格\ntable1 = ax.table(\n    cellText=df1.values,\n    colLabels=df1.columns,\n    cellLoc='center',\n    loc='left',\n    bbox=[0, 0.3, 0.4, 0.6]\n)\nfor (row, col), cell in table1.get_celld().items():\n    if row == 0:\n        cell.set_text_props(weight='bold')\n    if row &gt; 0:\n        colname = df1.columns[col]\n        cell.set_facecolor(color_mapping.get(colname, 'white'))\n    else:\n        colname = df1.columns[col]\n        cell.set_facecolor(color_mapping.get(colname, 'white'))\n\n# 绘制箭头\n#ax.arrow(0.45, 0.6, 0.1, 0, head_width=0.03, head_length=0.05, fc='k', ec='k')\n\n# 绘制转换后表格\ntable2 = ax.table(\n    cellText=df2.values,\n    colLabels=df2.columns,\n    cellLoc='center',\n    loc='right',\n    bbox=[0.55, 0.3, 0.4, 0.6]\n)\nfor (row, col), cell in table2.get_celld().items():\n    if row == 0:\n        cell.set_text_props(weight='bold')\n    if row &gt; 0:\n        colname = df2.columns[col]\n        if colname == 'num':\n            cell.set_facecolor(color_mapping['num'][(row-1) % 2])\n        else:\n            cell.set_facecolor(color_mapping.get(colname, 'white'))\n    else:\n        colname = df2.columns[col]\n        if colname == 'num':\n            cell.set_facecolor(color_mapping['num'][0])\n        else:\n            cell.set_facecolor(color_mapping.get(colname, 'white'))\n            # 添加 FancyArrowPatch 箭头以美化转换效果\n\n            fancy_arrow = FancyArrowPatch(\n                (0.48, 0.6), (0.52, 0.6),\n                transform=fig.transFigure,\n                connectionstyle=\"arc3,rad=0\",\n                arrowstyle='-|&gt;',\n                linewidth=2,\n                color='black'\n            )\n            fig.patches.append(fancy_arrow)\nplt.show()",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ansome Python + AI</span>"
    ]
  },
  {
    "objectID": "body/00_py_with_AI_pic.html#画一幅图",
    "href": "body/00_py_with_AI_pic.html#画一幅图",
    "title": "5  Ansome Python + AI",
    "section": "",
    "text": "写一段 Python 代码，制作类似的图形\n请注意左右两侧图形的颜色块要一一对应，这是这幅图的关键。 只保留中文注释，图中的文字用英文。 不要显示 warning information",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ansome Python + AI</span>"
    ]
  },
  {
    "objectID": "body/01_1_install-Python-Anocanda.html",
    "href": "body/01_1_install-Python-Anocanda.html",
    "title": "6  Python：安装和环境配置",
    "section": "",
    "text": "6.1 安装 Anaconda\n对于初学者来讲，建议安装 Anaconda 套装。它是一个开源的 Python 发行版，集成了 Python 解释器、包管理器 Conda 和许多常用的科学计算和数据分析库（如 NumPy、Pandas、Matplotlib 等）。\n虽然 Anaconda 自带的编辑器 Jupyter Notebook 很好用，但如果你平时经常用 VScode 写东西，建议安装 VScode 作为编辑器。VScode 支持多种编程语言，可以安装各种插件来增强功能。对于编写 Python 代码而言，仅需安装 python 和 jupyter 插件就可以满足基本需求。\n网上有不少关于 Anaconda 和 VScode 的安装和配置的教程，如：\n根据我的使用经验，基本步骤总结如下：\n下面，我详细说明每个步骤的操作。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python：安装和环境配置</span>"
    ]
  },
  {
    "objectID": "body/01_1_install-Python-Anocanda.html#安装-anaconda",
    "href": "body/01_1_install-Python-Anocanda.html#安装-anaconda",
    "title": "6  Python：安装和环境配置",
    "section": "",
    "text": "Note\n\n\n\n对于多数用户，只需看 Step 1-2 即可。\n\n\n\n下载 Anaconda（建议注册一个账号，若不注册，可以点击 Skip）。\n安装 Anaconda。安装 Anaconda 最重要的事情：\n\nSelect Installation Type 页面，建议选择 Just Me，然后点击 Next。\nChoose Install Location 页面，建议使用默认路径 C:\\Users\\用户名\\Anaconda3 作为 Anaconda 的安装路径，这样可以避免一些潜在的权限和路径问题。然而， 如果你的用户名中包含中文字符或空格，建议选择「自定义路径」，并选择一个英文路径，如 C:\\myProgram\\Anaconda3。\nAdvanced Installation Options 页面，确保同时勾选如下两个选项：\n\n[√] Add Anaconda to my PATH environment variable\n[√] Register Anaconda as my default Python 3.x\n\n\n详情参见：VSCode与Anaconda安装配置\n\n安装完成后，打开 Anaconda Navigator（在开始菜单或应用程序中找到它）。\n在 Anaconda Navigator 中，你可以创建和管理虚拟环境、安装包、启动 Jupyter Notebook 等。\n安装完成后，打开 Anaconda Prompt（命令行界面），输入以下命令检查安装是否成功：\nconda --version\n如果显示版本号，则表示安装成功。\n在 Anaconda Prompt 中输入以下命令更新 Conda 到最新版本：\nconda update conda\n创建一个新的虚拟环境（可选）：如果你想在一个独立的环境中工作，比如，你要同时使用 Python 3.8 和 Python 3.12，以便完成不同的项目，你可以创建一个新的虚拟环境。输入以下命令创建一个名为 myenv38 的虚拟环境，并安装 Python 3.8：\nconda create --name myenv38 python=3.8\n同理，如果你想使用 Python 3.12，你可以创建一个名为 myenv312 的虚拟环境，并安装 Python 3.12：\nconda create --name myenv312 python=3.12\n接下来，你可以激活特定的虚拟环境，比如 myenv38，输入以下命令：\nconda activate myenv38\n此时，若执行 canda list 命令，你会看到当前环境中安装的所有包和版本信息；而执行 canda install Stargazer, v = 2.1.1，则会在当前环境中安装 Stargazer 包的 2.1.1 版本。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python：安装和环境配置</span>"
    ]
  },
  {
    "objectID": "body/01_1_install-Python-Anocanda.html#安装-vscode",
    "href": "body/01_1_install-Python-Anocanda.html#安装-vscode",
    "title": "6  Python：安装和环境配置",
    "section": "6.2 安装 VScode",
    "text": "6.2 安装 VScode\n\n下载 VScode（选择适合你操作系统的版本）。\n安装 VScode（双击下载的安装包，按照提示完成安装）。\n安装完成后，打开 VScode。\n在 VScode 中，你可以 安装各种插件 来增强功能，比如 Python、Jupyter 等。\n\n\n6.2.1 建议安装的 VScode 插件\n\n如果你不了解 VScode，可以先读一下 VScode编辑器。\n有关插件的安装和使用，参见：VScode插件：安装、配置和使用\n安装插件很容易：点击图中的 四个小方块 图标，在搜索框中填入插件名称，点击 Install 即可。\n\n\n\n6.2.1.1 Python 插件\n\nVScode：实用 Python 插件清单\n\n\nPython：必装，运行 Python 代码\nJupyter：必装，运行 Jupyter Notebook 文件\nPylance：代码补全和智能提示等功能\nData Wrangler：表格呈现\n编程助手 (选一个即可，否则可能会有冲突)\n\nGitHub Copilot (首月免费，后续每月 $10.0，使用 Visa 或 Master 信用卡付款)\nCodeium (Copilot 的替代品，Free，目前已经更名为 Windsurf Plugin)\nCline / Cline Chinese (Copilot 的替代品，Free)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n安装编程助手前，请确保能顺畅上网。\n建议预先申请一个 GitHub 账号，使用 Copilot 时，可以用 GitHub 账号进行关联和登录。\n我个人使用 Copilot，觉得效果还不错。Codeium 据说不错，甚至在 VScode 中的安装量比 Copilot 还要多。Cline 是最近新出的，大家也可以测试一下。\n\n\n\n\n\n6.2.1.2 Markdown 插件\n\nVScode：实用 Markdown 插件推荐\n\n\nMarkdown All in One\nMarkdown Preview Enhanced\nMarp (制作幻灯片)",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python：安装和环境配置</span>"
    ]
  },
  {
    "objectID": "body/01_1_install-Python-Anocanda.html#jupyter-notebook",
    "href": "body/01_1_install-Python-Anocanda.html#jupyter-notebook",
    "title": "6  Python：安装和环境配置",
    "section": "6.3 Jupyter Notebook",
    "text": "6.3 Jupyter Notebook\n\n6.3.1 简介\n\n\n\n\n\n\nNote\n\n\n\n\n这里介绍的 Jupyter Notebook 是指在 VScode 中使用的 Jupyter Notebook，而不是 Anaconda 自带的 Jupyter Notebook。VScode 中的 Jupyter Notebook 更加灵活和强大，支持多种编程语言和插件。\n在 VScode 中安装了 Jupyter 插件后，就已经完成了 Jupyter Notebook 的安装和配置。\n\n\n\n顾名思义，Jupyter Notebook 就是一个文本编辑器。如果你使用过 Stata，那么它类似于 Stata 的 Do 文件；如果你使用过 RStudio，那么它类似于 RStudio 的 R Markdown 文件。Jupyter Notebook 的一个重要特点就是它是一个交互式的计算环境，允许你在一个文档中编写和运行代码、可视化数据、撰写文本和公式等。\n简言之，你可以把你的分析目的 (文本块)，分析过程 (代码块)，分析结果 (表格或图形) 都整合到一个文档中，形成一个完整的分析报告。\n\n\n\n6.3.2 安装\n在 VSCode 中使用 Jupyter Notebook，你需要安装以下软件：\n\nPython：Jupyter Notebook 是基于 Python 的，因此你需要安装 Python。你可以从 Python 官网 下载并安装最新版本的 Python。\nVSCode：你需要安装 Visual Studio Code。你可以从 VSCode 官网 下载并安装最新版本的 VSCode。\nJupyter 扩展：在 VSCode 中使用 Jupyter Notebook，你需要安装 Jupyter 扩展。你可以在 VSCode 的扩展市场中搜索 “Jupyter” 并安装它。\nPython 扩展：你还需要安装 Python 扩展。你可以在 VSCode 的扩展市场中搜索 “Python” 并安装它。\n\n\n\n6.3.3 新建项目文件结构\n\n本地新建一个文件夹，如 D:/FinData/Proj_Maotai\n(推荐) 在该文件夹下新建如下几个子文件夹，用于分类存放文件\n\n[./data]：存放 .csv、.xlsx 等数据文件\n[./doc]：存放说明文档、报告等文件\n[./codes]：存放代码文件，包括自编函数、模块等\n[./output]：存放输出文件，包括图表、结果等\n此外，建议在该文件夹下新建一个 README.md 文件，对项目进行说明 (如项目背景、目标、数据来源、程序的执行顺序和方法等)。\n\n\n\n\n20250516012952\n\n\n\n\n6.3.3.1 新建 Jupyter Notebook 文件 (.ipynb)\n\n打开 VScode，依次点击 文件 -&gt; 打开文件夹，选择 D:/FinData/Proj_Maotai 文件夹。\n右击该文件夹，选择 New File (亦可直接点击下图中的 New File 图标)，新建一个文件，名称为 data_clean.ipynb。注意：一定要以 .ipynb 结尾，否则无法用 Jupyter Notebook 打开，也无法添加 Python 代码块。\n\n你也可以使用命令行方式新建一个 .ipynb 文件：按快捷键 Ctrl+Shift+P &gt;&gt; 输入或选择 Create: New Jupyter Notebook 会打开一个名为 Untitled-1.ipynb 的文件，输入内容后另存到目标文件夹即可。\n\n\n完成上述设定后，VScode 的文件目录结构如下：\n# 目录结构\nD:/FinData/Proj_Maotai\n├── codes\n├── data\n├── doc\n├── output\n├── README.md\n└── data_clean.ipynb\n\n\n6.3.3.2 借助 AI 工具自动创建项目文档 (备选)\n\nChatGPT 对话过程\n\n如果觉得手动创建文件夹麻烦，可以借助 ChatGPT 等 AI 工具，自动创建项目文档。下面是我编写的一个示例提示词 (你只需要指定目标文件夹路径即可，即使这个文件夹不存在也没有关系)：\n\n请帮我在 Windows 系统上为一个数据分析项目生成标准的项目结构。 项目的根目录是 D:/FinData/Proj_Maotai，请在该路径下创建以下结构：\nD:/FinData/Proj_Maotai\n├── codes             # 用于存放脚本代码\n├── data              # 原始数据或处理后的数据\n├── doc               # 项目文档与说明资料\n├── output            # 图表、模型结果、分析报告等输出文件\n├── README.md         # 项目说明文件，简要介绍项目目的与结构\n├── 01_data_clean.ipynb       # 数据清洗与预处理\n├── 02_EDA.ipynb              # 探索性数据分析\n└── 03_regression.ipynb       # 回归分析与建模\n请提供 Python 代码，以便我在写 Jupyter Notebook 中运行。 请确保必要的 .ipynb 文件和 README.md 都被自动生成。如果文件已存在，请保留原文件不覆盖。 你可以默认这些 .ipynb 文件为空白，也可以加一两行注释。\n\n经过测试，ChatGPT 和 豆包生成的代码都可以一次性顺利执行：\n\nChatGPT 对话过程\n豆包对话过程\n\n\n\n6.3.3.3 采用插件创建项目模板\n除了上述方法，你也可以在 VScode 中搜索 Project Templates，安装对应的插件来创建项目模板。安装完成后，点击左侧的 Project Templates 图标，选择 Create New Project，然后选择你需要的模板即可。\n\n该插件提供了多种项目模板，包括数据分析、机器学习、Web 开发等，可以酌情选择。\n该插件也支持自定义模板，具体操作请参考插件的说明文档。\n\n不过，如果项目不是很复杂，建议还是手动创建项目文件夹，这样更灵活，也更容易管理。\n\n\n\n6.3.4 使用 Jupyter Notebook\nStep 1：选择解释器。初次打开 data_clean.ipynb 文件时，可能需要按下图方式设定 Python 解释器，以便随后用 python.exe 来运行新增的代码块。\n\nStep 2：添加 Markdown 文本块。点击上图中的 + Markdown 按钮，添加一个 Markdown 文本块。可以用 Markdown 语法撰写文档说明。\n\n预览：点击图中的 √ 或按快捷键 Esc；\n编辑：在预览 双击鼠标 区可重新计入编辑模式。\n\n\nStep 3a： 让 AI 自动生成代码(可选)：如果你已经在 VScode 中安装了插件 Github Copilot，可以点击图中的 Generate 按钮，输入提示词 (比如，生成随机数 x~N(0,1)，N=100，绘制直方图+密度函数图, 英文标题)，敲回车，或点击下图中的右箭头，Copilot 会自动生成代码。如果代码块右下角显示的不是 python，可以单击之，选择 python，将次代码块标记为 Python 语言。\n\n\nStep 3b： 自行添加代码块。点击上图中的 + Code 按钮，添加一个代码块。可以在代码块中输入 Python 代码。\n\n运行代码块：点击上图中的 ▶ 按钮，或按快捷键 Ctrl + Enter；\n\n\nStep 4： 修改和调试代码。你可以酌情修改代码。\n\n若出现大量警告信息或程序无法运行，可以选中全部代码或被标注了红色波浪线代码，点击下图中的黄色星星按钮，选择 Fix using copilot，多数情况下都能自动修复。\n若相对可以正常运行的代码做一些优化，则可以选中代码后，点击黄色星星，选择 Modify using copilot，然后输入提示词。\n\n\n\n\n20250516021357\n\n\n\n6.3.4.1 界面和主要功能\n在上文中，为了突出重点，我没有让 VScode 编辑器全屏。事实上，全屏后，你会发现 Jupyter Notebook 提供了一组功能强大的工具栏和菜单栏，帮助你更好地编写和运行代码。下面是 Jupyter Notebook 的主要界面元素：\n\n多数菜单的功能都是比较直观的，下面我简单介绍几个常用的功能：\n\nView data：查看数据和概要信息。注意：需要安装 Data Wrangler 插件才具有此功能。\n...：最右侧的三个点，点击后可以选择 Export，将当前 Notebook 导出为 PDF、HTML、Markdown 等格式；还有预览 (Preview) 等功能 (快捷键 Esc)。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python：安装和环境配置</span>"
    ]
  },
  {
    "objectID": "body/01_1_install-Python-Anocanda.html#导出和文档转换",
    "href": "body/01_1_install-Python-Anocanda.html#导出和文档转换",
    "title": "6  Python：安装和环境配置",
    "section": "6.4 导出和文档转换",
    "text": "6.4 导出和文档转换\n在 VScode 中，你可以将 Jupyter Notebook 导出为多种格式，包括 HTML、PDF 和 Markdown。你可以在菜单栏中选择 文件 -&gt; 导出为，然后选择你想要的格式。当然，还需要安装一些额外的工具来支持这些导出功能，主要包括 Pandoc 和 TeX Live。\n\n6.4.1 安装 Pandoc（用于文档格式转换）\nJupyter 和 Quarto 在导出 Markdown、Word、PDF 时都会调用 Pandoc。\n\n推荐安装方式（适用于 Anaconda 用户）：\nconda install -c conda-forge pandoc\n或者前往官网下载安装包（Windows/macOS/Linux 均支持）： https://pandoc.org/install\n安装完成后，你可以在终端中输入以下命令测试是否成功：\npandoc --version\n\n\n\n6.4.2 安装 TeX Live（用于导出 PDF）\nJupyter 和 Quarto 的 PDF 导出依赖 LaTeX 引擎，如 pdflatex 或 xelatex。推荐安装完整版本的 TeX Live。\n\nWindows 用户请访问官网下载器： https://tug.org/texlive/windows.html\n安装过程中可选择 “完整版” 或 “Typical full installation”；\n安装完成后，务必重启 VS Code 和终端；\n然后在终端中测试：\npdflatex --version\n\n\n\n6.4.3 如何打开终端？\n很多初学者不清楚“在终端中输入命令”具体指什么。你可以按以下方式打开终端：\n\n方式一（推荐）： 在 VS Code 中按下快捷键 Ctrl + ~（就是数字 1 左侧的波浪线），即可打开内置终端。\n方式二： 从系统菜单中打开：\n\nWindows：点击开始 → 输入 cmd 或 Anaconda Prompt 或 PowerShell；\nmacOS：打开 Launchpad → 搜索「终端（Terminal）」；\nLinux：按下 Ctrl + Alt + T 打开终端窗口。\n\n\n终端窗口中，你可以输入如 conda install、pandoc --version 等命令，按下回车运行。\n\n\n6.4.4 安装完成后即可使用以下方式导出 PDF\n\n在 VS Code 中点击右上角「导出（Export）」按钮；\n或在终端中运行：\njupyter nbconvert your_notebook.ipynb --to pdf\n或使用 Quarto（如果你已安装）：\nquarto render your_notebook.ipynb --to pdf\n\n完成上述安装和设定后，即可顺利将 Notebook 文档导出为 PDF、HTML、Word 等多种格式，满足教学、写作和发布的常见需求。\n\n\n6.4.5 高阶用法：使用 Quarto 导出漂亮 PDF 或制作电子书网站\n如果你希望导出的文档更美观、格式更统一，或者希望将多个 Jupyter Notebook 或 Markdown 文档整合成一个电子书（book）或教学网站（website），可以考虑使用 Quarto。\nQuarto 是 RStudio 团队开发的下一代科学与技术出版平台，同时支持 .ipynb、.qmd、.md 文件的混合编写和发布。常见功能包括：\n\n一键导出 排版美观的 PDF 文档（支持标题、目录、脚注、交叉引用、引用文献等）；\n创建结构化的电子书（Quarto Book），适合撰写讲义、教程和学术教材；\n部署交互式教学网站（Quarto Website），可发布为静态网页托管在 GitHub Pages 上。\n\n\n6.4.5.1 示例命令：\n将 .ipynb 或 .qmd 导出为 PDF：\nquarto render your_notebook.ipynb --to pdf\n将多个文档组织为电子书结构（在 _quarto.yml 中设置章节）：\nquarto render\n\n\n6.4.5.2 安装方式：\n\n可从官网下载安装：https://quarto.org/download\n安装完成后，在终端中测试：\nquarto --version\n\nQuarto 完全兼容你现有的 VS Code 工作流，安装 Quarto 插件后即可直接在 VS Code 中预览、渲染和发布。对于希望构建专业文档的用户，Quarto 是目前最值得推荐的方案。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python：安装和环境配置</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html",
    "href": "body/01_2_install_FAQs.html",
    "title": "7  Python 安装常见问题",
    "section": "",
    "text": "7.1 安装了 Anaconda 还需要安装 Python 3.13 吗？\n答：不需要！ 而且，强烈反对。Anaconda 是一个完整的 Python 科学计算发行版，安装时会自动集成 Python 解释器和常用扩展包 (如 NumPy、Pandas 等)，并通过 Conda 环境管理器提供灵活的版本控制。\n若额外安装官网 Python，可能引发以下问题：\n建议通过 Conda 统一管理 Python 环境，既能自由切换不同版本（如 conda create -n py312 python=3.12），又能确保依赖隔离和生态兼容性，避免因混合安装导致的技术债。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#安装了-anaconda-还需要安装-python-3.13-吗",
    "href": "body/01_2_install_FAQs.html#安装了-anaconda-还需要安装-python-3.13-吗",
    "title": "7  Python 安装常见问题",
    "section": "",
    "text": "版本混乱：系统环境变量可能优先指向非 Anaconda 的 Python，导致命令行调用错误的解释器版本；\n\n依赖冲突：Conda 和 pip 混合管理包时，依赖项版本容易冲突（例如 TensorFlow 或 PyTorch 的兼容性问题）；\n\n环境隔离失效：全局安装的 Python 可能干扰 Conda 创建的独立环境，破坏项目隔离性；\n\n维护困难：需手动协调多个 Python 实例的更新与兼容性，增加运维复杂度。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#安装-anaconda-时需要注意什么",
    "href": "body/01_2_install_FAQs.html#安装-anaconda-时需要注意什么",
    "title": "7  Python 安装常见问题",
    "section": "7.2 安装 Anaconda 时需要注意什么？",
    "text": "7.2 安装 Anaconda 时需要注意什么？\n\nChoose Install Location 页面，建议使用默认路径 C:\\Users\\用户名\\Anaconda3 作为 Anaconda 的安装路径，这样可以避免一些潜在的权限和路径问题。注意： 如果你的用户名中包含中文字符或空格，建议选择「自定义路径」，并选择一个英文路径，例如 C:\\PromgramFile\\Anaconda3。\nAdvanced Installation Options 页面，确保同时勾选如下两个选项：\n\n[√] Add Anaconda to my PATH environment variable\n[√] Register Anaconda as my default Python 3.x\n\n\n详情参见：VSCode与Anaconda安装配置",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#默认解释器的路径",
    "href": "body/01_2_install_FAQs.html#默认解释器的路径",
    "title": "7  Python 安装常见问题",
    "section": "7.3 默认解释器的路径",
    "text": "7.3 默认解释器的路径\n问题描述：每次在 VScode 的 Jupyter 中运行代码时，都会弹出一个窗口询问选择解释器的路径。\n\n原因 1：VScode 设置问题：VScode 在运行 Jupyter Notebook 时需要指定 Python 解释器的路径，如果没有设置默认解释器，就会弹出这个窗口。 environment variable`，导致 VScode 无法找到 Python 解释器的路径。\n\n解决方法：在 VScode 中，按下 Ctrl + Shift + P，输入Python: Select Interpreter\\，选择你想要的 Python 解释器路径即可。\n\n原因 2：Anaconda 安装时的配置有问题。\n在安装 Anaconda 时，在 Advanced Installation Options 页面，你可能没有勾选 Add Anaconda to my PATH environment variable，导致 VScode 无法找到 Python 解释器的路径。\n\n解决方案：将 Anaconda 的安装路径添加到系统的环境变量中。具体步骤如下：\n\n在 Windows 中，右键点击 “此电脑”，选择 “属性”。\n依次点击 高级系统设置 &gt;&gt; 环境变量\n在 “系统变量” 中找到 Path，点击 “编辑”。\n点击 “新建”，添加 Anaconda 的安装路径，例如 C:\\Users\\用户名\\Anaconda3 和 C:\\Users\\用户名\\Anaconda3\\Scripts。\n点击“确定”，保存设置。\n\n\n\n\n20250513211532",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#pip-install-在哪里执行",
    "href": "body/01_2_install_FAQs.html#pip-install-在哪里执行",
    "title": "7  Python 安装常见问题",
    "section": "7.4 pip install 在哪里执行？",
    "text": "7.4 pip install 在哪里执行？\n答：pip install pkg_name 通常在命令行界面中执行。不同操作系统打开命令行界面的方式略有不同：\n\nWindows 系统：按下 Win + R 键，输入 cmd，然后按下 Enter 键。\nMac 系统：按下 Command + Space 键，输入 Terminal，然后按下 Enter 键。\nVSCode 中：按下 Ctrl + Shift + P，输入 Terminal: Create New Terminal，然后按下 Enter 键。\n更快捷的方式 (VScode 中)：\n\nWindows：按下 Ctrl + ~ 键 (~ 在 Esc 键下方)。\nMac：按下 Command + Shift + ~ 键。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#什么是-vscode-的-terminal",
    "href": "body/01_2_install_FAQs.html#什么是-vscode-的-terminal",
    "title": "7  Python 安装常见问题",
    "section": "7.5 什么是 VScode 的 terminal？",
    "text": "7.5 什么是 VScode 的 terminal？\n答：VScode 的 terminal 是一个集成的命令行界面，允许用户在 VScode 编辑器中直接执行命令行操作。它支持多种 Shell，如 PowerShell、Bash 和 Command Prompt 等。用户可以在 terminal 中运行 Python 脚本、安装包、管理版本控制等操作，而无需切换到外部命令行窗口。\n\n\n\n20250513225516\n\n\n开启方法：\n\n在 VScode 中，按下 Ctrl + Shift + P，输入 Terminal: Create New Terminal，然后按下 Enter 键。\n更快捷的方式：\n\nWindows：按下 Ctrl + ~ 键（~ 在 Esc 键下方）。\nMac：按下 Command + Shift + ~ 键。\n\n\n用途：\n\n执行命令行操作，如安装 Python 包（pip install pkg_name）、运行脚本等。\n运行 Git 命令进行版本控制：\n\ngit clone：克隆远程仓库到本地。\ngit add：将更改添加到暂存区。\ngit commit：提交更改到本地仓库。\ngit push：将本地提交推送到远程仓库。\n\n管理虚拟环境和依赖项。\n调试和测试代码。\n查看系统信息和环境变量等。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#conda-install-与-pip-install-有何差别",
    "href": "body/01_2_install_FAQs.html#conda-install-与-pip-install-有何差别",
    "title": "7  Python 安装常见问题",
    "section": "7.6 Conda install 与 pip install 有何差别？",
    "text": "7.6 Conda install 与 pip install 有何差别？\n相似点：都是 Python 的包管理工具；都能安装 Python 库和包，并自动处理依赖关系。\n主要区别：\n\n包来源不同：\n\nConda：主要从 Anaconda 官方仓库（例如 Anaconda Cloud）安装包，并且可以安装 Python 之外的其他工具和库（例如 R 语言的库）。它支持更广泛的语言和工具。\npip：从 Python 官方包索引（PyPI）安装 Python 包，通常只用于 Python 相关的包。\n\n虚拟环境管理：\n\nConda：不仅可以管理 Python 包，还可以管理虚拟环境。在 Conda 环境中，你可以控制整个环境的配置，包括 Python 版本和依赖的库。\npip：仅管理 Python 包，不负责环境的管理。虽然 virtualenv 或 venv 可以配合 pip 使用来管理虚拟环境，但这需要额外的配置。\n\n依赖解决：\n\nConda：在安装包时，Conda 会自动解决依赖冲突，确保所有包和环境的兼容性。\npip：通常会安装指定的包，但不总是自动解决复杂的依赖关系。如果发生依赖冲突，pip 可能不会提醒用户。\n\n适用场景：\n\nConda：适用于需要管理多个工具和语言环境（如 Python、R）的情况，尤其在数据科学、机器学习等领域中，Conda 更加常用。\npip：适用于单纯的 Python 项目，尤其是当你不需要其他语言支持时，pip 更简便。\n\n\n\n总结\n\nAnaconda 是一个包含 Conda 的大套件，提供了用于数据分析和科学计算的工具。\nConda 是 Anaconda 的包和环境管理工具，可以管理 Python 以及其他语言的包。\npip 是 Python 的官方包管理工具，通常用于管理 Python 包，适用于纯 Python 项目。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_2_install_FAQs.html#conda-和-anaconda-有何关系",
    "href": "body/01_2_install_FAQs.html#conda-和-anaconda-有何关系",
    "title": "7  Python 安装常见问题",
    "section": "7.7 Conda 和 Anaconda 有何关系？",
    "text": "7.7 Conda 和 Anaconda 有何关系？\nAnaconda 是一个开源的 Python 发行版，旨在简化 Python 和 R 编程语言中数据科学、机器学习和科学计算的使用。Anaconda 提供了包括 Python 和 R 语言在内的各种开源库以及管理和部署环境所需的工具。\nConda 是 Anaconda 的一个组件，它是一个包管理器和环境管理器。Conda 负责安装、更新、卸载包和管理虚拟环境。实际上，Conda 不仅仅可以用来管理 Python 包，还可以管理其他语言（例如 R 和 Ruby）的包。\n总结：Anaconda 是一个包含 Conda 的完整发行版，Conda 是其中的包管理工具。\n\nConda 的用途\n\n包管理：Conda 用于安装、升级和卸载 Python 包以及其他语言的包。它能够管理并解决依赖问题，确保你安装的包兼容且稳定。\n环境管理：Conda 允许创建和管理虚拟环境。通过虚拟环境，你可以在同一台机器上管理多个不同版本的 Python 和包，而不会发生冲突。例如，你可以为一个项目使用 Python 3.7，为另一个项目使用 Python 3.9，并且确保每个项目有独立的依赖。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Python 安装常见问题</span>"
    ]
  },
  {
    "objectID": "body/01_3_markdown.html",
    "href": "body/01_3_markdown.html",
    "title": "8  Markdown",
    "section": "",
    "text": "8.1 何谓 Markdown？\nMarkdown 是一种轻量级的标记语言，允许你使用易读易写的纯文本格式编写文档，然后转换成结构化的 HTML, PDF, Word 等多种格式的文档。Markdown 语法简单易学，适合用来撰写笔记、文档、幻灯片等。\n大家在网上看到的很多博客文章，程序说明文档，甚至是在线书籍 (Python for Data Analysis, 3E)，都是用 Markdown 写的。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "body/01_3_markdown.html#语法速览",
    "href": "body/01_3_markdown.html#语法速览",
    "title": "8  Markdown",
    "section": "8.2 语法速览",
    "text": "8.2 语法速览\n\n\n\n\n\n\nFigure 8.1: Markdown 语法对照\n\n\n\n你可以在如下网站按部就班地学习 Markdown 的基本用法，大概五分钟后你就可以掌握常用 Markdown 语法规则了：\n\nhttps://www.markdowntutorial.com/zh-cn",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "body/01_3_markdown.html#markdown-基本语法",
    "href": "body/01_3_markdown.html#markdown-基本语法",
    "title": "8  Markdown",
    "section": "8.3 Markdown 基本语法",
    "text": "8.3 Markdown 基本语法\n\nSource: markdownguide.org/cheat-sheet/\n\n这份 Markdown 备忘单介绍了常用的 Markdown 语法。为了便于您快速了解基本的语法规则，这里略去了很多细节信息，详情参见：基础语法 和 扩展语法。\n以下是 John Gruber 原始设计文档中列出的基本元素，所有 Markdown 应用程序都支持这些元素。\n\n\n\n\n\n\n\n元素\nMarkdown 语法\n\n\n\n\n标题\n# 一级标题## 二级标题### 三级标题\n\n\n粗体\n**粗体文本**\n\n\n斜体\n*斜体文本*\n\n\n引用块\n&gt; 引用内容\n\n\n有序列表\n1. 第一项2. 第二项3. 第三项\n\n\n无序列表\n- 第一项  -  第一条- 第二项- 第三项\n\n\n代码高亮显示\n`代码` (`xtreg` → xtreg)\n\n\n水平线\n---\n\n\n链接\n[连享会主页](https://www.lianxh.cn)\n\n\n图片\n![图片标题](/Fig/image.jpg) 或 ![](图片网址)\n\n\n\n\n8.3.1 表格\n| 命令    | 范例                 |\n| :------ | :------------------- |\n| xtreg   | `xtreg y x, fe`      |\n| reghdfe | `reghdfe y x, a(id)` |\n\n\n\n命令\n范例\n\n\n\n\nxtreg\nxtreg y x, fe\n\n\nreghdfe\nreghdfe y x, a(id)\n\n\n\n\n\n8.3.2 数学公式\n\n单行数学公式用 $$ 符号包围起来；\n行内数学公式用 $ 符号包围起来；\n包围符号内侧不要有空格，否则在有些 Markdown 编辑器中无法正常显示公式\n\n正确：$y = f(x)$\n错误：$ y = f(x) $ 或 $y = f(x) $\n\n有关 LaTeX 数学公式的语法和工具，参见：\n\nMarkdown常用LaTex数学公式\n神器-数学公式识别工具-mathpix\n\n\n模型设定为：\n\n$$y_{it} = \\alpha_i + x_{it}\\beta + u_{it}$$\n\n其中，$y_{it}$ 为被解释变量，$\\alpha_i$ 为个体效应。\n模型设定为：\n\\[y_{it} = \\alpha_i + x_{it}\\beta + u_{it}\\]\n其中，\\(y_{it}\\) 为被解释变量，\\(\\alpha_i\\) 为个体效应。\n\n\n8.3.3 代码块\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': [4, 5, 6]\n})\n```\n\n```stata\nsysuse \"auto.dta\", clear\nregress mpg weight\ndisplay \"Results: \" 2 + 3\n```\n渲染效果：\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': [4, 5, 6]\n})\nsysuse \"auto.dta\", clear\nregress mpg weight\ndisplay \"Results: \" 2 + 3\n\n\n8.3.4 扩展阅读\n\n初虹, 2024, 让「记录」变得简单：Markdown使用详解, 连享会 No.1456.\n初虹, 2021, 学术论文写作新武器：Markdown-上篇, 连享会 No.603.\n初虹, 2021, 学术论文写作新武器：Markdown-下篇, 连享会 No.604.\n初虹, 2021, 学术论文写作新武器：Markdown-中篇, 连享会 No.605.\n连玉君, 2024, VScode插件：安装、配置和使用, 连享会 No.1490.\n连玉君, 2024, VScode：实用 Markdown 插件推荐, 连享会 No.1390.",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "body/01_3_markdown.html#marp-幻灯片",
    "href": "body/01_3_markdown.html#marp-幻灯片",
    "title": "8  Markdown",
    "section": "8.4 marp 幻灯片",
    "text": "8.4 marp 幻灯片\n在 VScode 中安装 Marp 插件后，你可以使用 Markdown 语法来创建幻灯片。使用 Marp 最大的好处是你可以专注于内容，而不必担心幻灯片的格式和样式。Marp 会自动将你的 Markdown 文档转换为美观的幻灯片。\n\n\n8.4.1 模版 1：最基本的设定\n以下是一个简单的 Marp 幻灯片模板，你只需要新建一个 .md 文件，输入如下内容，然后在 VScode 中打开该文件即可：\n---\nmarp: true\n---\n\n# 幻灯片标题\n\n---\n\n## 第一页幻灯片\n\n- xxx\n- xxx\n\n---\n\n## 第二页幻灯片\n\n- xxx\n- xxx\n\n\n8.4.2 模版 2：更多的设定\n该模板的主要功能包括：\n\n幻灯片的标题、作者、页码、脚注\n幻灯片的字号\n标题的颜色和页面背景颜色\n\n---\nmarp: true\nsize: 16:9      # 宽版：4:3\npaginate: true  # 显示页码\nfooter: '脚注文本或 [xxx](URL)'\n---\n\n&lt;style&gt;\n/*一级标题局中*/\nsection.lead h1 {\n  text-align: center; /*其他参数：left, right*/\n}\nsection {\n  font-size: 22px;      /* 正文字号 */\n}\nh1 {\n  color: blackyellow;   /* 标题的颜色 */\n  /*font-size: 28px; */ /* 标题的字号, 其它标题也可以这样修改 */\n}\nh2 {\n  color: green;\n}\nh3 {\n  color: darkblue;\n}\n\n/* 右下角添加页码 */\nsection::after {\n  content: attr(data-marpit-pagination) '/' attr(data-marpit-pagination-total); \n}\nheader,\nfooter {\n  position: absolute;\n  left: 50px;\n  right: 50px;\n  height: 25px;\n}\n&lt;/style&gt;\n\n&lt;!--顶部文字--&gt;\n[lianxh.cn](https://www.lianxh.cn/news/46917f1076104.html) \n\n&lt;br&gt;\n\n&lt;!--封面图片--&gt;\n![bg right:50% w:400 brightness:. sepia:50%](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20220722114227.png) \n\n&lt;!--幻灯片标题--&gt;\n# Marp 参数设置\n\n&lt;br&gt;\n&lt;br&gt;\n\n&lt;!--作者信息--&gt;\n[连玉君](https://www.lianxh.cn) (中山大学)\narlionn@163.com\n\n&lt;br&gt;\n---\n&lt;!-- backgroundColor: #FFFFF9 --&gt;\n## 第一页幻灯片\n\n- 背景是淡黄色的，可以根据需要修改颜色\n\n---\n&lt;!-- backgroundColor:white --&gt;\n## 第二页幻灯片\n\n- 背景是纯白色\n- 下面的图片在右侧，占页面 60% 的宽度\n\n![bg right:60% w:800](图片网址)\n详情参见：\n\n宋森安, 2021, 用Markdown制作幻灯片-五分钟学会Marp（上篇）, 连享会 No.656.\n宋森安, 2021, 用Markdown制作幻灯片-五分钟学会Marp（下篇）, 连享会 No.657.\n连玉君, 2022, Marp幻灯片模板：用Markdown快速写幻灯片, 连享会 No.1059.",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html",
    "href": "body/01_py_01_basic.html",
    "title": "9  Python 入门",
    "section": "",
    "text": "9.1 数值类型和计算\n参考教程：\nPython 语言简单易懂，多数语句都非常符合人类语言的直觉。比如，计算两个数字相加：\n3+4\n\n7\n我们也可以把它赋值给一个变量，然后再调用 (比如，打印出来)：\na = 3 + 4\nprint(a)\n\n7\n此处的 print() 是一个函数，表示打印出括号内的内容。Python 中的多数运算和操作都是通过函数来实现的。这里，我们采用 print() 函数来打印一些常用的数学运算的结果：\nprint(2*5)     # 乘法\nprint(2**5)    # 乘方\nprint(2**0.5)  # 平方根\n\nprint(30/4)    # 除法\nprint(30//4)   # 整数除法, 两个斜杠\nprint(30%4)    # 取余\n\n10\n32\n1.4142135623730951\n7.5\n7\n2\n不同于 C 和 Java 等语言，Python 不需要预先声明变量的类型，它会根据赋值的内容自动推断变量的类型：\na = 2\nb = 'BMW'\n\nprint(a*10)   # 整数乘法\nprint(b*10)   # 字符串重复\n\n20\nBMWBMWBMWBMWBMWBMWBMWBMWBMWBMW",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#数值类型和计算",
    "href": "body/01_py_01_basic.html#数值类型和计算",
    "title": "9  Python 入门",
    "section": "",
    "text": "9.1.1 变量类型\nPython 支持整数和浮点数两种数值类型。整数是没有小数点的数字，比如 1、2、3 等；而浮点数是带有小数点的数字，比如 1.0、2.5、3.14 等。 我们可以使用 type() 函数来查看一个变量的类型：\ntype(10)   # int\ntype(10.0) # float\n很多时候我们也会用到字符型变量：\n\nprint(\"Hello, World!\")\nstr1 = 'Python'\nstr2 = \"is amazing\"\nstr3 = str1 + str2\n\nprint(str3)                   # 字符串拼接，不会添加空格\nprint(str1, str2, '=', str3)  # 字符串拼接, 自动添加空格\n\nHello, World!\nPythonis amazing\nPython is amazing = Pythonis amazing\n\n\n说明：字符串需要用单引号或双引号括起来，Python 会自动识别。比如，'hello' 和 \"hello\" 是等价的。如果你在字符串中需要使用单引号，可以用双引号括起来，反之亦然。比如，\"I'm a student\" 和 'I\\'m a student' 是等价的。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#逻辑运算与比较",
    "href": "body/01_py_01_basic.html#逻辑运算与比较",
    "title": "9  Python 入门",
    "section": "9.2 逻辑运算与比较",
    "text": "9.2 逻辑运算与比较\n在数据清洗阶段，经常需要根据特定的条件删除或筛选变量和观察值，这就需要使用 &gt;、&lt;、&gt;=、&lt;=、== 和 != 等比较运算符来进行逻辑判断。\n\n1 &gt; 2\n\nFalse\n\n\n\n2 &gt;= 2\n\nTrue\n\n\n注意以上程序的结果返回的是 True 和 False，这两个值在 Python 中分别代表 ‘逻辑真’ 和 ‘逻辑假’。逻辑真、假之间可以有与、或、非的运算：\n\nTrue and True\n\nTrue\n\n\n\n(5==5) and (3&gt;4)   # True and False\n\nFalse\n\n\n有兴趣的读者可以测试一下如下表达式的返回值：\n(5&lt;5) and (3&gt;4)            # False and False\n(5==5) or ('Cat'=='Dog')   # True or False\nnot ('Cat'!='Dog')         # not True\n注意： - Python 中的逻辑运算符是 and、or 和 not，而不是 &&、|| 和 !。这与 C 和 Java 等语言不同。 - 判断是否相等需要用双等号 ==，判断不相等要使用 !=，否则会报错：\n\nprint('真的！') if ('Cat' != 'cat') else print('假的!')\n\n真的！",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#运算优先级",
    "href": "body/01_py_01_basic.html#运算优先级",
    "title": "9  Python 入门",
    "section": "9.3 运算优先级",
    "text": "9.3 运算优先级\n以上我们介绍了几种常见的运算，包括：\n\n算数运算\n\n+\n-\n\\*\n/\n//\n%\n\\*\\*\n\n比较运算\n\n==\n!=\n&lt;\n&lt;=\n&gt;\n&gt;=\n\n逻辑运算\n\nand\nor\nnot\n\n\n这些运算符号并不是从左到右依次执行的，而是具有优先级顺序，比如：\n3 + 5*7 - 2\n运算时，会先进行乘法运算，再执行加减运算：\nPython 中运算符的优先级从高到低依次为：\n\n**\n\n+、-: 正负号\n\n*、/、%\n+、-：加减运算\n\n==、!=、&lt;、&gt;、&lt;=、&gt;=\n\nnot\n\nand\n\nor\n\n请问，按照以上规则，如下表达式的运算顺序是什么？会得到什么结果？\n1&gt;2 and 3&gt;2\n此外，需要注意幂运算的等级比正负号要高，所以如下两个表达式的结果是不同的：\n-2**2      # -4\n(-2)**2    #  4\n对于 -2**2，其计算顺序是：先计算 \\(2^2\\)，再取负，得到了 \\(-4\\)。因此，在编写代码时，如果不确定变量 x 的值是正数还是负数，且需要进行类似 x**2 这样的运算，更稳妥的写法上 (x)**2。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#变量",
    "href": "body/01_py_01_basic.html#变量",
    "title": "9  Python 入门",
    "section": "9.4 变量",
    "text": "9.4 变量\n变量（variable）是几乎所有编程语言都具有的特性。变量实质上是内存中的一个区域，其中存储着某一些值。在 Python 中，由于不用像 C、Java 一样显示地指明变量类型，因而用起来非常简单，直接使用等号 “=” 赋值即可。比如，我们可以使用以下语句将 3 这个值保存在变量 x 中，并在后面引用这个变量：\n\nx = 3\nprint(x)\n\n3\n\n\n变量命名需要一些规则\n\n变量名不能以数字开头\n\n变量名不能是 Python 的保留字符，比如 is、in 等\n\n不能含有 +、-、*、空格等特殊字符，但是下划线允许\n\n变量名区分大小写\n\n其他字符都可以使用。由于 Python3 支持 Unicode，因而也可以使用中文变量名 (不推荐)：\n\n收入 = 3000\nprint(收入)\n\n3000\n\n\n虽然 Python 的变量名要求相对比较宽松，但是还是有一些良好的习惯需要注意：\n\n尽量不要使用中文做变量名\n\n变量名要有意义，方便阅读\n\n尽量不要使用下划线开头，因为下划线开头的变量在 Python 中可能有特殊含义\n\n命名时，如果变量名包含几个单词，可以使用下划线区分，或者使用驼峰规则，每个单词第一个字母大写，比如：cat_weight，或者 CatWeight\n\n除了简单的使用等号赋值之外，Python 还有其他几个比较方便的赋值语句，比如：\n\n+=：a += b 等价于 a = a + b\n\n-=：a -= b 等价于 a = a - b\n\n*=：a *= b 等价于 a = a * b\n\n/=：a /= b 等价于 a = a / b\n\n**=：a **= b 等价于 a = a ** b\n\n//=：a //= b 等价于 a = a // b\n\n%=：a %= b 等价于 a = a % b\n\n\na = 2\na += 1\nprint(a)\n\na -= 1\nprint(a)\n\na *= 2\nprint(a)\n\na /= 2\nprint(a)\n\na **= 2\nprint(a)\n\n3\n2\n4\n2.0\n4.0",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#字符串",
    "href": "body/01_py_01_basic.html#字符串",
    "title": "9  Python 入门",
    "section": "9.5 字符串",
    "text": "9.5 字符串\n除了数值类型，字符串也是一种常用的数据类型。在 Python 中，即可以用单引号 ''，也可以用双引号 \"\" 来标记字符串，二者等价：\n\na = \"Hello,\"\nb = 'Python!'\nprint(a, b)\n\nHello, Python!\n\n\n采用两种标记符，有助于处理一些特殊情形，比如\n\na = \"Tom's viewpoint: \"\nb = '\"Python\" is amazing!'\nprint(a)\nprint(b)\nprint(a + b)\n\nTom's viewpoint: \n\"Python\" is amazing!\nTom's viewpoint: \"Python\" is amazing!\n\n\n也就是说，字符串内包含 ' 时，我们可以用双引号括起来，反之亦然。当然，有时候字符串内会同时包含单引号和双引号，此时我们可以使用转义字符 \\ 来解决这个问题，比如：\n\nc = \"Tom's idea: \\\"Python\\\" is amazing, let's learn it.\"\nprint(c)\n\nTom's idea: \"Python\" is amazing, let's learn it.\n\n\n此处，我们用 \\\" 来表示字符串中的双引号，以避免与外围的双引号冲突。类似地，我们也可以用 \\' 来表示字符串中的单引号。\n除了单引号之外，还有一些其他的字符需要转义，比如，斜杠 \\ 本身就需要转义，因为如果不对 \\ 转义，解释器无法知晓这个斜杠是一个纯粹的斜杠，还是与后面的字符链接起来的转义字符，比如：\n\na = \"工作路径为 D:\\mydata\\python\"\nb = \"工作路径为 D:\\\\mydata\\\\python\"\nprint(a)\nprint(b)\n\n工作路径为 D:\\mydata\\python\n工作路径为 D:\\mydata\\python\n\n\n&lt;&gt;:1: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:1: SyntaxWarning: invalid escape sequence '\\m'\nC:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_38900\\3500448571.py:1: SyntaxWarning: invalid escape sequence '\\m'\n  a = \"工作路径为 D:\\mydata\\python\"\n\n\n除此之外，Python3 中还有其他转义字符：\n\n每一行结尾处的 \\：续行符\n\n\\\\：反斜杠\n\n\\'：单引号\n\n\\\"：双引号\n\n\\b：退格\n\n\\v：纵向制表符\n\n\\t：横向制表符\n\n\\r：回车\n\n\\n：换行\n\n\\f：换页\n\n……\n\n举几个例子：\n\nprint(\"Name:\\tTom\\t谭萱\\nAge:\\t30\\t25\\nSex:\\t男\\t女\")\n\nName:   Tom 谭萱\nAge:    30  25\nSex:    男   女\n\n\n在 Python 中，\\n 表示 换行符，而 \\r 表示 回车符。它们的作用略有不同，具体如下：\n\n\\n 会将光标移到下一行的开头，相当于“换行并定位至该行行首”；\n\\r 只会将光标移到当前行的行首，但不会换行，因此它会从当前行的开头开始重新输出字符，可能会覆盖原来的内容。\n\n来看一个例子：\n\nprint(\"Downloading...\\n搞定了\")  # 使用 \\n（换行符）\nprint('-'*30)\nprint(\"Downloading...\\r搞定了\")  # 使用 \\r（回车符） \n\nDownloading...\n搞定了\n------------------------------\n搞定了nloading...\n\n\n第二个输出结果有点奇怪，是因为 \\r 把光标拉回了行首 (没有换行)，然后开始打印 搞定了。这会覆盖原有字符 Downloading... 中开头 3 个字符 (Dow)，最终变成了 搞定了nloading...。\n这种 \\r 的行为在一些进度条或动态打印时非常常见。下面的代码中，由于每次打印都用 \\r 把光标拉回了行首，覆盖原内容，所以你看到的其实只有一行在不断刷新。\n\nimport time\n\n# 模拟一个简单的进度条\nfor i in range(0, 101, 10):\n    print(f\"下载进度：{i}%\".ljust(20), end=\"\\r\")\n    time.sleep(0.2)  # 暂停 0.2 秒，模拟下载过程\n\nprint(\"下载完成！            \")  # 打印最终状态\n\n下载完成！               \n\n\n除了使用单引号和双引号表示字符串之外，Python 还支持长字符串、原始字符串两种表示方法：长字符串使用三个单引号 ''' 或者三个双引号 \"\"\" 包裹，可以用来表示跨越多行的字符串。比如：\n\na = \"\"\"这是一个可以跨行的字符串\n使用三个单引号\n或者三个双引号包裹\n\"\"\"\n\nb = '''\nHello, my friend!\nI am learning Python.\n'''\nprint(a)\nprint(b)\n\n这是一个可以跨行的字符串\n使用三个单引号\n或者三个双引号包裹\n\n\nHello, my friend!\nI am learning Python.\n\n\n\n而原始字符串即不对反斜杠进行转义，比如一个路径可能为：\na = \"C:\\network\\table\"\n然而注意到，由于 \\n 有转义，所以 Python 解释器在碰到 \\n 时将其解释为回车。同理，\\t 则会被解释为 Tab：\n\na = \"C:\\network\"\nprint(a)\n\nC:\network\n\n\n如果需要声明该字符串为原始字符串，可以直接在字符串前面加一个“r”，即：\n\na=r\"C:\\network\"\nprint(a)\n\nC:\\network\n\n\n此时，Python解释器就不会将“\\n”进行转义了。\n此外，Python3中所有的字符串都是以Unicode进行编码的，因而极大地规避了在Python2以及其他语言中可能碰到的乱码问题，因而使用Python3是非常方便的。也正因为如此，我们可以很方便的使用Unicode字符，并使用“\\N{unicode_name}”来表示Unicode字符，比如：\n\na=\"This is a cat: \\N{cat}\"\nprint(a)\n\nThis is a cat: 🐈\n\n\nUnicode字符可以从 http://unicode-table.com 中找到。\n如果需要拼接两个字符串，可以简单的使用加号：\n\na=\"This is a cat: \"\nb=\"\\N{cat}\"\nc=a+b\nprint(c)\n\nThis is a cat: 🐈\n\n\n最后需要额外注意的是，作为字符串的 “3” 和作为整型数据的 3 是完全不一样的。因此，我们不能使用如下表达式：\n\"3\" + 2\n正确的做法是：先使用 int() 函数将字符串 “3” 转化为数值类型，再进行计算：\n\na = int(\"3\") + 2\nprint(a)\n\n5\n\n\n同理，如果希望将一个数值型数字处理为字符串，也需要使用 str() 函数先将数字转化为字符串：\n\na = 3\nb = \"There are \" + str(a) + \" cats.\"\nprint(b)\n\nThere are 3 cats.",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#列表和元组",
    "href": "body/01_py_01_basic.html#列表和元组",
    "title": "9  Python 入门",
    "section": "9.6 列表和元组",
    "text": "9.6 列表和元组\n以上我们初步介绍了Python的三种基本数据类型：整型、浮点型以及字符串。接下来我们引入Python中的两种最基本也是最常用的数据结构：列表（list）和元组（tuple）。\n列表和元组都是序列（sequence）的一种，可以看成是一些元素的集合，每个元素都有其位置编号，编号从0开始。列表使用方括号“[]”进行声明，而元组使用小括号“()”进行声明，或者不用括号直接声明。列表和元组所包含的内容可以是任何Python允许的数据类型、对象等等。\n\n9.6.1 元组\n最简单也是最基本的是元组。元组不可更改，一旦创建，只能读取而不能写入，比如：\n\nname_list = \"Messi\",10\nprint(name_list)\n\n('Messi', 10)\n\n\n以上就创建了一个元组，我们可以读取其某一个分量，但是不能对其进行更改。我们可以使用元组名后面加一个方括号读取相应编号位的元素：\n\nprint(name_list[0])\nprint(name_list[1])\n## 以下语句会报错：\n# name_list[1]=7\n\nMessi\n10\n\n\n由于编号从0开始，因而name_list[0]代表的是元组中的第一个元素，而name_list[1]代表第二个元素。方括号中也可以是负数，代表倒数第几个元素：\n\nprint(name_list[-1])\nprint(name_list[-2])\n\n10\nMessi\n\n\n此外，如果需要声明只有一个元素的元组，需要额外加一个逗号，否则解释器无法判断需要声明的是一个值还是一个元组：\n\nname='Messi',\nprint(name)\nname1='Messi'\nprint(name1)\n\n('Messi',)\nMessi\n\n\n当然，在声明元组时，一个良好的习惯是加上括号，使得程序更具有可读性。\n由于元组也是Python中的对象，因而元组的成员也可以是元组，并可以使用两个方括号对作为元组成员的元组中的元素进行读取操作：\n\nname_list=(('Messi',10),\n           ('Xavi',6),\n           ('Iniesta',8),\n           ('Puyol',5)\n          )\nprint(name_list[0][0])\nprint(name_list[1][0],\":\",name_list[1][1])\n\nMessi\nXavi : 6\n\n\n元组虽然不能修改，但是支持切片（slicing）操作：即从中取出一个子集。切片操作同样使用元组名称后面跟一个方括号，在方括号中使用冒号“:”代表起始位置和终点位置（注意是左闭右开区间）：\n\nprint(name_list[0:2])\nprint(name_list[-3:-1])\nprint(name_list[-3:])\nprint(name_list[2:])\n\n(('Messi', 10), ('Xavi', 6))\n(('Xavi', 6), ('Iniesta', 8))\n(('Xavi', 6), ('Iniesta', 8), ('Puyol', 5))\n(('Iniesta', 8), ('Puyol', 5))\n\n\n实际上，切片操作还可以支持步进，切片的通用语法为：\nx[start:end:step]\n其中start的默认值为0，step的默认值为1，而end的默认值为x的维数的大小。如果我们指向取出奇数位的元素，我们可以使用：\n\nprint(name_list[::2])\n\n(('Messi', 10), ('Iniesta', 8))\n\n\n以上切片操作被翻译为：从0开始，一直到结束，隔一个取一个元素。\n\n\n9.6.2 列表\n列表的很多操作跟元组类似，但是列表允许被修改，因而更加灵活，也有更多的操作。\n我们可以很方便的使用方括号定义一个列表：\n\nplayer_list=[('Messi',10),\n           ('Xavi',6),\n           ('Iniesta',8),\n           ('Puyol',5)\n          ]\nprint(player_list)\n\n[('Messi', 10), ('Xavi', 6), ('Iniesta', 8), ('Puyol', 5)]\n\n\n注意以上声明的过程中，与元组唯一的不同是我们在最外面使用了方括号而非圆括号。\n或者，我们可以使用 list() 将一个可迭代（iterable）的对象（包括字符串、元组、列表等）转化为一个列表，比如：\n\nprint(name_list)\nname_list_list=list(name_list)\nprint(name_list_list)\nmessi=list('Messi')\nprint(messi)\n\n(('Messi', 10), ('Xavi', 6), ('Iniesta', 8), ('Puyol', 5))\n[('Messi', 10), ('Xavi', 6), ('Iniesta', 8), ('Puyol', 5)]\n['M', 'e', 's', 's', 'i']\n\n\n与列表不同的是，我们可以对列表进行修改操作：\n\nprint(player_list)\nplayer_list[3]=('ter Stegen',1)\nprint(player_list)\n\n[('Messi', 10), ('Xavi', 6), ('Iniesta', 8), ('Puyol', 5)]\n[('Messi', 10), ('Xavi', 6), ('Iniesta', 8), ('ter Stegen', 1)]\n\n\n以及使用del语句进行删除操作：\n\ndel player_list[2]\nprint(player_list)\n\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1)]\n\n\n当然，也可以进行新增，使用列表的append()方法可以在列表最后添加一个元素，比如：\n\nplayer_list.append(('Busquets',5))\nprint(player_list)\n\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5)]\n\n\n如果需要添加的元素比较多，可以使用extend()方法，比如：\n\nplayer_list_new=[('Pique',3),('Suárez',9)]\nplayer_list.extend(player_list_new)\nprint(player_list)\n\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n\n\n如果需要在某一个位置插入元素，可以使用insert()方法：\n\nplayer_list.insert(1,('Alba',18))\nprint(player_list)\n\n[('Messi', 10), ('Alba', 18), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n\n\n还可以使用count()方法计算某个元素出现的次数、使用index()方法找到某个元素第一次出现的位置，比如：\n\nmessi=list('Messi')\ncount_s=messi.count('s')\nfirst_s=messi.index('s')\nprint(count_s)\nprint(first_s)\n\n2\n2\n\n\n需要特别注意的是，在Python中，使用等号将一个对象赋值给另一个对象，并不会导致对象的拷贝，而仅仅是给了一个别名，比如：\n\nanother_play_list=player_list\nprint(player_list)\ndel another_play_list[1]\nprint(player_list)\n\n[('Messi', 10), ('Alba', 18), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n\n\n在以上程序中，我们会发现，虽然我们删除的是another_play_list的第2个元素，但是实际上，another_player_list和play_list只是同一个变量的不同别名而已，并没有重新复制一个新的list。\n如果我们需要的是list的一个新的拷贝，需要使用list的copy()方法：\n\nanother_play_list=player_list.copy()\nprint(player_list)\ndel another_play_list[1]\nprint(player_list)\nprint(another_play_list)\n\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n[('Messi', 10), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n\n\n最后，列表、元组、字符串还支持in操作符，该操作符判断in之前的元素是否属于之后的列表、元组或者字符串，比如：\n\nprint('Messi' in player_list[0][0])\nprint('Messi' in player_list[1][0])\nprint(('Pique', 3) in player_list)\nprint('d' in 'Messi')\n\nTrue\nFalse\nTrue\nFalse\n\n\n如果要判断in之前的元素“不属于”之后的列表、元组或字符串，可以使用“not in”:\n\nprint('Messi' not in player_list[0][0])\nprint('Messi' not in player_list[1][0])\nprint(('Pique', 3) not in player_list)\nprint('d' not in 'Messi')\n\nFalse\nTrue\nFalse\nTrue\n\n\n最后，我们还可以使用 sort() 方法对列表进行排序，比如：\n\na=[1,6,2,4,7]\na.sort()\nprint(a)\na.sort(reverse=True)\nprint(a)\n\n[1, 2, 4, 6, 7]\n[7, 6, 4, 2, 1]\n\n\n在比较复杂的情况下，还可以使用key选项制定排序的方式，比如，我们可能需要对player_list中的球员号码进行排序，可以使用：\n\nplayer_list.sort(key=lambda x: x[1])\nprint(player_list)\n\n[('ter Stegen', 1), ('Pique', 3), ('Busquets', 5), ('Xavi', 6), ('Suárez', 9), ('Messi', 10)]\n\n\n当然，以上的语法已经超出了目前所学范围，我们将在后面介绍lambda的含义。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#集合",
    "href": "body/01_py_01_basic.html#集合",
    "title": "9  Python 入门",
    "section": "9.7 集合",
    "text": "9.7 集合\n无论是列表还是元组，都允许有重复的元素存在，但是有时我们可能需要不重复的元素，此时可以使用集合（set）类。\n集合的声明与列表类似，区别在于集合使用大括号{}，而非中括号。\n与list()类似，可以使用使用set()构建集合：\n\nletters=set(\"Messi\")\nprint(letters)\n\n{'e', 's', 'i', 'M'}\n\n\n以上可以看到，set()构建了一个不重复元素组成的集合。可以使用add()方法以及update()方法为集合新增元素，比如：\n\nletters.add('a')\nprint(letters)\nletters.add(('a',))\nprint(letters)\nletters.update({'c','d'})\nprint(letters)\n\n{'M', 'e', 's', 'i', 'a'}\n{('a',), 'M', 'e', 's', 'i', 'a'}\n{('a',), 'M', 'e', 'd', 's', 'i', 'a', 'c'}\n\n\n值得注意的是，在上面的程序中，我们添加了字符串’a’，以及一个元组(‘a’,)，两者一个是字符串，一个是元组，是不同的，因而在集合中两者并不冲突。\n如果需要删除，可以使用remove()方法以及discard()方法，两者的区别在于：remove()方法不能删除不存在的元素，否则报错；而discard()方法如果要删除的元素不存在，不会报错。\n\nletters.remove(('a',))\nprint(letters)\nletters.discard('z')\nprint(letters)\n\n{'M', 'e', 'd', 's', 'i', 'a', 'c'}\n{'M', 'e', 'd', 's', 'i', 'a', 'c'}\n\n\n最后，作为集合，还可以使用issubset()和issuperset()方法判断某一个集合是不是另外一个集合的子集或者超集：\n\nprint(letters.issuperset({'a','b'}))\nprint(letters.issuperset({'a','d'}))\nprint({'a','d'}.issubset(letters))\nprint({'a','d'}.issuperset(letters))\n\nFalse\nTrue\nTrue\nFalse",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#控制语句循环",
    "href": "body/01_py_01_basic.html#控制语句循环",
    "title": "9  Python 入门",
    "section": "9.8 控制语句：循环",
    "text": "9.8 控制语句：循环\n有时我们需要重复一条类似的命令很多次，此时我们可以使用循环命令。\n在Python中有两个循环语句：while和for，两者很大程度上是等价的，但是在不同情况下方便程度时不一样的。\nfor作为关键字，其基本语法为：\nfor var in iterable_obj:\n    ## code\n其中var为一个变量，iterable_obj为一个可迭代对象，如列表、元组或者字符串，其后面紧接着跟着一个冒号。\n在这里需要注意的是，不像C或者Java使用大括号区分代码块，在Python中，主要靠缩进区分代码块，因而需要循环执行的代码，要写在for语句的下一行，并使用Tab键或者几个（一般为4/8个）空格进行缩进。\n比如，以下语句把字符串中的每个字符都分别打印出来：\n\nname='Messi'\nfor n in name:\n    print(n)\n\nM\ne\ns\ns\ni\n\n\n而以下代码将player_list中所有的人名及号码打印出来：\n\nfor player in player_list:\n    print(player[0],end='')\n    print(\" : \",end='')\n    print(player[1])\nprint(\"---the end---\")\n\nter Stegen : 1\nPique : 3\nBusquets : 5\nXavi : 6\nSuárez : 9\nMessi : 10\n---the end---\n\n\n注意到最后一行并没有被缩进，因而不属于需要循环执行的代码块，因而只执行了一次。\n此外，经常遇到的一个情形是对数字进行循环，此时可以使用range()函数。如果使用range(N)，将会返回一个可迭代的对象，其值为0,…,N-1。比如：\n\nlist(range(10))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n也可以使用range(N,M)的形式，此时返回迭代对象的值为N,N+1,…,M-1，比如：\n\nlist(range(1,11))\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n使用以上特性，我们可以方便的使用range()函数来写for 循环，比如：\n\nname='Messi'\nfor i in range(len(name)):\n    print(name[i])\n\nM\ne\ns\ns\ni\n\n\n其中len()函数取得name中元素的个数，由于len(name)的值为5，因而range(len(name))就产生了一个可以迭代的、值为0,1,2,3,4的对象。\n以下程序计算了从1到101的所有奇数的和：\n\nsum_odd=0\nfor i in range(0,51):\n    odd=2*i+1\n    sum_odd+=odd\nprint(sum_odd)\n\n2601\n\n\n而while循环的语法为：\nwhile logic_expression:\n    ## code\n同样，while循环的代码块也需要用缩进表示，而logic_expression是一个逻辑判断语句，只有当logic_expression值为真时，循环才继续执行，否则跳出循环。比如刚刚从1到101的所有奇数的和的代码也可以写为：\n\nsum_odd=0\nodd=1\nwhile odd&lt;=101:\n    sum_odd+=odd\n    odd+=2\nprint(sum_odd)\n\n2601\n\n\n特别需要注意的是一定不要忘了及时更新odd，否则很容易造成无限循环。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#控制语句条件",
    "href": "body/01_py_01_basic.html#控制语句条件",
    "title": "9  Python 入门",
    "section": "9.9 控制语句：条件",
    "text": "9.9 控制语句：条件\n条件语句用于判断某一个逻辑表达式，如果为真，则执行某个代码块。其最基本的形式如下：\nif logic_expression:\n    ## code\n同样，代码块也需要用缩进表示，其中的代码块只有当logic_expression的值为真时才执行，否则不执行。\n比如，如下的代码中，首先判断球员姓名是否为Messi或者Suárez，如果是，则打印其位置：\n\nfor p in player_list:\n    if p[0]=='Messi' or p[0]=='Suárez':\n        print(p[0],\":前锋\")\n\nSuárez :前锋\nMessi :前锋\n\n\n此外，if 后面还可以跟elif语句：\nif logic_expression1:\n    ## code1\nelif logic_expression2:\n    ## code2\nelif  logic_expression3:\n    ## code3\n....\n即“else if”，如果logic_expression1满足，则执行code1，如果不满足，则继续判断logic_expression2是否满足，若满足，则执行code2，以此类推。比如：\n\nfor p in player_list:\n    if p[0] in ('Messi', 'Suárez'):\n        print(p[0],\"：前锋\")\n    elif p[0] in ('Xavi', 'Arthur','Busquets'):\n        print(p[0],\"：中场\")\n    elif p[0] in ('Pique'):\n        print(p[0],\"：后卫\")\n\nPique ：后卫\nBusquets ：中场\nXavi ：中场\nSuárez ：前锋\nMessi ：前锋\n\n\n最后，还可以加else语句，用于所有的if或者elif的逻辑表达式都不满足时执行\n\nfor p in player_list:\n    if p[0] in ('Messi', 'Suárez'):\n        print(p[0],\"：前锋\")\n    elif p[0] in ('Xavi', 'Iniesta','Busquets'):\n        print(p[0],\"：中场\")\n    elif p[0] in ('Pique'):\n        print(p[0],\"：后卫\")\n    else:\n        print(p[0],\"守门员\")\n\nter Stegen 守门员\nPique ：后卫\nBusquets ：中场\nXavi ：中场\nSuárez ：前锋\nMessi ：前锋\n\n\n此外，if语句可以与break、continue、pass等一起控制循环。其中：\n\nbreak：跳出循环不再执行\ncountinue：跳出本次循环后面的代码，但是循环继续执行\npass：什么都不做，继续执行\n\n比如，计算从1到101的所有奇数的和的代码也可以写为：\n\nsum_odd=0\nodd=1\nwhile True:\n    sum_odd+=odd\n    odd+=2\n    if odd&gt;101:\n        break\nprint(sum_odd)\n\n2601\n\n\n在以上代码中，while True代表循环会一直执行，但是if语句会判断odd是否大于了101，如果odd一旦大于101，就会使用break退出循环。\n如果我们需要计算从1到101的所有不能被5整除的奇数的和，可以使用pass语句：\n\nsum_odd=0\nodd=1\nwhile odd&lt;=101:\n    if odd%5==0:\n        pass\n    else:\n        sum_odd+=odd\n    odd+=2\nprint(sum_odd)\n\n2101\n\n\n以下代码我们使用continue语句将一个字符串中所有的’s’都给去掉\n\na='Messi'\nb=''\nfor s in a:\n    if s=='s':\n        continue\n    b+=s\nprint(b)\n\nMei\n\n\n在以上代码中，当碰到’s’时，循环跳过了b+=s这一句，而是继续执行循环，直到循环结束。与之相比的是break命令直接跳出了循环：\n\na='Messi'\nb=''\nfor s in a:\n    if s=='s':\n        break\n    b+=s\nprint(b)\n\nMe",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#实例",
    "href": "body/01_py_01_basic.html#实例",
    "title": "9  Python 入门",
    "section": "9.10 实例",
    "text": "9.10 实例\n\nimport pandas as pd\n\n# 构造一个简单的学生成绩数据\nstudents = [\n    {\"name\": \"Alice\", \"score\": 85},\n    {\"name\": \"Bob\", \"score\": 58},\n    {\"name\": \"Charlie\", \"score\": 92},\n    {\"name\": \"David\", \"score\": 40},\n    {\"name\": \"Eva\", \"score\": 60}\n]\n\n# 只保留成绩及格（&gt;=60）的学生\npassed_students = [s for s in students if s[\"score\"] &gt;= 60]\n\n# 转换为 pandas DataFrame 并打印为表格\ndf_passed = pd.DataFrame(passed_students)\n\n# 打印格式化的表格\nprint(\"及格学生名单：\")\nprint(df_passed.to_string(index=False))\n\n及格学生名单：\n   name  score\n  Alice     85\nCharlie     92\n    Eva     60\n\n\n在上例中，我们使用了 列表推导式（List Comprehension）写法：passed_students 是一个新列表，它通过列表推导式从 students 列表中筛选出所有 \"score\" 大于等于 60 的学生字典 s。这种写法逻辑简洁、表达紧凑：\npassed_students = [s for s in students if s[\"score\"] &gt;= 60]\n它等价于下面的传统写法：\npassed_students = []\nfor s in students:\n    if s[\"score\"] &gt;= 60:\n        passed_students.append(s)\n两者实现的功能完全一致，都是遍历 students 列表，对每个学生字典 s 检查其 \"score\" 值是否大于等于 60，如果是，就将该学生加入新的列表 passed_students。\n列表推导式的优势在于：\n\n写法简洁，更适合一行逻辑较清晰的筛选任务；\n常用于数据清洗、筛选、转换等操作，阅读性和执行效率较高。\n\n当逻辑比较复杂（如嵌套循环或多个条件判断）时，仍推荐使用传统的 for 循环方式，更利于维护和调试。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#控制语句异常",
    "href": "body/01_py_01_basic.html#控制语句异常",
    "title": "9  Python 入门",
    "section": "9.11 控制语句：异常",
    "text": "9.11 控制语句：异常\n理想与现实总是有差距的。在程序现实运行过程中，出于很多原因，总是可能会存在异常（exception）。比如，一个最简单的异常是，允许用户输入两个数字相除，但是用户却输入了0作为分母；或者，用户输入的不是数字，而是字母。此时，正常的程序可能会发生错误。\n任何高级语言几乎都带有处理异常的功能，Python也不例外。\n在Python中，可以使用try…except…else…finally语句来处理异常，语法为：\ntry:\n    # code1\nexcept Exception1:\n    # code2\nexcept Exception2:\n......\n\nelse:\n    # code3\nfinally:\n    #code4\n首先，解释器会执行code1，如果没有错误，就执行code3，并继续下去。如果发生了错误，会查看具体发生何种错误，执行相应的except中的命令。最终，无论错误是否发生，code4都会被执行，并继续执行finally后面的代码。\n比如，下面一个例子展示了分母为0时的处理方法：\n\na=1\nb=0\ntry:\n    c=a/b\nexcept ZeroDivisionError as e:\n    print(\"分母为0:，错误信息：\", e)\nelse:\n    print(\"没有错误发生。\")\nfinally:\n    print(\"C'est la vie!\")\n    print(c)\nprint(\"生活还要继续。\")\n\n分母为0:，错误信息： division by zero\nC'est la vie!\nThis is a cat: 🐈\n生活还要继续。\n\n\n\na=0\nb=1\ntry:\n    c=a/b\nexcept ZeroDivisionError as e:\n    print(\"分母为0:，错误信息：\", e)\nelse:\n    print(\"没有错误发生。\")\nfinally:\n    print(\"C'est la vie!\")\n    print(c)\nprint(\"生活还要继续。\")\n\n没有错误发生。\nC'est la vie!\n0.0\n生活还要继续。\n\n\nexcept可以不止有一个，比如，我们可能还需要处理类型错误，比如将数字和字符串进行运算：\n\na='0'\nb=1\ntry:\n    c=a/b\nexcept ZeroDivisionError as e:\n    print(\"分母为0:，错误信息：\", e)\nexcept TypeError as e:\n    print(\"类型错误：\", e)\nelse:\n    print(\"没有错误发生。\")\nfinally:\n    print(\"C'est la vie!\")\n    print(c)\n\n类型错误： unsupported operand type(s) for /: 'str' and 'int'\nC'est la vie!\n0.0\n\n\n或者可以将两者合并：\n\na='0'\nb=1\ntry:\n    c=a/b\nexcept (ZeroDivisionError,TypeError) as e:\n    print(\"错误：\", e)\nelse:\n    print(\"没有错误发生。\")\nfinally:\n    print(\"C'est la vie!\")\n    print(c)\n\n错误： unsupported operand type(s) for /: 'str' and 'int'\nC'est la vie!\n0.0\n\n\n如果不知道会发生什么错误，也可以什么也不加，捕获所有错误：\n\na='0'\nb=1\ntry:\n    c=a/b\nexcept:\n    print(\"错误：\")\nelse:\n    print(\"没有错误发生。\")\nfinally:\n    print(\"C'est la vie!\")\n    print(c)\n\n错误：\nC'est la vie!\n0.0\n\n\n更好的办法是将错误捕获，并打印出来方便调试：\n\na='0'\nb=1\ntry:\n    c=a/b\nexcept Exception as e:\n    print(\"错误：\", e)\nelse:\n    print(\"没有错误发生。\")\nfinally:\n    print(\"C'est la vie!\")\n    print(c)\n\n错误： unsupported operand type(s) for /: 'str' and 'int'\nC'est la vie!\n0.0",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#列表推导",
    "href": "body/01_py_01_basic.html#列表推导",
    "title": "9  Python 入门",
    "section": "9.12 列表推导",
    "text": "9.12 列表推导\n在Python中，可以结合循环语句for、判断语句if、else等，写出更加简洁的程序。\n比如，如果我们希望生成一个1…99中所有能被3整除的奇数的表达式，一般可以通过如下的程序：\n\na=[]\nfor i in range(50):\n    if (2*i+1)%3==0:\n        a.append(2*i+1)\nprint(a)\n\n[3, 9, 15, 21, 27, 33, 39, 45, 51, 57, 63, 69, 75, 81, 87, 93, 99]\n\n\n以上代码已经足够简洁，但是Python还支持以下更简洁的方式：\n\na=[2*i+1 for i in range(50) if (2*i+1)%3==0]\nprint(a)\n\n[3, 9, 15, 21, 27, 33, 39, 45, 51, 57, 63, 69, 75, 81, 87, 93, 99]\n\n\n当然，也支持双重循环，比如列出一个奇数元组，第一个分类能被3整除，第二个分类能被5整除：\n\nb=[(2*i+1,2*j+1) for i in range(50) for j in range(50) if (2*i+1)%3==0 and (2*j+1)%5==0]\nprint(b)\n\n[(3, 5), (3, 15), (3, 25), (3, 35), (3, 45), (3, 55), (3, 65), (3, 75), (3, 85), (3, 95), (9, 5), (9, 15), (9, 25), (9, 35), (9, 45), (9, 55), (9, 65), (9, 75), (9, 85), (9, 95), (15, 5), (15, 15), (15, 25), (15, 35), (15, 45), (15, 55), (15, 65), (15, 75), (15, 85), (15, 95), (21, 5), (21, 15), (21, 25), (21, 35), (21, 45), (21, 55), (21, 65), (21, 75), (21, 85), (21, 95), (27, 5), (27, 15), (27, 25), (27, 35), (27, 45), (27, 55), (27, 65), (27, 75), (27, 85), (27, 95), (33, 5), (33, 15), (33, 25), (33, 35), (33, 45), (33, 55), (33, 65), (33, 75), (33, 85), (33, 95), (39, 5), (39, 15), (39, 25), (39, 35), (39, 45), (39, 55), (39, 65), (39, 75), (39, 85), (39, 95), (45, 5), (45, 15), (45, 25), (45, 35), (45, 45), (45, 55), (45, 65), (45, 75), (45, 85), (45, 95), (51, 5), (51, 15), (51, 25), (51, 35), (51, 45), (51, 55), (51, 65), (51, 75), (51, 85), (51, 95), (57, 5), (57, 15), (57, 25), (57, 35), (57, 45), (57, 55), (57, 65), (57, 75), (57, 85), (57, 95), (63, 5), (63, 15), (63, 25), (63, 35), (63, 45), (63, 55), (63, 65), (63, 75), (63, 85), (63, 95), (69, 5), (69, 15), (69, 25), (69, 35), (69, 45), (69, 55), (69, 65), (69, 75), (69, 85), (69, 95), (75, 5), (75, 15), (75, 25), (75, 35), (75, 45), (75, 55), (75, 65), (75, 75), (75, 85), (75, 95), (81, 5), (81, 15), (81, 25), (81, 35), (81, 45), (81, 55), (81, 65), (81, 75), (81, 85), (81, 95), (87, 5), (87, 15), (87, 25), (87, 35), (87, 45), (87, 55), (87, 65), (87, 75), (87, 85), (87, 95), (93, 5), (93, 15), (93, 25), (93, 35), (93, 45), (93, 55), (93, 65), (93, 75), (93, 85), (93, 95), (99, 5), (99, 15), (99, 25), (99, 35), (99, 45), (99, 55), (99, 65), (99, 75), (99, 85), (99, 95)]\n\n\n此外还支持else语句，比如，以下代码将1…10的所有奇数都取负数，所有偶数保持不变：\n\nc=[i+1 if (i+1)%2==0 else -(i+1) for i in range(10)]\nprint(c)\n\n[-1, 2, -3, 4, -5, 6, -7, 8, -9, 10]\n\n\n注意如果需要使用else，if…else…要写在for前面。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#字典",
    "href": "body/01_py_01_basic.html#字典",
    "title": "9  Python 入门",
    "section": "9.13 字典",
    "text": "9.13 字典\n字典（dictionary）在Python中是一种映射关系，即特定的单词（键，key）以及其值（value）之间的关系。字典可以使用大括号配合冒号进行声明，比如之前的球员号码：\n\nplayers={\"Messi\":10,\n        \"Xavi\":6,\n        \"Iniesta\":8,\n        \"Pique\":3}\nprint(players)\nprint(players['Messi'])\n\n{'Messi': 10, 'Xavi': 6, 'Iniesta': 8, 'Pique': 3}\n10\n\n\n在以上的代码中，我们使用大括号以及冒号声明了一个字典：playsers，其中键为”Messi”、“Xavi”等等，其值分别为10、6等等。接着，使用players[‘Messi’]取得了键为’Messi’的值。另外也可以使用dict()进行创建：\n\nplayers=dict(Messi=10,Xavi=6,Iniesta=8,Pique=3)\nprint(players)\nprint(players['Messi'])\n\n{'Messi': 10, 'Xavi': 6, 'Iniesta': 8, 'Pique': 3}\n10\n\n\n与上面的结果一样。\n在循环语句中，可以使用通常的循环方法获得一个字典的keys：\n\nfor k in players:\n    print(\"Player: \",k,\": \",players[k])\n\nPlayer:  Messi :  10\nPlayer:  Xavi :  6\nPlayer:  Iniesta :  8\nPlayer:  Pique :  3\n\n\n在以上循环中，我们使用循环遍历了players中所有的键，并将其值打印了出来。\n此外，字典还支持如下操作：\n\nlen(players)：字典players的键-值对的个数\ndel players(k)：删除键k\nk in players：判断字典players中是否有键k\n\n比如：\n\nprint(\"Players中有\",len(players),\"个球员\")\nprint(players)\nif \"Iniesta\" in players:\n    del players[\"Iniesta\"]\nprint(players)\n\nPlayers中有 4 个球员\n{'Messi': 10, 'Xavi': 6, 'Iniesta': 8, 'Pique': 3}\n{'Messi': 10, 'Xavi': 6, 'Pique': 3}",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#python中的none",
    "href": "body/01_py_01_basic.html#python中的none",
    "title": "9  Python 入门",
    "section": "9.14 Python中的None",
    "text": "9.14 Python中的None\n在Python中还有一个非常特殊的类型：None，即什么都没有。注意None并不是空的元组、列表，也不是空的字符串，就是None：\n\ntype(None)\n\nNoneType\n\n\n\ntype('')\n\nstr\n\n\n\ntype([])\n\nlist\n\n\n\ntype(False)\n\nbool\n\n\n由于None表示空的、没有，因而None跟其他任何数据类型比较都是返回False。\n如果要判断某个变量是否是None，可以使用is关键字：\n\na=None\nb=[]\nprint(a is None)\nprint(b is None)\n\nTrue\nFalse",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic.html#小结",
    "href": "body/01_py_01_basic.html#小结",
    "title": "9  Python 入门",
    "section": "9.15 小结",
    "text": "9.15 小结\n最后，我们使用一个综合的例子，回顾一下目前未知所学的内容。\n在接下来的程序中，我们使用input()函数从用户的输入中得到数字，知道用户输入“end”为止，并将所有的数字相加。\n\nsumm=0\nwhile True:\n    text=input(\"请输入一个数字，或者end结束：\")\n    if text==\"end\":\n        break\n    summ+=float(text)\nprint(summ)\n\n请输入一个数字，或者end结束：3\n请输入一个数字，或者end结束：3\n请输入一个数字，或者end结束：2.3\n请输入一个数字，或者end结束：end\n8.3\n\n\n在以上的程序中，我们首先使用input()函数获得用户输入，接着判断用户输入的是否为”end”，如果是，则退出，否则，由于input()获得的是一个字符串，因而我们使用float()函数将该字符串转换为一个浮点数字，再将其相加。\n但是以上程序并不完美，比如，如果用户输入的不是“end”也不是数字，就会报错，因而一个更完善的版本是加入错误处理：\n\nsumm=0\nwhile True:\n    text=input(\"请输入一个数字，或者end结束：\")\n    if text==\"end\":\n        break\n    try:\n        summ+=float(text)\n    except Exception as e:\n        print(\"请输入数字或end！\")\n        continue\nprint(summ)\n\n请输入一个数字，或者end结束：5\n请输入一个数字，或者end结束：5\n请输入一个数字，或者end结束：bug\n请输入数字或end！\n请输入一个数字，或者end结束：end\n10.0",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Python 入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html",
    "href": "body/01_py_01_basic_01_grammer.html",
    "title": "10  Python 代码风格",
    "section": "",
    "text": "10.1 缩进与空行\n对于许多 Python 初学者来说，从 “零基础” 到能敲出一段勉强运行的代码，往往需要花费不少精力，在这个过程中，代码格式和风格常常被抛诸脑后。可别小看这些细节，从长远来看，不规范的代码就像一团乱麻，不仅自己后续维护时容易迷失方向，当项目复杂度上升、参与协作的人数增多，其他开发者面对这样的代码也会一头雾水，极大影响开发效率。\n为此，本文将系统梳理 Python 代码编写的格式和风格要点，同时还会推荐几款实用的 VS Code 插件，并分享如何借助 AI 工具如 Copilot，让你的代码在保持规范的同时，编写过程也更加轻松高效。\n有关 Python 代码风格的规范，最权威的参考是 PEP 8，它是 Python 官方的编码风格指南，涵盖了 Python 代码的方方面面，包括命名规范、缩进、空格使用、注释等。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#缩进与空行",
    "href": "body/01_py_01_basic_01_grammer.html#缩进与空行",
    "title": "10  Python 代码风格",
    "section": "",
    "text": "4 个空格 代表一级缩进；别用 Tab。\n模块级逻辑（导入、数据加载、建模、绘图）之间留 1‑2 行 空行，让结构一目了然。\n\n# Bad\nimport pandas as pd\ndf=pd.read_csv(\"sales.csv\")\nfor y in df[\"year\"].unique():\n  subset=df[df[\"year\"]==y]\n  print(y,subset[\"profit\"].mean())\n\n# Good\nimport pandas as pd\n\ndf = pd.read_csv(\"sales.csv\")\n\nfor y in df[\"year\"].unique():\n    subset = df[df[\"year\"] == y]\n    print(y, subset[\"profit\"].mean())",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#行长度与换行-79-字符",
    "href": "body/01_py_01_basic_01_grammer.html#行长度与换行-79-字符",
    "title": "10  Python 代码风格",
    "section": "10.2 行长度与换行（≤ 79 字符）",
    "text": "10.2 行长度与换行（≤ 79 字符）\n核心原则：让每一行保持可扫描性。\n\n首选：用圆括号 / 方括号 / 花括号包裹后换行。\n必要时（无括号且行极长）：使用 \\，但反斜杠置于行尾，并让下一行缩进 4 空格。\n长列表 / 参数：一个元素（或一个参数）一行，末尾加逗号，易于版本控制。\n\n# Bad – 行太长且难读\nax.plot(df[\"date\"], df[\"close\"], label=\"Shanghai Composite Index Close Price\")\n\n# Good – 括号换行\nax.plot(\n    df[\"date\"],\n    df[\"close\"],\n    label=\"Shanghai Composite Index Close Price\",\n)\n\n# Good – 无括号时最后一招\ntotal = price + cost + tax - discount - coupon \\\n    - special_offer\n\n# Good - version2：可读性更强 (运算符放在行首，而非行尾)\ntotal =   price + cost + tax \\\n        - discount \\\n        - coupon \\\n        - special_offer",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#换行显示拼接与隐式拼接",
    "href": "body/01_py_01_basic_01_grammer.html#换行显示拼接与隐式拼接",
    "title": "10  Python 代码风格",
    "section": "10.3 换行：显示拼接与隐式拼接",
    "text": "10.3 换行：显示拼接与隐式拼接\n\nSource: Python 语言参考手册：2. 词法分析\n\n### 显式拼接行\n两个及两个以上的物理行可用反斜杠（\\）拼接为一个逻辑行，规则如下：以不在字符串或注释内的反斜杠结尾时，物理行将与下一行拼接成一个逻辑行，并删除反斜杠及其后的换行符。例如：\nif 1900 &lt; year &lt; 2100 and 1 &lt;= month &lt;= 12 \\\n   and 1 &lt;= day &lt;= 31 and 0 &lt;= hour &lt; 24 \\\n   and 0 &lt;= minute &lt; 60 and 0 &lt;= second &lt; 60:   # 看来是个有效的日期\n        return 1\n以反斜杠结尾的行，不能加注释；反斜杠也不能拼接注释。除字符串字面值外，反斜杠不能拼接形符（如，除字符串字面值外，不能用反斜杠把形符切分至两个物理行）。反斜杠只能在代码的字符串字面值里，在其他任何位置都是非法的。\n### 隐式拼接行\n圆括号、方括号、花括号内的表达式可以分成多个物理行，不必使用反斜杠。例如：\nmonth_names = ['Januari', 'Februari', 'Maart',      # 这些是\n               'April',   'Mei',      'Juni',       # 一年之中\n               'Juli',    'Augustus', 'September',  # 各个月份的\n               'Oktober', 'November', 'December']   # 荷兰语名称\n隐式行拼接可含注释；后续行的缩进并不重要；还支持空的后续行。隐式拼接行之间没有 NEWLINE 形符。三引号字符串支持隐式拼接行（见下文），但不支持注释。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#空格使用记下面-三条-就够",
    "href": "body/01_py_01_basic_01_grammer.html#空格使用记下面-三条-就够",
    "title": "10  Python 代码风格",
    "section": "10.4 空格使用（记下面 三条 就够）",
    "text": "10.4 空格使用（记下面 三条 就够）\n\n\n\n\n\n\n\n\n规则\nBad\nGood\n\n\n\n\n运算符两侧留空格\nroi=profit/cost\nroi = profit / cost\n\n\n函数参数赋值不留空格\ndf.sort_values( by =\"date\")\ndf.sort_values(by=\"date\")\n\n\n切片不留空格\nseries[ 1 : 5 ]\nseries[1:5]",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#命名约定",
    "href": "body/01_py_01_basic_01_grammer.html#命名约定",
    "title": "10  Python 代码风格",
    "section": "10.5 命名约定",
    "text": "10.5 命名约定\n\n变量 / 列名：lower_case_with_underscores\n常量：UPPER_CASE\n避免 l、O、0 混淆。\n\n# Bad\nProfitRate = df.Profit.mean()\n\n# Good\nprofit_rate = df[\"profit\"].mean()",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#注释与文档四种常见场景",
    "href": "body/01_py_01_basic_01_grammer.html#注释与文档四种常见场景",
    "title": "10  Python 代码风格",
    "section": "10.6 注释与文档（四种常见场景）",
    "text": "10.6 注释与文档（四种常见场景）\n\n行内注释：代码后留 2 空格再写 #。\ndf[\"roe\"] = df[\"net_income\"] / df[\"equity\"]  # 计算 ROE\n逻辑分块注释：在复杂步骤前用一句话说明 目的。\n# ~~~~~ 计算年度收益并绘图 ~~~~~\n\n# Step 1 —— 获取数据 ——\n\n# Step 2 —— 清洗数据 ——\n块注释：多行解释流程，用完整句子，首字母大写。\n# Author: Zhaojun Wang.\n# Date: 2025/5/13\n# Source: CSMAR &gt;&gt; 个股收益数据库.\n# Goal: \n#    1. 计算个股年化收益率.\n#    2. 绘制年化收益率分布图.\n文档字符串（函数 / 类）：三引号包裹，首行一句话，空一行后详细说明（可选）。\ndef annualized_return(r: float, n: int) -&gt; float:\n    \"\"\"将单期利率转换为年化收益率。\n\n    参数\n    ----------\n    r : 单期收益率，如 0.02\n    n : 一年内的期数，例如月度数据则 n = 12\n    \"\"\"\n    return (1 + r) ** n - 1\n# 查看函数的帮助文件: 会显示上述文档字符串\nimport anualized_return\nhelp(annualized_return)",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#导入顺序",
    "href": "body/01_py_01_basic_01_grammer.html#导入顺序",
    "title": "10  Python 代码风格",
    "section": "10.7 导入顺序",
    "text": "10.7 导入顺序\n# Good\nimport datetime as dt          # 1. 标准库\nimport numpy as np             # 2. 第三方库\nimport pandas as pd\nfrom utils.io import save_png   # 3. 本地模块\n各组之间留 1 空行，避免 from module import *。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#类型提示",
    "href": "body/01_py_01_basic_01_grammer.html#类型提示",
    "title": "10  Python 代码风格",
    "section": "10.8 类型提示",
    "text": "10.8 类型提示\n即使暂时不写函数，也可以给变量加注解，IDE 会即时提示类型。\nrate: float = 0.08\namount: float = 1_200.0\ntax: float = amount * rate\n\n好处：pylance、mypy 可检查数值与字符串混用等低级错误。\n成本：仅多写 : 类型，对运行速度基本无影响。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#自动格式化与-vs-code-工作流",
    "href": "body/01_py_01_basic_01_grammer.html#自动格式化与-vs-code-工作流",
    "title": "10  Python 代码风格",
    "section": "10.9 自动格式化与 VS Code 工作流",
    "text": "10.9 自动格式化与 VS Code 工作流\n\n\n\n\n\n\n\n\n\n需求\n推荐工具\nVS Code 插件\n关键设置\n\n\n\n\n统一排版\nblack\nBlack Formatter\n“Format on Save”\n\n\n语法 / 风格检查\nflake8 或 pylint\nPython 扩展内置\n\"python.linting.enabled\": true\n\n\n导入排序\nisort\nisort\npython.sortImports.onSave\": true\n\n\n\n一键配置示例\npip install black flake8 isort\n# 在项目根目录创建 pyproject.toml\necho \"[tool.black]\\nline-length = 88\" &gt; pyproject.toml\n\nJupyter Notebook 中的 .ipynb 也支持 Format on Save：\n\n安装 Black Formatter 插件。\n在设置中启用 Jupyter: Format On Save。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#ai-生成代码还要格式化吗",
    "href": "body/01_py_01_basic_01_grammer.html#ai-生成代码还要格式化吗",
    "title": "10  Python 代码风格",
    "section": "10.10 AI 生成代码还要格式化吗？",
    "text": "10.10 AI 生成代码还要格式化吗？\n\nLLM 输出 ≠ 100 % 合规：ChatGPT / DeepSeek 生成的代码常有混用 Tab、行长超标等问题。\n最佳实践：生成后立即 black 一遍，让代码自动落到团队风格，不折腾手动对齐。\n调试视角：格式一致、空行明确，才能快速定位 AI 可能漏掉的边界条件或隐蔽 Bug。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#借助-ai-工具进行格式化",
    "href": "body/01_py_01_basic_01_grammer.html#借助-ai-工具进行格式化",
    "title": "10  Python 代码风格",
    "section": "10.11 借助 AI 工具进行格式化",
    "text": "10.11 借助 AI 工具进行格式化\n1. GitHub Copilot 插件\n如果你已经在 VScode 中安装了 github copilot 插件，可以选中代码后，输入提示词 格式化，快速调整格式：\n\n\n\nCopilot_01_format\n\n\n2. 其他插件：Prettier, autopep8 等 如果不使用 github copilot，可以使用 Ctrl + Shift + P，输入 Format Document，快速调整格式：\n如下几个 VScode 插件也可以实现格式化功能： - Prettier - Code formatter - Python autopep8 - autoDocstring\n3. ChatGPT, DeepSeek 等\n也可以在 ChatGPT 或 DeepSeek 中输入提示词快速调整格式，比如：\n\n\n\n\n\n\n提示词\n\n\n\n帮我按照 PEP 8 规范格式化如下 Python 代码，要求： 1. 不要对原文内容工作任何修改 2. 输出结果时，不要添加任何额外的文字\n~~~ 贴入 Python 代码 ~~~",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_01_grammer.html#总结",
    "href": "body/01_py_01_basic_01_grammer.html#总结",
    "title": "10  Python 代码风格",
    "section": "10.12 总结",
    "text": "10.12 总结\n按照本清单落实 缩进、空格、命名、注释、自动工具 五个核心点，你的脚本即可达“干净易读、工具友好”的 80 % 合规线。剩余细节交给 black + flake8 + isort，把精力留给金融建模与数据洞察。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Python 代码风格</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html",
    "href": "body/01_py_01_basic_02_QuickReference.html",
    "title": "11  Python 常用命令速查表",
    "section": "",
    "text": "11.1 环境配置",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#环境配置",
    "href": "body/01_py_01_basic_02_QuickReference.html#环境配置",
    "title": "11  Python 常用命令速查表",
    "section": "",
    "text": "Anaconda：推荐使用 Anaconda 进行 Python 环境管理和包安装\n\nGetting started with conda\n\nVS Code：推荐使用 VS Code 作为 Python 开发环境\nVS Code 常用插件（推荐安装）\n\nPython（基础语法支持）\nJupyter（运行 .ipynb 文件）\nPylance（智能补全与类型检查）\nGitHub Copilot / ChatGPT 插件（AI 辅助编程）\nData wrangler（呈现表格）",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#基础语法与变量操作",
    "href": "body/01_py_01_basic_02_QuickReference.html#基础语法与变量操作",
    "title": "11  Python 常用命令速查表",
    "section": "11.2 基础语法与变量操作",
    "text": "11.2 基础语法与变量操作\nprint(\"Hello, world!\")       # 输出字符串\nname = input(\"请输入姓名：\")  # 获取用户输入\nx = 5                        # 赋值\ntype(x)                      # 查看变量类型\nint(\"123\"), str(123)         # 类型转换\nlen(\"abc\")                   # 求长度（字符串、列表等通用）\n\nnum = 3.14                   # 浮点数\nis_active = True             # 布尔值\nx, y, z = 1, 2, \"three\"      # 多变量赋值\n10 // 3                      # 整除 → 3\n2 ** 3                       # 幂运算 → 8\nabs(-5)                      # 绝对值\nround(3.1415, 2)             # 四舍五入",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#控制流程",
    "href": "body/01_py_01_basic_02_QuickReference.html#控制流程",
    "title": "11  Python 常用命令速查表",
    "section": "11.3 控制流程",
    "text": "11.3 控制流程\n# 条件判断\nif x &gt; 0:\n    print(\"正数\")\nelif x == 0:\n    print(\"零\")\nelse:\n    print(\"负数\")\n\n# for 循环\nfor i in range(5):\n    print(i)\n\n# while 循环\nwhile x &lt; 10:\n    x += 1\n\n# 跳出、跳过、占位\nbreak, continue, pass",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#常用数据结构命令",
    "href": "body/01_py_01_basic_02_QuickReference.html#常用数据结构命令",
    "title": "11  Python 常用命令速查表",
    "section": "11.4 常用数据结构命令",
    "text": "11.4 常用数据结构命令\n\n11.4.1 字符串 str\ns = \"hello\"\ns.upper(), s.lower()        # 转大写、小写\ns.replace(\"l\", \"L\")         # 替换字符\ns.split(\",\")                # 分割字符串\n\",\".join([\"a\", \"b\"])        # 合并为字符串\n\n\n11.4.2 列表 list\nlst = [1, 2, 3]\nlst.append(4)               # 添加元素\nlst.pop()                   # 删除最后一个\nlst[0], lst[-1]             # 索引访问第一个、最后一个元素\nlst[1:3]                    # 切片\n\nlst.insert(1, 1.5)          # 指定位置插入\nlst.remove(1.5)             # 删除指定元素\nlst.extend([4,5])           # 合并列表\nlst.index(2)                # 查找元素索引\n[ x**2 for x in lst ]       # 列表推导式\n\n\n11.4.3 字典 dict\nd = {\"a\": 1, \"b\": 2}        # 创建字典\nd[\"a\"]                      # 通过键取值\nd.get(\"a\", 0)               # 安全取值，键不存在返回默认值\nd.keys(), d.values(), d.items()  # 获取所有键、值、键-值对\n\n\n11.4.4 集合 set\ns = set([1, 2, 3])\ns.add(4)\ns.union({2, 5})          # 求并集\ns.intersection({2, 3})   # 求交集",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#文件路径项目设置",
    "href": "body/01_py_01_basic_02_QuickReference.html#文件路径项目设置",
    "title": "11  Python 常用命令速查表",
    "section": "11.5 文件、路径、项目设置",
    "text": "11.5 文件、路径、项目设置\nimport os\nos.getcwd()                 # 当前工作目录\nos.chdir(\"路径\")            # 切换目录\nos.listdir()                # 查看目录内容\nos.path.exists(\"data.txt\")  # 检查文件存在\nos.mkdir(\"new_folder\")      # 创建目录    \n\n# 文件读写\nwith open(\"data.txt\", \"r\") as f:\n    content = f.read()       # 读取文件内容\n\nwith open(\"out.txt\", \"w\") as f:\n    f.write(\"Hello, file!\")  # 写入文件内容\n\nwith open(\"data.txt\") as f:  # 逐行读取\n    for line in f:\n        print(line.strip())\n\n# JSON处理\nimport json\ndata = {\"name\": \"Alice\"}\njson.dump(data, open(\"data.json\", \"w\"))\nloaded = json.load(open(\"data.json\"))",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#包安装与环境管理使用-pip",
    "href": "body/01_py_01_basic_02_QuickReference.html#包安装与环境管理使用-pip",
    "title": "11  Python 常用命令速查表",
    "section": "11.6 包安装与环境管理（使用 pip）",
    "text": "11.6 包安装与环境管理（使用 pip）\npip install pandas          # 安装\npip install -U numpy        # 升级\npip uninstall matplotlib    # 卸载\n\npip list                    # 查看所有包\npip show seaborn            # 查看包信息\n\npip freeze &gt; req.txt        # 导出依赖\npip install -r req.txt      # 安装依赖",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#jupyter-vs-code-使用技巧",
    "href": "body/01_py_01_basic_02_QuickReference.html#jupyter-vs-code-使用技巧",
    "title": "11  Python 常用命令速查表",
    "section": "11.7 Jupyter & VS Code 使用技巧",
    "text": "11.7 Jupyter & VS Code 使用技巧\n\n11.7.1 常用 Jupyter 魔法命令（只适用于 .ipynb）\n%pwd                       # 显示当前路径\n%cd 路径                   # 切换目录\n%whos                      # 查看变量\n%reset -f                  # 清空变量\n%timeit sum(range(10000)) # 测试代码运行时间",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#基础绘图与数据分析模块速查",
    "href": "body/01_py_01_basic_02_QuickReference.html#基础绘图与数据分析模块速查",
    "title": "11  Python 常用命令速查表",
    "section": "11.8 基础绘图与数据分析模块（速查）",
    "text": "11.8 基础绘图与数据分析模块（速查）\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# pandas\ndf = pd.read_csv(\"data.csv\")\ndf.head(), df.describe()\ndf[\"col\"].mean(), df.dropna()\n\n# numpy\na = np.array([1, 2, 3])\na.mean(), a.std(), a.shape\n\n# matplotlib\nplt.plot([1, 2, 3], [4, 5, 6])\nplt.title(\"简单图形\")\nplt.xlabel(\"X轴\")\nplt.ylabel(\"Y轴\")\nplt.show()",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#代码风格与注释规范",
    "href": "body/01_py_01_basic_02_QuickReference.html#代码风格与注释规范",
    "title": "11  Python 常用命令速查表",
    "section": "11.9 代码风格与注释规范",
    "text": "11.9 代码风格与注释规范\n\n11.9.1 注释与文档字符串\n# 单行注释用 #\n\"\"\"\n多行注释可用于函数文档\n\"\"\"\n\ndef add(x, y):\n    \"\"\"返回两个数的和\"\"\"\n    return x + y\n\n\n11.9.2 格式建议（PEP 8 简要）\n\n变量名用小写加下划线：my_variable\n函数名应有描述性：def calculate_mean()\n运算符左右加空格：a = b + c\n每行不超过 79 个字符",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_02_QuickReference.html#分组计算",
    "href": "body/01_py_01_basic_02_QuickReference.html#分组计算",
    "title": "11  Python 常用命令速查表",
    "section": "11.10 分组计算",
    "text": "11.10 分组计算\ndf[['reduced_lunch', 'school_rating']].groupby(['school_rating']).describe()",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Python 常用命令速查表</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html",
    "href": "body/01_py_01_basic_03_Packages.html",
    "title": "12  Python 常用扩展包",
    "section": "",
    "text": "12.1 数据处理与分析\n截至 2024 年 5 月 6 日，Python 社区已发布超过 530,000 个包（来源），涵盖了从科学计算、数据分析到机器学习、Web 开发的几乎所有领域。用户可通过 PyPI 进行查找和安装。\n然而，对于经济、金融、管理、社会科学等领域的初学者来说，要在如此庞大的生态中快速识别出高效实用的工具包，并不容易。为此，本文梳理了这些领域中较为常用、应用成熟的 Python 扩展包，按功能分类整理，并附上官网或 GitHub 链接，便于进一步了解与使用。\n这些库是处理结构化数据的核心工具，适用于经济建模、金融分析和社会学研究。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#数据处理与分析",
    "href": "body/01_py_01_basic_03_Packages.html#数据处理与分析",
    "title": "12  Python 常用扩展包",
    "section": "",
    "text": "pandas (官网)\n数据分析的瑞士军刀，支持数据清洗、转换和统计分析。\nNumPy (官网)\n高性能数值计算的基础库，支持多维数组和矩阵运算。\nscipy (官网)\n构建在 NumPy 基础上的科学计算库，包含优化、积分、插值等模块。\nDask (官网)\n并行计算库，支持超大数据集的处理，API 与 pandas 高度兼容。\nPolars (GitHub)\n基于 Rust 的极速 DataFrame 库，适合高频金融数据处理。\ncuDF (文档)\nRAPIDS.AI 提供的 GPU 加速 DataFrame 库，语法类似 pandas。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#数据可视化",
    "href": "body/01_py_01_basic_03_Packages.html#数据可视化",
    "title": "12  Python 常用扩展包",
    "section": "12.2 数据可视化",
    "text": "12.2 数据可视化\n用直观图表展示经济趋势、金融指标或社会现象。\n\nMatplotlib (官网)\nPython 最基础的绘图库，适合精细定制各类图表。\nSeaborn (官网)\n用于统计图表绘制，默认风格美观，适合快速可视化。\nPlotly (官网)\n支持交互式图表，适合构建金融仪表盘或 Web 分析应用。\nBokeh (官网)\n适合 Web 端交互式可视化和实时流式数据图表。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#统计与计量经济学",
    "href": "body/01_py_01_basic_03_Packages.html#统计与计量经济学",
    "title": "12  Python 常用扩展包",
    "section": "12.3 统计与计量经济学",
    "text": "12.3 统计与计量经济学\n从基础统计到复杂计量模型，覆盖社会科学研究需求。\n\nstatsmodels (官网)\n回归分析、时间序列建模的首选工具，类似于 R 中的 lm 和 glm。\nlinearmodels (GitHub)\n提供工具变量、面板数据、系统 GMM 等高级计量方法。\nARCH (GitHub)\n金融时间序列分析的经典库，支持 GARCH、EGARCH 等模型。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#机器学习与-automl",
    "href": "body/01_py_01_basic_03_Packages.html#机器学习与-automl",
    "title": "12  Python 常用扩展包",
    "section": "12.4 机器学习与 AutoML",
    "text": "12.4 机器学习与 AutoML\n从传统算法到经济预测，助力数据驱动决策。\n\nscikit-learn (官网)\n入门首选，集成分类、回归、聚类、降维等算法。\nXGBoost / LightGBM (官网, 文档)\n高性能梯度提升框架，广泛应用于风控、信贷评分等金融预测场景。\ncuML (文档)\nRAPIDS.AI 的 GPU 加速机器学习库，与 scikit-learn API 保持一致。\ntslearn (GitHub)\n专注于时间序列聚类、分类与对齐的机器学习工具。\nPyCaret (GitHub)\n自动化机器学习框架，封装 sklearn 流程，适合快速原型开发。\nH2O.ai (官网)\nJava 编写的分布式 AutoML 平台，支持 Python、R、Java 接口，擅长大数据机器学习。\nTPOT (GitHub)\n基于遗传编程的 AutoML 工具，可自动搜索最优模型管道。\nauto-sklearn (GitHub)\n基于贝叶斯优化的 AutoML 工具，兼容 sklearn 风格。\nFLAML (GitHub)\n微软开源的轻量级 AutoML 工具，支持低资源、高效率搜索。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#金融科技与量化计算",
    "href": "body/01_py_01_basic_03_Packages.html#金融科技与量化计算",
    "title": "12  Python 常用扩展包",
    "section": "12.5 金融科技与量化计算",
    "text": "12.5 金融科技与量化计算\n专为金融数据、交易策略和经济建模设计。\n\nQuantLib (GitHub)\n金融工程标准工具，适用于衍生品定价与风险管理。\nTA-Lib (官网)\n包含 150 多种技术指标（如 MACD、RSI），适合交易策略构建。\nccxt (官网)\n统一 API 接入加密货币交易所，适合实时行情获取与策略执行。\nPyPortfolioOpt (GitHub)\n投资组合优化库，支持均值-方差、最小方差、风险平价等策略。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#网络爬虫与自动化",
    "href": "body/01_py_01_basic_03_Packages.html#网络爬虫与自动化",
    "title": "12  Python 常用扩展包",
    "section": "12.6 网络爬虫与自动化",
    "text": "12.6 网络爬虫与自动化\n高效获取公开经济数据或社会舆情信息。\n\nRequests (官网)\n简洁的 HTTP 库，适用于 API 抓取和基本数据请求。\nBeautifulSoup (官网)\nHTML/XML 解析利器，适合静态网页数据提取。\nSelenium (官网)\n浏览器自动化框架，支持处理 JavaScript 动态加载页面。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#宏观与市场数据获取",
    "href": "body/01_py_01_basic_03_Packages.html#宏观与市场数据获取",
    "title": "12  Python 常用扩展包",
    "section": "12.7 宏观与市场数据获取",
    "text": "12.7 宏观与市场数据获取\n\nyfinance (GitHub)\n从 Yahoo Finance 抓取股票、汇率、指数等历史数据。\nFRED API (官网)\n获取美国联储宏观经济数据（需配合 fredapi 包）。\nAlpha Vantage (官网)\n免费金融数据 API，涵盖股票、外汇、加密货币等。\nOECD API (官网)\n提供全球经济合作组织（OECD）各国经济社会数据。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#自然语言处理nlp",
    "href": "body/01_py_01_basic_03_Packages.html#自然语言处理nlp",
    "title": "12  Python 常用扩展包",
    "section": "12.8 自然语言处理（NLP）",
    "text": "12.8 自然语言处理（NLP）\n适用于社会科学、金融情感分析、文本挖掘与用户舆情分析。\n\nNLTK (官网)\n自然语言处理的经典教学工具，内置 50+ 语料库与词典资源（如 WordNet），适合快速原型构建与教学使用。\nspaCy (官网)\n工业级 NLP 库，内建高效的文本处理组件，支持 GPU、多语言、预训练模型（如 BERT）、NER 与句法分析，适合大规模信息提取与生产部署。\nGensim (官网)\n专用于主题建模、文档相似度计算与文本向量化，支持 LDA、LSA、word2vec 等主流算法，适合海量语料处理与信息检索场景。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#参考资料与延伸阅读",
    "href": "body/01_py_01_basic_03_Packages.html#参考资料与延伸阅读",
    "title": "12  Python 常用扩展包",
    "section": "12.9 参考资料与延伸阅读",
    "text": "12.9 参考资料与延伸阅读\n\nspaCy 官方网站\nNLTK 教程\nGensim 教程与文档\nspaCy Cheatsheet (PDF)\nPython Package Index (PyPI)\nRAPIDS.AI 官方文档\nML-Python Best Of\nscikit-learn 官方文档\nstatsmodels 官方文档\nH2O.ai 官方文档\nPyCaret 教程\nauto-sklearn 教程\nTPOT 教程\nFLAML 教程",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_03_Packages.html#相关推文",
    "href": "body/01_py_01_basic_03_Packages.html#相关推文",
    "title": "12  Python 常用扩展包",
    "section": "12.10 相关推文",
    "text": "12.10 相关推文\n\nNote：产生如下推文列表的 Stata 命令为：\n  lianxh 扩展包 Python金融 selenium 可复现数据科学 , md nocat\n安装最新版 lianxh 命令：\n  ssc install lianxh, replace\n\n\n范思妤, 2023, Python：基于selenium爬取科创板审核问询, 连享会 No.1172.\n连小白, 2025, R语言：Top期刊中使用最多的50个R扩展包, 连享会 No.1550.\n陈卓然, 2023, Python金融分析系列-1：日期和时间变量的处理和转换, 连享会 No.1294.\n陈卓然, 2023, Python金融分析系列-2：数据可视化, 连享会 No.1295.\n陈卓然, 2023, Python金融分析系列-3：金融时间序列, 连享会 No.1298.\n陈卓然, 2023, Python金融分析系列-4：数学工具-近似、凸优化、积分和符号运算, 连享会 No.1300.\n陈卓然, 2023, Python：爬虫雅虎财经数据-selenium, 连享会 No.1306.\n高瑜, 2024, 新书推荐：可复现数据科学及 Python 应用, 连享会 No.1485.",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Python 常用扩展包</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html",
    "href": "body/01_py_01_basic_04_import.html",
    "title": "13  Python：import 使用详解",
    "section": "",
    "text": "13.1 引言\n对于 Python 初学者来说，经常会在代码的前几行看到如下语句：\n这时候，初学者往往会产生疑问：这些语句的作用是什么？为什么有时会看到很多类似的 import 语句？我如何知道自己需要导入哪些包？这些包到底是从哪里来的？它们如何帮助我实现特定的功能？\n在本篇讲义中，我们将深入探讨 import 语句的使用，特别是如何通过导入模块和包，来扩展 Python 的功能，避免重复编写代码，提高开发效率。\n通过实践，初学者可以逐渐掌握如何根据自己的需求，导入所需的库和模块，从而让自己的代码变得更加简洁且高效。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#引言",
    "href": "body/01_py_01_basic_04_import.html#引言",
    "title": "13  Python：import 使用详解",
    "section": "",
    "text": "import numpy as np\nimport yfinance as yf\nimport pandas as pd\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#什么是模块包和函数",
    "href": "body/01_py_01_basic_04_import.html#什么是模块包和函数",
    "title": "13  Python：import 使用详解",
    "section": "13.2 什么是模块、包和函数？",
    "text": "13.2 什么是模块、包和函数？\n函数 (Function)\n在 Python 中，函数是程序的基本组成部分。函数是一段执行特定任务的代码，可以接收输入并返回输出。函数是我们编写高效、简洁代码的重要工具。\n例如，math.sqrt() 是 Python 标准库中的一个函数，用于计算平方根。它是一个模块中的一个功能。\n模块 (Module)\n模块是一个包含 Python 代码的文件，通常是一个 .py 文件。一个模块可以包含多个函数、类和变量，用来实现特定的功能。模块是对功能的封装，可以提高代码的可维护性和可复用性。\n例如，math 是一个标准库模块，它包含了许多数学计算相关的函数，如 sqrt()、sin()、cos() 等。\n包 (Package)\n包是一个包含多个模块的目录。包可以将相关的模块组织在一起，方便管理和使用。每个包目录中都会包含一个特殊的 __init__.py 文件，它标识该目录是一个包。\n例如，numpy 是一个非常常见的 Python 包，它包含多个子模块（如 numpy.linalg 用于线性代数运算，numpy.fft 用于傅里叶变换等）。\n函数、模块和包之间的关系\n为了更好地理解函数、模块和包之间的关系，下面是一个结构图：\nPackage (包)\n    ├── Module (模块)\n    │     ├── Function (函数)\n    │     ├── Function (函数)\n    │     └── Class (类)\n    ├── Module (模块)\n    └── __init__.py\n在上图中，我们可以看到： - 包（Package） 是由多个 模块（Module） 组成的文件夹。 - 每个 模块（Module） 内部可以包含多个 函数（Function），也可以包含 类（Class）。 - 函数 是模块中的功能实现，它通常执行某一具体的任务。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#import-语句基本用法",
    "href": "body/01_py_01_basic_04_import.html#import-语句基本用法",
    "title": "13  Python：import 使用详解",
    "section": "13.3 import 语句：基本用法",
    "text": "13.3 import 语句：基本用法\n\n13.3.1 导入整个模块\n最常见的方式是导入整个模块：\nimport math\n这样我们就可以使用 math 模块中的所有函数，如 math.sqrt()、math.sin() 等。\n\n\n13.3.2 给模块起别名\n为了提高代码的可读性和简洁性，我们通常给模块起一个别名，尤其是对于较长的模块名。例如，numpy 可以用 np 作为别名：\nimport numpy as np\n之后，我们可以通过 np 来引用 numpy 中的函数或类：\narr = np.array([1, 2, 3])\nprint(arr)\n\n\n13.3.3 从模块中导入特定函数\n如果只需要模块中的特定功能，可以直接导入所需的函数：\nfrom math import sqrt\n此时，我们可以直接使用 sqrt() 函数，而不需要再写 math.sqrt()。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#import-的机制",
    "href": "body/01_py_01_basic_04_import.html#import-的机制",
    "title": "13  Python：import 使用详解",
    "section": "13.4 import 的机制",
    "text": "13.4 import 的机制\n\n13.4.1 导入的背后：存储和内存\n当你导入一个模块时，Python 会从其存储位置加载模块的代码到内存中，之后在内存中执行。对于标准库模块（如 math），它们已经随着 Python 安装包一起安装在你的电脑上，而第三方包（如 numpy、yfinance 等）需要通过 pip 或 conda 等工具安装，并通过 import 语句加载到内存中。\n\n\n13.4.2 为什么需要 import？\n很多初学者会问：“我已经安装了 yfinance 这个包，它已经在我的电脑上了，为什么每次使用时还要写 import yfinance as yf？”这是因为安装包并不会自动加载到 Python 的工作环境中。每次执行代码时，我们都需要明确告诉 Python 哪些功能是我们需要使用的，而 import 就是告诉 Python 去哪里找这些功能。import 将模块或包加载到内存中，以便在运行时使用。\n\n\n13.4.3 如何查看已安装包的存储位置？\n对于初学者来说，了解自己安装的包存储在哪里，有助于理解模块的导入机制。假设我们想查看 numpy 包的存储路径，可以使用以下 Python 命令：\nimport numpy\nprint(numpy.__file__)\n这将输出 numpy 包的文件路径，类似于：\nC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\n在该路径下，你会看到 numpy 包的所有文件和子目录，包含了该包的源码、配置文件等。\n\n\n13.4.4 目录结构\n我们可以通过 dir 命令查看该路径下的所有文件。例如：\nimport os\nprint(os.listdir(r'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy'))\n你还可以使用 tree 命令（如果安装了 tree 工具）以树形结构显示目录内容：\nC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\n├── core\n│   ├── arrayobject.py       &lt;- 用于数组操作的模块\n│   ├── umath.py             &lt;- 数学运算模块\n│   └── ...\n├── linalg\n│   ├── linalg.py            &lt;- 线性代数运算模块\n│   └── ...\n└── __init__.py              &lt;- 初始化文件\n\n\n13.4.5 从模块中导入特定函数的好处\n通过 from module import function 语句，我们可以只导入模块中的某个函数或类，而不是整个模块。这带来了几个好处： - 减少内存消耗：只加载需要的部分，避免不必要的内存开销。 - 简化代码：导入函数后，我们可以直接使用函数名称，避免在代码中重复书写模块名。\n例如，从 math 模块中只导入 sqrt 函数：\nfrom math import sqrt\nprint(sqrt(25))  # 直接使用 sqrt 函数",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#import-语句高级用法",
    "href": "body/01_py_01_basic_04_import.html#import-语句高级用法",
    "title": "13  Python：import 使用详解",
    "section": "13.5 import 语句：高级用法",
    "text": "13.5 import 语句：高级用法\n\n13.5.1 动态导入\n在某些情况下，我们可能需要在运行时根据条件来导入模块，这时可以使用 importlib：\nimport importlib\n\nnumpy = importlib.import_module('numpy')\nprint(numpy.array([1, 2, 3]))\n\n\n13.5.2 按需加载\n虽然通常情况下我们会在代码开始时导入所有需要的库，但在某些特殊情况下，按需加载可以提高代码的性能。例如：\ndef some_function():\n    import numpy as np\n    # 使用 numpy 库进行操作\n这种方式可以避免在程序启动时加载不必要的库，但对于大多数用户来说，在文件开始部分就加载所有需要的包更直观。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#总结与建议",
    "href": "body/01_py_01_basic_04_import.html#总结与建议",
    "title": "13  Python：import 使用详解",
    "section": "13.6 总结与建议",
    "text": "13.6 总结与建议\n在 Python 中，import 语句是非常重要的，它帮助我们将模块化的代码引入到程序中，提升代码的可重用性和模块化程度。我们可以通过导入整个模块、给模块起别名、从模块中导入特定功能等方式灵活地使用模块。\n在使用 import 时，我们需要根据实际需求选择合适的导入方式，避免命名冲突，并理解 import 是如何将模块加载到内存中的。继续实践并探索更多 Python 内置和第三方模块的使用，将会帮助你写出更简洁、可维护的代码。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#参考资料",
    "href": "body/01_py_01_basic_04_import.html#参考资料",
    "title": "13  Python：import 使用详解",
    "section": "13.7 参考资料",
    "text": "13.7 参考资料\n以下是与本讲义直接相关的一些链接，供读者扩展阅读：\n\nPython 官方文档 - 模块\nnumpy 官方文档\nPython 中的包和模块概念",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_04_import.html#附录提示词",
    "href": "body/01_py_01_basic_04_import.html#附录提示词",
    "title": "13  Python：import 使用详解",
    "section": "13.8 附录：提示词",
    "text": "13.8 附录：提示词\n\n\n\n\n\n\n提示词\n\n\n\n\n13.8.1 Prompt 1\n\n写一篇讲义，主题：Python 中的 import 使用详解。\n读者：初学者，对 Python 几乎一无所知\n语言风格：朴实，严谨。一个从事多年 Python 教学的教授所写\n\n你先帮我介绍一个提纲和思路，我修改确认后再开始写\n\n\n13.8.2 Prompt 2\n补充：\n\n为了让初学者有个直观的感受，能否以 numpy 包为例，介绍其存储位置，以及文件夹中的内&gt;容。我的路径为「C:-packages」，你可以在讲义中&gt;介绍一些 Python 命令，以便读者能够获取它的电脑中的路径。总之，要提供一些指引，让读者能&gt;够看到这个文件夹下的内容。也可以用 dir tree 结构图来呈现。似乎可以用 sys.path 命&gt;令。\n「引言」部分，可以采用更有趣的导入方式，比如：对于 Python 初学者而言，经常看到代码&gt;的前几行会出现如下语句：\n\nimport numpy as np\nimport yfinance as yf\n……\n不免产生如下疑问：这些语句的作用是什么？我如何知道我该 import 哪些 packages？……\n\n「2. 什么是模块和包？」部分：可以先介绍一下 function 的概念，这是 Python 的基本元&gt;素，然后再介绍更高阶的内容，这样读者更容易理解诸如 np.arry, os.getcwd () 这样的表达&gt;式\n有一个重要的问题是：很多人认为，我已经 install 了 yfinance package，它已经存储在了&gt;我的电脑上；另外， 诸如 math 这样的标准库模块，在我安装 Python 后 Anocanda 的时候就自&gt;动安装在我的电脑中了，为何我用的时候还需要 import yfinance？你要在讲义的合适位置讲一下&gt;这个问题。可能需要讲一下，import numpy 把【什么文件】导入到了【什么位置】（内存？），&gt;这种做法的好处是什么？\n「4.3 从模块中导入特定函数」部分，这种做法的好处是什么？\n「6.2 按需加载」最好补充一个例子。不过，我猜测对于多数用户而言，这个问题并不重要。反&gt;而是在文件开头部分就载入所有 packages 可以让代码更直观？\n\n\n\n13.8.3 Prompt 3\n修改： 在「2. 什么是模块、包和函数？」部分，能否增加一个 结构图，更直观地展示 函数，模块和 package 之间的关系\n\n\n13.8.4 Prompt 4\n很好，整合成一个完整的文档。 在结尾处提供 2-3 个与本讲义直接相关的链接，以便读者扩展阅读",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Python：import 使用详解</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html",
    "href": "body/01_py_01_basic_05_OOP.html",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "",
    "text": "14.1 简介\n本章的目的不是教你编程，而是为了让你更好地理解 Python 的语法规则。\n对于初学 Python 的人而言，“Python 是一门面向对象的编程 (OOP) 语言” 这样的表述想必并不陌生。然而，“面向对象”究竟是什么，尤其是“对象”的概念，却常常让人摸不着头脑。以众多 Stata 老用户为例，当他们初次见到下面这段代码时，往往会陷入困惑：\nimport statsmodels.api as sm\nimport pandas as pd\n\n# 加载示例数据\nmtcars = sm.datasets.get_rdataset('mtcars', 'datasets').data\n\n# 模型 1\nX1 = mtcars[['wt']]\nX1 = sm.add_constant(X1)\ny = mtcars['mpg']\nmodel1 = sm.OLS(y, X1).fit()\nprint(model1.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    mpg   R-squared:                       0.753\nModel:                            OLS   Adj. R-squared:                  0.745\nMethod:                 Least Squares   F-statistic:                     91.38\nDate:                Sat, 24 May 2025   Prob (F-statistic):           1.29e-10\nTime:                        01:31:42   Log-Likelihood:                -80.015\nNo. Observations:                  32   AIC:                             164.0\nDf Residuals:                      30   BIC:                             167.0\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         37.2851      1.878     19.858      0.000      33.450      41.120\nwt            -5.3445      0.559     -9.559      0.000      -6.486      -4.203\n==============================================================================\nOmnibus:                        2.988   Durbin-Watson:                   1.252\nProb(Omnibus):                  0.225   Jarque-Bera (JB):                2.399\nSkew:                           0.668   Prob(JB):                        0.301\nKurtosis:                       2.877   Cond. No.                         12.7\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n在 mtcars = sm.datasets.get_rdataset('mtcars', 'datasets').data 这条语句中，呈现出 sm.A.B().C 的形式。初学者不免产生如下疑问：\n同样令人费解的语句还有 model1 = sm.OLS(y, X1).fit()。\n上述问题其实是近两年 Python 学习者普遍面临的困惑。有了 AI 助手（如豆包、Copilot 等），很多人得以快速上手 Python。但好景不长，大家很快就会遭遇瓶颈。面对 AI 自动生成的代码，自己往往一知半解，基本不具备调试和修改代码的能力。这就导致在使用 Python 一段时间后，自身编写代码的能力始终难以显著提升，还总是花费大量时间进行调试，从而无法集中精力思考更高级的问题。\n为此，本文将详细介绍 Python 面向对象编程的核心概念，帮你深入理解 Python 代码的逻辑和结构关系，进而提升编写 Python 代码的能力。接下来，我们就将逐步解答上述代码中的疑问。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#简介",
    "href": "body/01_py_01_basic_05_OOP.html#简介",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "",
    "text": "这里面哪些是函数 (function)？\n哪些是方法 (method)？\n哪些又是对象的属性呢？\n需要学习哪些概念才能搞清楚这些语句的编写规则？",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#类-v.s-对象直观解释",
    "href": "body/01_py_01_basic_05_OOP.html#类-v.s-对象直观解释",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "14.2 类 v.s 对象：直观解释",
    "text": "14.2 类 v.s 对象：直观解释\n\n解读 1 - 填写表格：空白表是「类」，填好的表式「对象 (实例)」\n\n我们经常需要填写纸质或电子表格：去医院看病、网上购物、或者参加婚礼需要回复 RSVP。表格就是一种标准化的方式，方便他人或机构收集你的信息。不同的表格关注的信息各不相同：你会在医生的表格上填写敏感的健康状况，而婚礼邀请回复表格则关注你会带几位嘉宾 —— 这两种信息互不相干。\n在 Python 中，class（类）、type（类型）、data type（数据类型）这些术语基本等价。可以按照如下逻辑来理解：\n\n可以把类看作是 Python 对象（也称为「实例」）的模板 (blueprint)；\n对象则是具体的数据实体，代表某个「名词」（可以是医院里的病人、网上的购物订单、婚礼的嘉宾等等）。\n类就像是一张空白表格模板，而对象就是基于这个模板，实际填写了数据的具体表格。\n\n比如，下图中的 RSVP 回复表格就是类的一个例子，而具体填写好的 RSVP 回执，就是一个对象：\n\nSource：15 Object-Oriented Programming and Classes\n \n\n另一种类比：电子表格（Excel）\n\n你还可以把类和对象类比为电子表格（比如 Excel），如下图所示。表格的列名就类似于类（定义了每个属性），而表格的每一行就相当于一个具体对象（包含具体的数据）。\n\n下面，我们做详细介绍。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#类对象封装继承和多态",
    "href": "body/01_py_01_basic_05_OOP.html#类对象封装继承和多态",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "14.3 类、对象、封装、继承和多态",
    "text": "14.3 类、对象、封装、继承和多态\n\n14.3.1 类（Class）\n类是对象的模板，它定义了对象的属性和方法，可将其视为一种自定义的数据类型。以 Person 类为例：\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def introduce(self):\n        print(f\"我叫 {self.name}，今年 {self.age} 岁。\")\n        \n\nPerson 类包含两个函数，分别是 __init__() 和 introduce()。前者用于定义「对象的属性」，后者用于定义「对象的方法」。具体说明如下：\n\n__init__() 是一个特殊的函数，称为「构造函数」。它的作用是在创建类的对象时，初始化 对象的属性。在这个例子里，__init__() 定义了 Person 类的两个属性，即 name 和 age。\nintroduce() 函数定义了 Person 类的一个方法，其功能是打印出对象的 name 和 age 信息。\n\n这里要着重说明一下 self 这个参数。在 Python 的类中，self 是一个约定俗成的参数名，它代表类的实例对象本身。当你调用类的方法时，Python 会自动将调用该方法的对象作为第一个参数传递给 self。借助 self，方法能够访问和修改对象的属性。\n例如，在 __init__() 方法里，self.name = name 这一操作把传入的 name 参数值赋给了对象的 name 属性；在 introduce() 方法中，self.name 和 self.age 用于获取对象的 name 和 age 属性值。\n\n\n14.3.2 对象（Object）\n对象是类的实例。通过类能够创建多个不同的对象，每个对象都有自己独立的属性值。例如：\n\np1 = Person(\"张三\", 20)\np2 = Person(\"李四\", 25)\n\nprint(p1.name)  # 输出: 张三\nprint(p2.name)  # 输出: 李四\n\np1.introduce()  # 输出: 我叫 张三，今年 20 岁。\np2.introduce()  # 输出: 我叫 李四，今年 25 岁。\n\n张三\n李四\n我叫 张三，今年 20 岁。\n我叫 李四，今年 25 岁。\n\n\n此例中，p1 和 p2 是 Person 类的两个不同对象。p1.name 的值是 “张三”，p2.name 的值是 “李四”，这体现了不同对象的属性可以有不同的值。\n\n\n14.3.3 封装（Encapsulation）\n封装是面向对象编程的一个重要特性，它指的是将数据（属性）和操作数据的方法捆绑在一起，并且对外部隐藏对象的内部实现细节。封装的作用主要体现在以下几个方面：\n\n数据保护：防止外部代码直接访问和修改对象的属性，从而避免数据被意外修改或破坏。\n简化接口：只向外部暴露必要的方法，隐藏内部实现细节，降低外部代码与对象之间的耦合度，使代码更易于维护和扩展。\n\n在 Python 中，可以通过访问控制来实现封装。虽然 Python 没有像其他语言那样严格的访问修饰符（如 private、protected），但可以通过约定来表示属性或方法的访问级别。以单下划线开头的属性或方法被视为受保护的，以双下划线开头的属性或方法被视为私有的。例如：\n\nclass BankAccount:\n    def __init__(self, balance):\n        self.__balance = balance\n\n    def deposit(self, amount):\n        self.__balance += amount\n\n    def withdraw(self, amount):\n        if amount &lt;= self.__balance:\n            self.__balance -= amount\n        else:\n            print(\"余额不足\")\n\n    def get_balance(self):\n        return self.__balance\n\naccount = BankAccount(1000)\naccount.deposit(500)\naccount.withdraw(200)\nprint(account.get_balance())  # 输出: 1300\n\n1300\n\n\n在这个例子中，__balance 是一个私有属性，外部不能直接访问，只能通过 deposit、withdraw 和 get_balance 等方法来操作。这样就保证了账户余额的安全性，外部代码无法随意修改余额。\n\n\n14.3.4 4. 继承（Inheritance）\n继承是指一个类可以继承另一个类的属性和方法。被继承的类称为父类（基类），继承的类称为子类（派生类）。子类可以扩展父类的功能，也可以重写父类的方法。例如：\n\nclass Student(Person):\n    def __init__(self, name, age, student_id):\n        super().__init__(name, age)\n        self.student_id = student_id\n\n    def study(self):\n        print(f\"{self.name} 正在学习。\")\n\nstu = Student(\"王五\", 18, \"001\")\nstu.introduce() \nstu.study()    \n\n我叫 王五，今年 18 岁。\n王五 正在学习。\n\n\n在这个例子中，Student 类继承了 Person 类的属性和方法，并添加了自己的属性 student_id 和方法 study。super().__init__(name, age) 调用了父类的构造函数，对 name 和 age 属性进行初始化。\n\n\n14.3.5 多态（Polymorphism）\n多态是指不同的对象可以对同一个操作做出不同的响应。下面通过几个例子来帮助你理解多态的概念和应用。\n\n14.3.5.1 简单数据类型示例\na = 5\nb = \"apple\"\nprint(a * 3)  # 输出: 15\nprint(b * 3)  # 输出: appleappleapple\n可见，* 运算符对于整数 a 和字符串 b 有不同的行为：\n\n对于整数，* 表示乘法运算；\n对于字符串，* 表示重复字符串。\n\n这就是多态的体现，同一个运算符在不同的数据类型上有不同的操作。\n\n\n14.3.5.2 类的方法重写示例\n\n\nclass Shape:\n    def area(self):\n        pass\n\nclass Rectangle(Shape):\n    def __init__(self, length, width):\n        self.length = length\n        self.width = width\n\n    def area(self):\n        return self.length * self.width\n\nclass Circle(Shape):\n    def __init__(self, radius):\n        self.radius = radius\n\n    def area(self):\n        return 3.14 * self.radius * self.radius\n\nshapes = [Rectangle(4, 5), Circle(3)]\nfor shape in shapes:\n    print(shape.area())\n\n20\n28.259999999999998\n\n\n在这个例子中，Rectangle 和 Circle 类都继承自 Shape 类，并且重写了 area 方法。当我们遍历 shapes 列表并调用每个对象的 area 方法时，不同的对象会根据自己的实现方式计算并返回面积，这也是多态的应用。\n\n\n14.3.5.3 Python 支持多态的原因\nPython 能够支持多态，主要得益于其动态类型的特性。在 Python 中，变量在声明时不需要预先指定数据类型，变量的类型是在运行时动态确定的。这意味着一个变量可以在不同的时刻引用不同类型的对象。当调用一个函数或方法时，Python 不会关心对象的具体类型，只要对象实现了所需的方法或属性，就可以正常调用。\n这种特性使得 Python 代码更加灵活，能够轻松实现多态。例如，在上面的 shapes 列表中，Rectangle 和 Circle 对象虽然类型不同，但都实现了 area 方法，因此可以统一调用 area 方法来计算面积。\n\n\n\n14.3.6 面向对象概念在具体包和函数中的应用\n在实际的 Python 编程中，面向对象编程的概念广泛应用于各种包和函数中。下面以 pandas 和 matplotlib 这两个常用的包为例进行说明。\n\n14.3.6.1 pandas 中的应用\npandas 是一个用于数据处理和分析的强大包，其中大量使用了类和对象的概念。例如，DataFrame 是 pandas 中最常用的类之一，用于表示二维表格数据。\n\nimport pandas as pd\n\n# 创建一个 DataFrame 对象\ndata = {\n    'Name': ['张三', '李四', '王五'],\n    'Age': [20, 25, 18]\n}\ndf = pd.DataFrame(data)\n\n# 使用 DataFrame 的方法\nprint(df.head())      # 查看数据集行数\nprint('-' * 20)\nprint(df.describe().T.round(2))  # T 表示转置\n\n  Name  Age\n0   张三   20\n1   李四   25\n2   王五   18\n--------------------\n     count  mean   std   min   25%   50%   75%   max\nAge    3.0  21.0  3.61  18.0  19.0  20.0  22.5  25.0\n\n\n此例中，pd.DataFrame 是一个类，df 是 DataFrame 类的一个对象。\n我们可以调用 df 对象的各种方法，如 head() 和 describe()，来对数据进行操作和分析。甚至可以采用链式调用的方式来连续执行多个操作，如 df.describe().T.round(2) 表示对 df 对象依次进行如下操作：计算基本统计量 → 转置 → 四舍五入 (保留两位有效数字)。\n\n\n14.3.6.2 matplotlib 中的应用\nmatplotlib 是一个用于数据可视化的包，也广泛应用了面向对象编程的思想。例如，我们可以使用 Figure 和 Axes 类来创建和定制图形。\n\nimport matplotlib.pyplot as plt\n\n# 创建一个 Figure 对象和一个 Axes 对象\nfig, ax = plt.subplots(figsize=(2, 2))\n\n# 绘制数据\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 6, 8, 10]\nax.plot(x, y)\n\n# 设置图形属性\nax.set_title('line plot')\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n在这个例子中，fig 是 Figure 类的对象，ax 是 Axes 类的对象。\n我们可以通过调用 ax 对象的方法，如 plot()、set_title()、set_xlabel() 和 set_ylabel() 来绘制和定制图形。这体现了面向对象编程在 matplotlib 中的应用，通过将图形的不同部分封装成对象，使得图形的创建和定制更加灵活和可控。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#包函数方法和属性",
    "href": "body/01_py_01_basic_05_OOP.html#包函数方法和属性",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "14.4 包、函数、方法和属性",
    "text": "14.4 包、函数、方法和属性\n我们先简要介绍一下理解复杂语句所需的基础概念。\n\n14.4.1 包（Package）和模块（Module）\n\n14.4.1.1 模块（Module）\n\n模块是单个 .py 文件，包含函数、类、变量等代码。\n例如：\n\narrow.api.py 是一个模块，包含 get() 函数。\nnumpy.random.py 也是一个模块，内含若干个用于生成随机数的函数。\n\n\n\n\n14.4.1.2 包（Package）\n包是一个包含多个模块的目录，通常还包含一个 __init__.py 文件。\n一个包中可以包含多个子包，而每个包中又可以包含多个模块。包的目录结构类似于文件系统的目录结构。__init__.py 文件的作用是标识该目录是一个包，更重要的是，它详细记录了这个包里都有哪些模块和子包。\n包通过目录结构组织代码，例如：\npandas/               # 根包\n  __init__.py         # 标识这是一个包\n  core/               # 子包\n    __init__.py\n    frame.py          # 模块（定义 DataFrame）\n    series.py         # 模块（定义 Series）\n  io/                 # 子包\n    __init__.py\n    excel.py          # 模块（处理 Excel 文件）\n比如，arrow 是一个用于处理日期和时间的包，该包的程序文件存放于 arrow 目录下：\n\n其中包含 __init__.py 文件和其他模块文件（如 arrow.py、util.py 等）。当你使用 import arrow 时，Python 会自动执行 __init__.py 文件中的代码，从而初始化包的命名空间。\n你若执行 from arrow import api，则会导入 arrow 包中的 api 模块。然后你可以使用 api 模块中的函数和类，例如 api.get()。\n\nimport arrow as ar\n\n# 查看 arrow 的类型\nprint(type(ar)) \n\n# 查看 arrow 的路径\nprint(ar.__file__)  \n\n# 输出类似：/path/to/site-packages/arrow/__init__.py\n# 这表明 arrow 是包含多个子包的根目录。\n\n&lt;class 'module'&gt;\nc:\\ProgramData\\anaconda3\\Lib\\site-packages\\arrow\\__init__.py\n\n\n同理，你可以使用如下方法查看其他包的路径：\n\nimport pandas as pd\nprint(pd.__file__)  # 查看 pandas 的路径\n\nc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\n\n\n\n\n\n14.4.2 函数（Function）和方法（Method）\n函数是一段完成特定任务的独立代码块，可以直接调用。而方法是与对象关联的函数，必须通过对象来调用。例如，\n\n在 sm.datasets.get_rdataset() 中，get_rdataset() 是一个函数，它属于 statsmodels 包中 datasets 模块。\n在 model1 = sm.OLS(y, X1).fit() 中：\n\nOLS() 是 sm 包中的一个函数，用于创建一个普通最小二乘回归模型对象。\nsm.OLS(y, X1) 创建了一个 OLS 对象。\n\nfit() 是 sm.OLS(y, X1) 创建的对象的方法。\n\n\n\n\n14.4.2.1 类中的属性（Attribute）和方法（Method）\n属性 是类或对象的数据成员，而 方法 则是类或对象的函数成员。\n因此，在 mtcars = sm.datasets.get_rdataset('mtcars', 'datasets').data 中，.data 就是 get_rdataset() 函数返回的对象的一个属性，里面存储着对象里的数据。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#解析复杂语句",
    "href": "body/01_py_01_basic_05_OOP.html#解析复杂语句",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "14.5 解析复杂语句",
    "text": "14.5 解析复杂语句\n现在我们来详细解析引言中提到的复杂语句：\nimport statsmodels.api as sm\n\n# 加载示例数据\nmtcars = sm.datasets.get_rdataset('mtcars', 'datasets').data\nmtcars.head()\n具体解释如下：\n\nsm 是 statsmodels.api 模块的别名。\ndatasets 是 sm 下的一个子模块，专门用于访问内置或外部数据集。\nget_rdataset('mtcars', 'datasets') 是 datasets 子模块中的一个函数，用于从 R 的数据集仓库中的 datasets 包中获取名为 'mtcars' 的数据集。这个函数会返回一个包含数据集及其元信息 (meta information) 的对象 (可以假想为名称为 mtcars_object 的对象)。\n.data 是对象 mtcars_object 的一个属性，用于提取实际的数据内容（通常为一个 pandas.DataFrame）。\n因此，最终得到的 mtcars 变量就是一个 pandas.DataFrame 对象，包含了 'mtcars' 数据集的实际数据。\nmtcars.head() 是 pandas.DataFrame 对象的方法，用于查看数据集的前几行数据。\n\n需要注意的是，在上述语句中，datasets 这个关键词出现了两次，两者含义不同，不要混淆：\n\n第一次是指 sm 下的 datasets 子模块；\n第二次是作为参数传递给 get_rdataset() 函数，它是 R 语言中的一个扩展包的名称，而 mtcars 则是 datasets 包中的一个数据集。\n\n把上述代码拆成两行更有助于理解 模块、函数 和 属性 这三个概念的区别：\nimport statsmodels.api as sm\n\n# 获取数据集对象：'object = 模块.函数()' 格式\n#        本例中：'object = 模块.子模块.函数(参数1, 参数2)' 格式\nmtcars_object = sm.datasets.get_rdataset('mtcars', 'datasets') \n\n# 获取数据集内容：'object.属性' 格式\nmtcars_df = mtcars_object.data \n可以将这行代码拆解为以下几步，更便于初学者理解：\n# 第一步：获取 datasets 子模块\ndatasets_module = sm.datasets\n\n# 第二步：调用 get_rdataset 函数获取数据集对象\nrdataset = datasets_module.get_rdataset('mtcars', 'datasets')\n  # - 'mtcars' 是数据集的名称\n  # - 'datasets' 是数据集所在的包名\n# 第三步：通过 data 属性获取实际的数据\nmtcars = rdataset.data\n至此，代码的第二部分也很容易理解了：\n# 模型 1\nX1 = data[['weight']]\nX1 = sm.add_constant(X1)\ny = data['mpg']\nmodel1 = sm.OLS(y, X1).fit()\n解释如下：\n\nsm.OLS(y, X1)：\n\nOLS 是 statsmodels.api 模块中的一个类，用于创建一个普通最小二乘回归模型的对象。这里传入的参数 y 是因变量，X1 是自变量。\n\n.fit()：是 sm.OLS(y, X1) 创建的对象的方法，用于拟合模型，即根据输入的数据计算模型的参数。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#参考资料",
    "href": "body/01_py_01_basic_05_OOP.html#参考资料",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "14.6 参考资料",
    "text": "14.6 参考资料\n\nPython 100 Days - 18.面向对象编程入门",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_05_OOP.html#总结",
    "href": "body/01_py_01_basic_05_OOP.html#总结",
    "title": "14  Python：语法解析-面向对象编程",
    "section": "14.7 总结",
    "text": "14.7 总结\n\n模块是单个 .py 文件，包含函数、类、变量等代码。\n包是一个包含多个模块的目录，通常还包含一个 __init__.py 文件。\n类是对象的模板，它定义了对象的属性和方法。\n对象是类的实例。通过类能够创建多个不同的对象，每个对象都有自己独立的属性值。\n封装是将数据（属性）和操作数据的方法捆绑在一起，并对外部隐藏对象的内部实现细节。\n继承是一个类可以继承另一个类的属性和方法。\n多态是指不同的对象可以对同一个操作做出不同的响应。\n函数是一段完成特定任务的独立代码块，可以直接调用。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Python：语法解析-面向对象编程</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html",
    "href": "body/01_py_01_basic_06_filepath.html",
    "title": "15  Python 路径设置",
    "section": "",
    "text": "15.1 路径的基本类型\n在 Python 数据分析和科学计算项目中，文件路径的设置是最容易被初学者忽视但又至关重要的一个环节。路径的写法直接关系到数据能否顺利读取、结果能否正确保存、代码能否方便迁移和团队协作。\n假设有如下常见的项目结构：",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html#路径的基本类型",
    "href": "body/01_py_01_basic_06_filepath.html#路径的基本类型",
    "title": "15  Python 路径设置",
    "section": "",
    "text": "绝对路径 直接写明从磁盘根目录开始的完整路径，如 C:/Users/lian/project/data/train.csv。优点是直观，缺点是只能在自己的电脑上用，可移植性很差。\n相对路径 以「当前工作目录」为起点的路径，写法更灵活，比如 data/train.csv、./data/train.csv 或 ../data/train.csv。团队协作和跨平台推荐使用相对路径。\n\n\n15.1.1 路径中的常用符号\n\n. 表示当前目录\n.. 表示上一级目录\n/ 是路径分隔符，推荐在所有平台上都用 /（Windows 也支持）\n\n\n\n15.1.2 当前工作目录\nPython 在读取文件时，所有相对路径都是以当前工作目录为基准。 你可以用如下代码查看：\nimport os\nprint(os.getcwd())\n如果你在 project/ 目录下打开并运行 .ipynb 或 .py 文件，那么：\n\ndata/train.csv\n./data/train.csv\n\n这两种写法都表示访问 project/data/ 目录下的 train.csv 文件。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html#子目录和上级目录的写法",
    "href": "body/01_py_01_basic_06_filepath.html#子目录和上级目录的写法",
    "title": "15  Python 路径设置",
    "section": "15.2 子目录和上级目录的写法",
    "text": "15.2 子目录和上级目录的写法\n如果你在 scripts/02_regress.ipynb 中想读取 data/train.csv：\n\n路径写法应为 ../data/train.csv 表示从 scripts/ 目录返回上一层（即 project/），再进入 data/。\n\n例子：\nimport pandas as pd\ndf = pd.read_csv('../data/train.csv')\n如果在 project/ 目录下运行 01_data_clean.ipynb：\ndf = pd.read_csv('data/train.csv')",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html#路径设置方法",
    "href": "body/01_py_01_basic_06_filepath.html#路径设置方法",
    "title": "15  Python 路径设置",
    "section": "15.3 路径设置方法",
    "text": "15.3 路径设置方法\n基本原则\n\n使用相对路径，并以项目主目录作为入口，这样团队成员和后续自动化运行都不会因路径错乱而报错。\n不要随意修改当前工作目录，如果确实需要，可以用 os.chdir()，但推荐只在顶层脚本中使用。\n建议统一用 / 做路径分隔符，避免不同操作系统兼容性问题。\n\n\n15.3.1 动态拼接路径的安全写法\nPython 推荐用 os.path.join() 或 pathlib.Path 自动拼接路径，增强可移植性：\nimport os\npath = os.path.join('data', 'train.csv')\n或用 pathlib：\nfrom pathlib import Path\npath = Path('data') / 'train.csv'\n\n\n15.3.2 Jupyter Notebook、VS Code 下的路径问题\n\nJupyter Notebook 的当前工作目录一般为你启动 Notebook 时所在的文件夹。\nVS Code 运行时，也以「打开文件夹」为当前工作目录。\n路径错误时优先检查 os.getcwd() 输出。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html#应用",
    "href": "body/01_py_01_basic_06_filepath.html#应用",
    "title": "15  Python 路径设置",
    "section": "15.4 应用",
    "text": "15.4 应用\n\n15.4.1 批量读取目录下文件\n如果要读取 data/ 目录下所有 csv 文件：\nimport glob\nfiles = glob.glob('data/*.csv')\nfor f in files:\n    print(f)\n\n\n15.4.2 数据导入与结果保存范例\nimport pandas as pd\ndf = pd.read_csv('data/train.csv')          # 项目主目录下执行\ndf = pd.read_csv('../data/train.csv')       # scripts 子目录下执行\n\n# 保存分析结果到 output 文件夹\ndf.to_csv('output/result.csv', index=False)",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html#路径设置最佳实践",
    "href": "body/01_py_01_basic_06_filepath.html#路径设置最佳实践",
    "title": "15  Python 路径设置",
    "section": "15.5 路径设置最佳实践",
    "text": "15.5 路径设置最佳实践\n\n明确项目目录结构，所有数据、脚本、输出分目录管理。\n路径全部写成相对路径，推荐以项目主目录为基准。\n多人协作时保证路径一致，避免硬编码本地绝对路径。\n重要脚本和 Notebook 开头加一句 print(os.getcwd())，方便调试和定位路径问题。\n文件找不到，多半是路径写错或者工作目录理解有误。 用 os.getcwd() 确认，再对照实际项目结构检查路径。\n不同系统分隔符问题，统一用 /，或用路径拼接函数自动处理。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_01_basic_06_filepath.html#参考资料",
    "href": "body/01_py_01_basic_06_filepath.html#参考资料",
    "title": "15  Python 路径设置",
    "section": "15.6 参考资料",
    "text": "15.6 参考资料\n\nPython 官方文档：os.path\npathlib 标准库文档\npandas IO：数据读写",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Python 路径设置</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_numpy_scipy.html",
    "href": "body/01_py_02_numpy_scipy.html",
    "title": "16  NumPy",
    "section": "",
    "text": "16.1 向量、矩阵及其运算\n数值计算是科学研究领域使用最多的编程功能。虽然Python自带了一些基本的数学函数以及列表、元组等数据结构，然而并没有对向量运算的天然支持，因而我们需要NumPy这个包来支持Python中的向量运算。\nNumPy提供了丰富的数值计算方法，由于篇幅所限，我们无法介绍所有的NumPy特性，更多的参考可以从NumPy（包括SciPy）的网站： https://docs.scipy.org/doc/ 找到更加详细的参考。\nNumPy最核心的是提供了向量和矩阵两个数据结构，可以方便的使用这些数据结构进行向量的加、减、数乘，以及矩阵的加、减、数乘、乘法、求逆、矩阵分解等运算。\n在Python中，如果需要使用NumPy，首先要使用pip安装numpy，接着在文件中导入numpy。numpy.array()函数提供了将一个列表转化为一个向量的方法，比如：\nimport numpy as np\n\na=np.array([1,2,3]) #创建一个三维向量\nprint('向量a=',a)\n\n向量a= [1 2 3]\n此外，还有一些其他的方法创建向量，比如：\nb=np.ones(3) #创建一个元素全为1的向量\nprint('b=',b)\nb0=np.zeros(3) #创建一个元素全为0的向量\nprint('b0=',b0)\n\nb= [ 1.  1.  1.]\nb0= [ 0.  0.  0.]\n还有一个更加常用的函数:linespace(n1,n2,N)，该函数创建从n1到n2区间平均分为N等份的网格点：\nlp = np.linspace(0, 5, 20)   # 0 到 5 等分 20 等分\nprint(\"0 到 5 等分 20 等分：\\n\",lp)\n\n0到5等分20等分：\n [ 0.          0.26315789  0.52631579  0.78947368  1.05263158  1.31578947\n  1.57894737  1.84210526  2.10526316  2.36842105  2.63157895  2.89473684\n  3.15789474  3.42105263  3.68421053  3.94736842  4.21052632  4.47368421\n  4.73684211  5.        ]\nNumPy支持很多向量运算，比如：\nprint(\"基本数学运算：元素对元素运算\")\nprint('数乘：3*a=',3*a)\nprint('a-b=',a-b)\nprint('a+b=',a+b)\nprint('a*b=',a*b)\nprint('b/a=',b/a)\nprint('向量运算')\nc=np.dot(a,b) #a.*b\nprint('点乘（内积）a.*b=',c)\nd=np.outer(a,b)\nprint('外积(a,b)=\\n',d)\n\n基本数学运算：元素对元素运算\n数乘：3*a= [3 6 9]\na-b= [ 0.  1.  2.]\na+b= [ 2.  3.  4.]\na*b= [ 1.  2.  3.]\nb/a= [ 1.          0.5         0.33333333]\n向量运算\n点乘（内积）a.*b= 6.0\n外积(a,b)=\n [[ 1.  1.  1.]\n [ 2.  2.  2.]\n [ 3.  3.  3.]]\n这里要特别特别注意的是，向量的乘法*和除法定义的是元素对元素的乘除法，这点与MATLAB等有很大不同。\n除了可以使用numpy.array()创建向量，也可以创建矩阵，创建矩阵时，提供一个列表的列表，每个列表代表矩阵中的一行：\nA=np.array([[1,2,3],[4,8,6],[4,3,2]])\nprint(\"矩阵A=\\n\",A)\n\n矩阵A=\n [[1 2 3]\n [4 8 6]\n [4 3 2]]\n以及一些特殊矩阵：\nM=np.zeros((3,3)) #全为0的矩阵\nprint(\"矩阵M=\\n\",M)\nO=np.ones((3,3)) #全为1的矩阵\nprint(\"矩阵O=\\n\",O)\nI=np.eye(3) #单位阵\nprint(\"矩阵I=\\n\",I)\n\n矩阵M=\n [[ 0.  0.  0.]\n [ 0.  0.  0.]\n [ 0.  0.  0.]]\n矩阵O=\n [[ 1.  1.  1.]\n [ 1.  1.  1.]\n [ 1.  1.  1.]]\n矩阵I=\n [[ 1.  0.  0.]\n [ 0.  1.  0.]\n [ 0.  0.  1.]]\n以及一些矩阵的运算：\nprint(\"A+I=\\n\",A+I)\nprint(\"A-I=\\n\",A-I)\nprint(\"A*I=\\n\",A*I)\nprint(\"I/A=\\n\",I/A)\nprint(\"矩阵相乘，A*O=\\n\", np.dot(A,O))\nprint(\"矩阵相乘，O*A=\\n\", np.dot(O,A))\nprint(\"矩阵转置，tranpose(A)=\\n\", A.transpose())\nprint(\"矩阵的逆，inv(A)=\\n\", np.linalg.inv(A))\nl,L=np.linalg.eig(A)\nprint(\"矩阵的特征值=\\n\", l)\nprint(\"矩阵的特征向量=\\n\", L)\n\nA+I=\n [[ 2.  2.  3.]\n [ 4.  9.  6.]\n [ 4.  3.  3.]]\nA-I=\n [[ 0.  2.  3.]\n [ 4.  7.  6.]\n [ 4.  3.  1.]]\nA*I=\n [[ 1.  0.  0.]\n [ 0.  8.  0.]\n [ 0.  0.  2.]]\nI/A=\n [[ 1.     0.     0.   ]\n [ 0.     0.125  0.   ]\n [ 0.     0.     0.5  ]]\n矩阵相乘，A*O=\n [[  6.   6.   6.]\n [ 18.  18.  18.]\n [  9.   9.   9.]]\n矩阵相乘，O*A=\n [[  9.  13.  11.]\n [  9.  13.  11.]\n [  9.  13.  11.]]\n矩阵转置，tranpose(A)=\n [[1 4 4]\n [2 8 3]\n [3 6 2]]\n矩阵的逆，inv(A)=\n [[ 0.06666667 -0.16666667  0.4       ]\n [-0.53333333  0.33333333 -0.2       ]\n [ 0.66666667 -0.16666667  0.        ]]\n矩阵的特征值=\n [ 11.80142315  -2.04468118   1.24325803]\n矩阵的特征向量=\n [[ 0.26952559  0.61195333  0.44683972]\n [ 0.88453378  0.21152352 -0.72721843]\n [ 0.3807308  -0.76208328  0.52104474]]\n同样，乘法*和除法定义的是元素对元素的乘除法，切记！\n如果需要提取出矩阵的元素，可以使用 A[row,col]（而非A[row][col]！！）。\n此外，数组和矩阵都支持切片操作。比如，如果希望提取出矩阵A的奇数行、奇数列，可以用：\nprint(\"A的奇数行、奇数列=\\n\", A[::2,::2])\n\nA的奇数行、奇数列=\n [[1 3]\n [4 2]]\n另外，这里与Python中的另外一个不同是，在Python的列表中，实行切片操作是直接对切片出的元素进行复制，而在NumPy中，切片操作只是一个视图（view），并没有进行复制。理解这一点是非常关键的，比如：\nlista=[1,2,3,4]\nsuba=lista[1:3]\nsuba[0]=1\nprint(lista)\nprint(suba)\nveca=np.array([1,2,3,4])\nsuba=veca[1:3]\nsuba[0]=1\nprint(veca)\nprint(suba)\n\n[1, 2, 3, 4]\n[1, 3]\n[1 1 3 4]\n[1 3]\n因而，在对数组、矩阵进行切片、修改时，需要特别注意。\n如果需要创建切片的副本，需要用copy()方法：\nveca=np.array([1,2,3,4])\nsuba=veca[1:3].copy()\nsuba[0]=1\nprint(veca)\nprint(suba)\n\n[1 2 3 4]\n[1 3]\n可以发现原始向量并没有被改变。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_numpy_scipy.html#向量矩阵的变形合并和分裂",
    "href": "body/01_py_02_numpy_scipy.html#向量矩阵的变形合并和分裂",
    "title": "16  NumPy",
    "section": "16.2 向量、矩阵的变形、合并和分裂",
    "text": "16.2 向量、矩阵的变形、合并和分裂\n对于向量、矩阵的另外一个更常用的操作是变形，比如，我们可能将一个向量变形为一个矩阵，可以按照如下的方法：\n\nvec_a=np.linspace(0,8,9)\nprint(\"vec_a:\\n\",vec_a)\nmat_a=vec_a.reshape(3,3)\nprint(\"mat_a:\\n\",mat_a)\nvec_b=vec_a.reshape(9,1)\nprint(\"vec_b:\\n\",vec_b)\n\nvec_a:\n [ 0.  1.  2.  3.  4.  5.  6.  7.  8.]\nmat_a:\n [[ 0.  1.  2.]\n [ 3.  4.  5.]\n [ 6.  7.  8.]]\nvec_b:\n [[ 0.]\n [ 1.]\n [ 2.]\n [ 3.]\n [ 4.]\n [ 5.]\n [ 6.]\n [ 7.]\n [ 8.]]\n\n\n实际上，我们可以通过向量或者矩阵的ndim属性查看其维度：\n\nprint(\"Dimension of vec_a:%2d\" % vec_a.ndim)\nprint(\"Dimension of vec_b:%2d\" % vec_b.ndim)\nprint(\"Dimension of mat_a:%2d\" % mat_a.ndim)\n\nDimension of vec_a: 1\nDimension of vec_b: 2\nDimension of mat_a: 2\n\n\n可见，vec_b作为列向量，在NumPy中实际上看成时一个矩阵。如果要看其维数，需要用shape属性：\n\nprint(\"Dimension of vec_a:%2d\" % vec_a.shape)\nprint(\"Dimension of vec_b:%2d ×%2d\" % vec_b.shape)\nprint(\"Dimension of mat_a:%2d ×%2d\" % mat_a.shape)\n\nDimension of vec_a: 9\nDimension of vec_b: 9 × 1\nDimension of mat_a: 3 × 3\n\n\n也可以只用size属性查看其大小：\n\nprint(\"Dimension of vec_a:%2d\" % vec_a.size)\nprint(\"Dimension of vec_b:%2d\" % vec_b.size)\nprint(\"Dimension of mat_a:%2d\" % mat_a.size)\n\nDimension of vec_a: 9\nDimension of vec_b: 9\nDimension of mat_a: 9\n\n\n此外，有时我们还需要拼接两个矩阵，此时需要使用np.concatenate、np.vstack、np.hstack三个方法。\nnp.concatenate方法用于拼接向量，比如：\n\na=np.array([1,2,3])\nb=np.array([4,5])\nc=np.array([6,7,8,9])\nvec=np.concatenate([a,b,c])\nprint(vec)\n\n[1 2 3 4 5 6 7 8 9]\n\n\nnp.vstack用于竖直拼接矩阵，hstack用于水平拼接举着，比如：\n\nmat_a=np.linspace(0,8,9).reshape(3,3)\nmat_b=np.linspace(10,18,9).reshape(3,3)\nprint(\"mat_a:\\n\",mat_a)\nprint(\"mat_b:\\n\",mat_b)\nmat_hab=np.hstack([mat_a,mat_b])\nprint(\"mat_hab:\\n\",mat_hab)\nmat_vab=np.vstack([mat_a,mat_b])\nprint(\"mat_hab:\\n\",mat_vab)\n\nmat_a:\n [[ 0.  1.  2.]\n [ 3.  4.  5.]\n [ 6.  7.  8.]]\nmat_b:\n [[ 10.  11.  12.]\n [ 13.  14.  15.]\n [ 16.  17.  18.]]\nmat_hab:\n [[  0.   1.   2.  10.  11.  12.]\n [  3.   4.   5.  13.  14.  15.]\n [  6.   7.   8.  16.  17.  18.]]\nmat_hab:\n [[  0.   1.   2.]\n [  3.   4.   5.]\n [  6.   7.   8.]\n [ 10.  11.  12.]\n [ 13.  14.  15.]\n [ 16.  17.  18.]]",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_numpy_scipy.html#随机数生成",
    "href": "body/01_py_02_numpy_scipy.html#随机数生成",
    "title": "16  NumPy",
    "section": "16.3 随机数生成",
    "text": "16.3 随机数生成\n科学计算中很多算法都依赖于随机数的生成，比如数值积分计算的Monte Carlo法、MCMC等方法。在Python中，自带了numpy.random包，可以用来生成随机数。\n为了使用numpy.random，必须先导入：\nimport numpy.random as nprd\n接下来，就可以直接使用了。比如，\n\nnprd.random(n) 产生一个 n 维向量，每个分量都服从均匀分布的随机数；\nnprd.randn(n) 产生一个 n 维向量，每个分量都服从正态分布的随机数；\nnprd.choice(a) 从向量 a 中随机抽取一个元素\n\n……\n具体随机数列表可以查看 numpy - random number。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_numpy_scipy.html#向量函数",
    "href": "body/01_py_02_numpy_scipy.html#向量函数",
    "title": "16  NumPy",
    "section": "16.4 向量函数",
    "text": "16.4 向量函数\n在此之前，我们曾经介绍过使用 Python 中自带的 math.exp()、math.sin()、math.cos() 等函数。现在想象以下，为了计算一个向量每个分量的指数函数，我们不得不写一个循环：\n\nimport math\na=np.array([1,2,3])\nb=np.array([math.exp(i) for i in a])\nprint(b)\n\n[  2.71828183   7.3890561   20.08553692]\n\n\n然而，Python 的循环非常的缓慢，如果数据量巨大，以上做法非常耗时。幸运的是，NumPy 为我们提供了非常强大的函数功能，比如：\n\na=np.array([1,0.5,3])\nprint('a=',a)\nprint('cos(a)=',np.cos(a))\nprint('exp(a)=',np.exp(a))\nprint('ln(a)=',np.log(a))\nprint('abs(a)=',np.abs(a))\n\na= [ 1.   0.5  3. ]\ncos(a)= [ 0.54030231  0.87758256 -0.9899925 ]\nexp(a)= [  2.71828183   1.64872127  20.08553692]\nln(a)= [ 0.         -0.69314718  1.09861229]\nabs(a)= [ 1.   0.5  3. ]\n\n\n函数列表可以从 Universal functions (ufunc) 中找到。\n此外，NumPy 还提供了方便的数据加总函数，比如求和、平均数、最大值、最小值、中位数等。\n比如，以下代码中，我们随机产生了一组正态分布的数据，并计算了其和和、平均数、最大值、最小值、中位数、四分位数：\n\nimport numpy as np\nimport numpy.random as nprd\n\na = nprd.randn(1000)\n\nprint(\"%-10s：%10.4f\" % (\"和\", np.sum(a)))\nprint(\"%-10s：%10.4f\" % (\"均值\", np.mean(a)))\nprint(\"%-10s：%10.4f\" % (\"最大值\", np.max(a)))\nprint(\"%-10s：%10d\"   % (\"最大值索引\", np.argmax(a)))\nprint(\"%-10s：%10.4f\" % (\"最小值\", np.min(a)))\nprint(\"%-10s：%10d\"   % (\"最小值索引\", np.argmin(a)))\nprint(\"%-10s：%10.4f\" % (\"中位数\", np.median(a)))\nprint(\"%-10s：%10.4f\" % (\"上四分位数\", np.percentile(a, 75)))\nprint(\"%-10s：%10.4f\" % (\"下四分位数\", np.percentile(a, 25)))\nprint(\"%-10s：%10.4f\" % (\"标准差\", np.std(a)))\nprint(\"%-10s：%10.4f\" % (\"方差\", np.var(a)))\n\n和         ：   10.9811\n均值        ：    0.0110\n最大值       ：    3.6534\n最大值索引     ：       664\n最小值       ：   -3.4083\n最小值索引     ：        91\n中位数       ：    0.0322\n上四分位数     ：    0.6480\n下四分位数     ：   -0.6401\n标准差       ：    0.9673\n方差        ：    0.9356\n\n\n不过，以上代码可能会有问题，如果向量中存在缺失值（比如NaN），以上函数也会计算出NaN。为了避免这一个问题，可以使用以上程序的安全版本：\n\nprint(\"%s：%f\" % (\"和\",np.nansum(a)))\nprint(\"%s：%f\" % (\"均值\",np.nanmean(a)))\nprint(\"%s：%f\" % (\"最大值\",np.nanmax(a)))\nprint(\"%s：%f\" % (\"最大值索引\",np.nanargmax(a)))\nprint(\"%s：%f\" % (\"最小值\",np.nanmin(a)))\nprint(\"%s：%f\" % (\"最小值索引\",np.nanargmin(a)))\nprint(\"%s：%f\" % (\"中位数\",np.nanmedian(a)))\nprint(\"%s：%f\" % (\"上四分位数\",np.nanpercentile(a,75)))\nprint(\"%s：%f\" % (\"上四分位数\",np.nanpercentile(a,25)))\nprint(\"%s：%f\" % (\"标准差\",np.nanstd(a)))\nprint(\"%s：%f\" % (\"方差\",np.nanvar(a)))\n\n和：10.981102\n均值：0.010981\n最大值：3.653389\n最大值索引：664.000000\n最小值：-3.408319\n最小值索引：91.000000\n中位数：0.032241\n上四分位数：0.648012\n上四分位数：-0.640122\n标准差：0.967257\n方差：0.935585\n\n\n此外还有两个特殊的函数：numpy.any()函数用于判断一个逻辑向量（其值为True/False）是否有True；而numpy.all()用于判断逻辑向量是否全为真，比如：\n\nvec_a=np.array([1,2,3])\nprint((vec_a==2).any())\nprint((vec_a==5).any())\nvec_b=np.array([1,2,3])\nprint((vec_a==vec_b).all())\nvec_b=np.array([1,2,4])\nprint((vec_a==vec_b).all())\n\nTrue\nFalse\nTrue\nFalse",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_numpy_scipy.html#scipy-简介",
    "href": "body/01_py_02_numpy_scipy.html#scipy-简介",
    "title": "16  NumPy",
    "section": "16.5 SciPy 简介",
    "text": "16.5 SciPy 简介\nSciPy 在 NumPy 的基础扩展了一些用于数值计算的高级工具，比如：\n\nscipy.special：特殊函数，包括gamma函数、beta函数、各种统计函数、erf函数等等，都可以从这里找到\nscipy.optimize：提供了最优化方法\nscipy.sparse：稀疏矩阵\nscipy.interpolate：插值\nscipy.integrate：积分和常微分方程\nscipy.fftpack：快速傅里叶变换\nscipy.stats：常用的统计函数\n\n……\n在此我们不再赘述，如有需要，可以参考 SciPy User Guide。我们也会在接下来通过实例的方式稍微介绍SciPy的用法。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html",
    "href": "body/01_py_02_pandas.html",
    "title": "17  pandas 快速入门",
    "section": "",
    "text": "17.1 目录\n本讲义基于 pandas 官方文档 10 Minutes to pandas 编写，结合中文读者习惯进行注释与讲解。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#目录",
    "href": "body/01_py_02_pandas.html#目录",
    "title": "17  pandas 快速入门",
    "section": "",
    "text": "对象创建\n查看数据\n选择数据\n缺失值处理\n运算\n数据导入导出\n索引\n分组\n连接\n绘图\n时间序列\nCategorical\nPlotting\nGetting data in/out",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#导入-pandas-和-numpy",
    "href": "body/01_py_02_pandas.html#导入-pandas-和-numpy",
    "title": "17  pandas 快速入门",
    "section": "17.2 导入 pandas 和 numpy",
    "text": "17.2 导入 pandas 和 numpy\n\nimport pandas as pd\nimport numpy as np",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#对象创建",
    "href": "body/01_py_02_pandas.html#对象创建",
    "title": "17  pandas 快速入门",
    "section": "17.3 对象创建",
    "text": "17.3 对象创建\n\n17.3.1 创建 Series\n\ns = pd.Series([1, 3, 5, np.nan, 6, 8])\ns\n\n0    1.0\n1    3.0\n2    5.0\n3    NaN\n4    6.0\n5    8.0\ndtype: float64\n\n\n\n\n17.3.2 创建 DataFrame\n\ndates = pd.date_range(\"20130101\", periods=6)\ndates\n\nDatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n               '2013-01-05', '2013-01-06'],\n              dtype='datetime64[ns]', freq='D')\n\n\n\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list(\"ABCD\"))\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\n\n\n2013-01-06\n-0.257989\n-1.401546\n1.692584\n-0.928318\n\n\n\n\n\n\n\n\n\n17.3.3 由 dict 创建 DataFrame\n\ndf2 = pd.DataFrame({\n    \"A\": 1.,\n    \"B\": pd.Timestamp('20130102'),\n    \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n    \"D\": np.array([3] * 4, dtype=\"int32\"),\n    \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n    \"F\": \"foo\"\n})\ndf2\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\n\n\n\n\n0\n1.0\n2013-01-02\n1.0\n3\ntest\nfoo\n\n\n1\n1.0\n2013-01-02\n1.0\n3\ntrain\nfoo\n\n\n2\n1.0\n2013-01-02\n1.0\n3\ntest\nfoo\n\n\n3\n1.0\n2013-01-02\n1.0\n3\ntrain\nfoo\n\n\n\n\n\n\n\n\n\n17.3.4 查看各列数据类型\n\ndf2.dtypes\n\nA          float64\nB    datetime64[s]\nC          float32\nD            int32\nE         category\nF           object\ndtype: object",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#查看数据",
    "href": "body/01_py_02_pandas.html#查看数据",
    "title": "17  pandas 快速入门",
    "section": "17.4 查看数据",
    "text": "17.4 查看数据\n\n17.4.1 查看头尾行\n\ndf.head()\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\n\n\n\n\n\n\n\n\ndf.tail(3)\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\n\n\n2013-01-06\n-0.257989\n-1.401546\n1.692584\n-0.928318\n\n\n\n\n\n\n\n\n\n17.4.2 显示索引、列名和底层 numpy 数据\n\ndf.index\n\nDatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n               '2013-01-05', '2013-01-06'],\n              dtype='datetime64[ns]', freq='D')\n\n\n\ndf.columns\n\nIndex(['A', 'B', 'C', 'D'], dtype='object')\n\n\n\ndf.to_numpy()\n\narray([[-0.52058527,  0.48153608, -0.35133101, -1.36249633],\n       [ 0.31290141,  1.50718565, -0.65209664,  1.13779112],\n       [-0.87323811, -1.8934827 ,  1.22485201, -0.11938684],\n       [-0.48861365, -0.17974916,  0.02371156,  1.18271133],\n       [ 0.23715514,  0.70976824, -0.46769407, -0.8552958 ],\n       [-0.25798935, -1.40154591,  1.69258428, -0.92831789]])\n\n\n\n\n17.4.3 描述性统计汇总\n\ndf.describe()\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\ncount\n6.000000\n6.000000\n6.000000\n6.000000\n\n\nmean\n-0.265062\n-0.129381\n0.245004\n-0.157499\n\n\nstd\n0.462917\n1.302976\n0.977027\n1.096220\n\n\nmin\n-0.873238\n-1.893483\n-0.652097\n-1.362496\n\n\n25%\n-0.512592\n-1.096097\n-0.438603\n-0.910062\n\n\n50%\n-0.373301\n0.150893\n-0.163810\n-0.487341\n\n\n75%\n0.113369\n0.652710\n0.924567\n0.823497\n\n\nmax\n0.312901\n1.507186\n1.692584\n1.182711\n\n\n\n\n\n\n\n\n\n17.4.4 数据转置\n\ndf.T\n\n\n\n\n\n\n\n\n2013-01-01\n2013-01-02\n2013-01-03\n2013-01-04\n2013-01-05\n2013-01-06\n\n\n\n\nA\n-0.520585\n0.312901\n-0.873238\n-0.488614\n0.237155\n-0.257989\n\n\nB\n0.481536\n1.507186\n-1.893483\n-0.179749\n0.709768\n-1.401546\n\n\nC\n-0.351331\n-0.652097\n1.224852\n0.023712\n-0.467694\n1.692584\n\n\nD\n-1.362496\n1.137791\n-0.119387\n1.182711\n-0.855296\n-0.928318\n\n\n\n\n\n\n\n\n\n17.4.5 按轴排序\n\ndf.sort_index(axis=1, ascending=False)\n\n\n\n\n\n\n\n\nD\nC\nB\nA\n\n\n\n\n2013-01-01\n-1.362496\n-0.351331\n0.481536\n-0.520585\n\n\n2013-01-02\n1.137791\n-0.652097\n1.507186\n0.312901\n\n\n2013-01-03\n-0.119387\n1.224852\n-1.893483\n-0.873238\n\n\n2013-01-04\n1.182711\n0.023712\n-0.179749\n-0.488614\n\n\n2013-01-05\n-0.855296\n-0.467694\n0.709768\n0.237155\n\n\n2013-01-06\n-0.928318\n1.692584\n-1.401546\n-0.257989\n\n\n\n\n\n\n\n\ndf.sort_values(by=\"B\")\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\n\n\n2013-01-06\n-0.257989\n-1.401546\n1.692584\n-0.928318\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#选择数据",
    "href": "body/01_py_02_pandas.html#选择数据",
    "title": "17  pandas 快速入门",
    "section": "17.5 选择数据",
    "text": "17.5 选择数据\n\n17.5.1 选择单列\n\ndf[\"A\"]\n\n2013-01-01   -0.520585\n2013-01-02    0.312901\n2013-01-03   -0.873238\n2013-01-04   -0.488614\n2013-01-05    0.237155\n2013-01-06   -0.257989\nFreq: D, Name: A, dtype: float64\n\n\n\n\n17.5.2 通过切片选取多行（行标签）\n\ndf[0:3]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\n\n\n\n\n\n\n\n\ndf[\"20130102\":\"20130104\"]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\n\n\n\n\n\n\n\n\n\n17.5.3 使用标签（loc）选择\n\n精确选取行/列\n\n\ndf.loc[dates[0]]\n\nA   -0.520585\nB    0.481536\nC   -0.351331\nD   -1.362496\nName: 2013-01-01 00:00:00, dtype: float64\n\n\n\ndf.loc[:, [\"A\", \"B\"]]\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n\n\n2013-01-02\n0.312901\n1.507186\n\n\n2013-01-03\n-0.873238\n-1.893483\n\n\n2013-01-04\n-0.488614\n-0.179749\n\n\n2013-01-05\n0.237155\n0.709768\n\n\n2013-01-06\n-0.257989\n-1.401546\n\n\n\n\n\n\n\n\ndf.loc[\"20130102\":\"20130104\", [\"A\", \"B\"]]\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n2013-01-02\n0.312901\n1.507186\n\n\n2013-01-03\n-0.873238\n-1.893483\n\n\n2013-01-04\n-0.488614\n-0.179749\n\n\n\n\n\n\n\n\ndf.loc[dates[0], [\"A\", \"B\"]]\n\nA   -0.520585\nB    0.481536\nName: 2013-01-01 00:00:00, dtype: float64\n\n\n\ndf.loc[dates[0], \"A\"]\n\n-0.5205852732718299\n\n\n\ndf.at[dates[0], \"A\"]\n\n-0.5205852732718299\n\n\n\n\n17.5.4 按位置（iloc）选取\n\n类似于 numpy 的索引\n\n\ndf.iloc[3]\n\nA   -0.488614\nB   -0.179749\nC    0.023712\nD    1.182711\nName: 2013-01-04 00:00:00, dtype: float64\n\n\n\ndf.iloc[3:5, 0:2]\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n2013-01-04\n-0.488614\n-0.179749\n\n\n2013-01-05\n0.237155\n0.709768\n\n\n\n\n\n\n\n\ndf.iloc[[1,2,4], [0,2]]\n\n\n\n\n\n\n\n\nA\nC\n\n\n\n\n2013-01-02\n0.312901\n-0.652097\n\n\n2013-01-03\n-0.873238\n1.224852\n\n\n2013-01-05\n0.237155\n-0.467694\n\n\n\n\n\n\n\n\ndf.iloc[1:3, :]\ndf.iloc[:, 1:3]\n\n\n\n\n\n\n\n\nB\nC\n\n\n\n\n2013-01-01\n0.481536\n-0.351331\n\n\n2013-01-02\n1.507186\n-0.652097\n\n\n2013-01-03\n-1.893483\n1.224852\n\n\n2013-01-04\n-0.179749\n0.023712\n\n\n2013-01-05\n0.709768\n-0.467694\n\n\n2013-01-06\n-1.401546\n1.692584\n\n\n\n\n\n\n\n\ndf.iat[1, 1]\n\n1.5071856526966947\n\n\n\n\n17.5.5 布尔索引\n\n条件筛选\n\n\ndf[df[\"A\"] &gt; 0]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\n\n\n\n\n\n\n\n\ndf[df &gt; 0]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-01\nNaN\n0.481536\nNaN\nNaN\n\n\n2013-01-02\n0.312901\n1.507186\nNaN\n1.137791\n\n\n2013-01-03\nNaN\nNaN\n1.224852\nNaN\n\n\n2013-01-04\nNaN\nNaN\n0.023712\n1.182711\n\n\n2013-01-05\n0.237155\n0.709768\nNaN\nNaN\n\n\n2013-01-06\nNaN\nNaN\n1.692584\nNaN\n\n\n\n\n\n\n\n\ndf2 = df.copy()\ndf2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]\ndf2\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\none\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\none\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\ntwo\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\nthree\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\nfour\n\n\n2013-01-06\n-0.257989\n-1.401546\n1.692584\n-0.928318\nthree\n\n\n\n\n\n\n\n\ndf2[df2[\"E\"].isin([\"two\", \"four\"])]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\ntwo\n\n\n2013-01-05\n0.237155\n0.709768\n-0.467694\n-0.855296\nfour",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#缺失值处理",
    "href": "body/01_py_02_pandas.html#缺失值处理",
    "title": "17  pandas 快速入门",
    "section": "17.6 缺失值处理",
    "text": "17.6 缺失值处理\npandas 使用 np.nan 代表缺失值。 可以用 dropna 删除含有缺失值的行，或者用 fillna 填充。\n\ndf1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [\"E\"])\ndf1.loc[dates[0]:dates[1], \"E\"] = 1\ndf1\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n1.0\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n1.0\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\nNaN\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\nNaN\n\n\n\n\n\n\n\n\ndf1.dropna(how=\"any\")\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n1.0\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n1.0\n\n\n\n\n\n\n\n\ndf1.fillna(value=5)\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n1.0\n\n\n2013-01-02\n0.312901\n1.507186\n-0.652097\n1.137791\n1.0\n\n\n2013-01-03\n-0.873238\n-1.893483\n1.224852\n-0.119387\n5.0\n\n\n2013-01-04\n-0.488614\n-0.179749\n0.023712\n1.182711\n5.0\n\n\n\n\n\n\n\n\npd.isna(df1)\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2013-01-01\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2013-01-02\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2013-01-03\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n2013-01-04\nFalse\nFalse\nFalse\nFalse\nTrue",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#运算",
    "href": "body/01_py_02_pandas.html#运算",
    "title": "17  pandas 快速入门",
    "section": "17.7 运算",
    "text": "17.7 运算\npandas 支持类似 numpy 的各类算术运算，且会自动对齐不同索引。\n\ndf.mean()\n\nA   -0.265062\nB   -0.129381\nC    0.245004\nD   -0.157499\ndtype: float64\n\n\n\ndf.mean(axis=1)\n\n2013-01-01   -0.438219\n2013-01-02    0.576445\n2013-01-03   -0.415314\n2013-01-04    0.134515\n2013-01-05   -0.094017\n2013-01-06   -0.223817\nFreq: D, dtype: float64\n\n\n\ns = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)\ndf.sub(s, axis=\"index\")\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-01\nNaN\nNaN\nNaN\nNaN\n\n\n2013-01-02\nNaN\nNaN\nNaN\nNaN\n\n\n2013-01-03\n-1.873238\n-2.893483\n0.224852\n-1.119387\n\n\n2013-01-04\n-3.488614\n-3.179749\n-2.976288\n-1.817289\n\n\n2013-01-05\n-4.762845\n-4.290232\n-5.467694\n-5.855296\n\n\n2013-01-06\nNaN\nNaN\nNaN\nNaN",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#apply-方法",
    "href": "body/01_py_02_pandas.html#apply-方法",
    "title": "17  pandas 快速入门",
    "section": "17.8 Apply 方法",
    "text": "17.8 Apply 方法\n\n自定义函数应用于行或列\n\n\ndf.apply(np.cumsum)\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n2013-01-01\n-0.520585\n0.481536\n-0.351331\n-1.362496\n\n\n2013-01-02\n-0.207684\n1.988722\n-1.003428\n-0.224705\n\n\n2013-01-03\n-1.080922\n0.095239\n0.221424\n-0.344092\n\n\n2013-01-04\n-1.569536\n-0.084510\n0.245136\n0.838619\n\n\n2013-01-05\n-1.332380\n0.625258\n-0.222558\n-0.016677\n\n\n2013-01-06\n-1.590370\n-0.776288\n1.470026\n-0.944994\n\n\n\n\n\n\n\n\ndf.apply(lambda x: x.max() - x.min())\n\nA    1.186140\nB    3.400668\nC    2.344681\nD    2.545208\ndtype: float64",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#直方图统计",
    "href": "body/01_py_02_pandas.html#直方图统计",
    "title": "17  pandas 快速入门",
    "section": "17.9 直方图统计",
    "text": "17.9 直方图统计\n\ns = pd.Series(np.random.randint(0, 7, size=10))\ns.value_counts()\n\n6    5\n5    2\n3    1\n1    1\n4    1\nName: count, dtype: int64",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#字符串方法",
    "href": "body/01_py_02_pandas.html#字符串方法",
    "title": "17  pandas 快速入门",
    "section": "17.10 字符串方法",
    "text": "17.10 字符串方法\n\nSeries 字符串方法自动适配缺失值。\n\n\ns = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])\ns.str.lower()\n\n0       a\n1       b\n2       c\n3    aaba\n4    baca\n5     NaN\n6    caba\n7     dog\n8     cat\ndtype: object",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#合并",
    "href": "body/01_py_02_pandas.html#合并",
    "title": "17  pandas 快速入门",
    "section": "17.11 合并",
    "text": "17.11 合并\n\n17.11.1 拼接\n\ndf = pd.DataFrame(np.random.randn(10, 4))\npieces = [df[:3], df[3:7], df[7:]]\npd.concat(pieces)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n0.149451\n-1.716458\n1.540956\n-1.478438\n\n\n1\n-0.788580\n0.942535\n0.860695\n1.277974\n\n\n2\n1.529843\n0.978873\n1.681723\n0.128001\n\n\n3\n-1.031891\n-0.645625\n-0.101714\n-0.894796\n\n\n4\n-1.341019\n-0.400039\n0.293592\n-1.754958\n\n\n5\n-0.018467\n-0.688119\n0.063590\n0.081667\n\n\n6\n0.042298\n0.433534\n0.509931\n0.708851\n\n\n7\n0.631839\n1.985047\n0.612073\n0.114068\n\n\n8\n1.433401\n-0.619146\n1.581860\n-1.031054\n\n\n9\n1.029629\n0.266897\n-0.649012\n0.456147\n\n\n\n\n\n\n\n\n\n17.11.2 merge（类似 SQL join）\n\nleft = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\nright = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\npd.merge(left, right, on='key')\n\n\n\n\n\n\n\n\nkey\nlval\nrval\n\n\n\n\n0\nfoo\n1\n4\n\n\n1\nbar\n2\n5",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#分组-groupby",
    "href": "body/01_py_02_pandas.html#分组-groupby",
    "title": "17  pandas 快速入门",
    "section": "17.12 分组 groupby",
    "text": "17.12 分组 groupby\n\nsplit-apply-combine\n统计、聚合、转换\n\n\ndf = pd.DataFrame({\n    'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],\n    'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n    'C': np.random.randn(8),\n    'D': np.random.randn(8)\n})\ndf.groupby('A').sum()\n\n\n\n\n\n\n\n\nB\nC\nD\n\n\nA\n\n\n\n\n\n\n\nbar\nonethreetwo\n-2.510037\n1.483046\n\n\nfoo\nonetwotwoonethree\n2.931827\n-2.711364\n\n\n\n\n\n\n\n\ndf.groupby(['A', 'B']).sum()\n\n\n\n\n\n\n\n\n\nC\nD\n\n\nA\nB\n\n\n\n\n\n\nbar\none\n-1.279562\n-0.243084\n\n\nthree\n-0.183928\n-0.697683\n\n\ntwo\n-1.046547\n2.423813\n\n\nfoo\none\n1.735463\n-3.088498\n\n\nthree\n0.289137\n0.215364\n\n\ntwo\n0.907227\n0.161770",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#reshaping",
    "href": "body/01_py_02_pandas.html#reshaping",
    "title": "17  pandas 快速入门",
    "section": "17.13 Reshaping",
    "text": "17.13 Reshaping\n\nStack/unstack\nPivot tables\n\n\ntuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n                    'foo', 'foo', 'qux', 'qux'],\n                   ['one', 'two', 'one', 'two',\n                    'one', 'two', 'one', 'two']]))\nindex = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\ndf = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\ndf2 = df[:4]\ndf2\n\n\n\n\n\n\n\n\n\nA\nB\n\n\nfirst\nsecond\n\n\n\n\n\n\nbar\none\n1.185040\n0.718365\n\n\ntwo\n0.680732\n0.058235\n\n\nbaz\none\n1.726562\n-0.828623\n\n\ntwo\n-0.362360\n0.716046\n\n\n\n\n\n\n\n\nstacked = df2.stack()\nstacked\n\nfirst  second   \nbar    one     A    1.185040\n               B    0.718365\n       two     A    0.680732\n               B    0.058235\nbaz    one     A    1.726562\n               B   -0.828623\n       two     A   -0.362360\n               B    0.716046\ndtype: float64\n\n\n\nstacked.unstack()\n\n\n\n\n\n\n\n\n\nA\nB\n\n\nfirst\nsecond\n\n\n\n\n\n\nbar\none\n1.185040\n0.718365\n\n\ntwo\n0.680732\n0.058235\n\n\nbaz\none\n1.726562\n-0.828623\n\n\ntwo\n-0.362360\n0.716046\n\n\n\n\n\n\n\n\nstacked.unstack(1)\n\n\n\n\n\n\n\n\nsecond\none\ntwo\n\n\nfirst\n\n\n\n\n\n\n\nbar\nA\n1.185040\n0.680732\n\n\nB\n0.718365\n0.058235\n\n\nbaz\nA\n1.726562\n-0.362360\n\n\nB\n-0.828623\n0.716046\n\n\n\n\n\n\n\n\nstacked.unstack(0)\n\n\n\n\n\n\n\n\nfirst\nbar\nbaz\n\n\nsecond\n\n\n\n\n\n\n\none\nA\n1.185040\n1.726562\n\n\nB\n0.718365\n-0.828623\n\n\ntwo\nA\n0.680732\n-0.362360\n\n\nB\n0.058235\n0.716046\n\n\n\n\n\n\n\n\n17.13.1 Pivot tables（透视表）\n\ndf = pd.DataFrame({\n    \"A\": [\"one\", \"one\", \"two\", \"three\"] * 3,\n    \"B\": [\"A\", \"B\", \"C\"] * 4,\n    \"C\": np.random.randn(12),\n    \"D\": np.random.randn(12)\n})\npd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])\n\n\n\n\n\n\n\n\nC\n-1.269507\n-1.163112\n-0.359637\n-0.353797\n-0.100903\n0.162224\n0.385348\n0.504784\n0.538580\n0.647929\n1.090241\n2.017582\n\n\nA\nB\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\none\nA\nNaN\nNaN\n-0.374013\nNaN\n0.191885\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nB\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-0.837664\nNaN\nNaN\nNaN\n-0.53223\nNaN\n\n\nC\n0.069504\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.184217\nNaN\nNaN\nNaN\n\n\nthree\nA\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.025075\nNaN\nNaN\n\n\nB\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-0.050209\nNaN\nNaN\nNaN\nNaN\n\n\nC\nNaN\nNaN\nNaN\nNaN\nNaN\n-0.813397\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntwo\nA\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.881732\n\n\nB\nNaN\n-1.001614\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nC\nNaN\nNaN\nNaN\n-0.216438\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#时间序列",
    "href": "body/01_py_02_pandas.html#时间序列",
    "title": "17  pandas 快速入门",
    "section": "17.14 时间序列",
    "text": "17.14 时间序列\n\nrng = pd.date_range('1/1/2012', periods=100, freq='S')\nts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\nts.resample('5Min').sum()\n\nC:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_56080\\2503940574.py:1: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n  rng = pd.date_range('1/1/2012', periods=100, freq='S')\n\n\n2012-01-01    24577\nFreq: 5min, dtype: int32\n\n\n\nrng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\nts = pd.Series(np.random.randn(len(rng)), rng)\nts_utc = ts.tz_localize('UTC')\nts_utc\n\n2012-03-06 00:00:00+00:00   -0.960792\n2012-03-07 00:00:00+00:00   -2.119477\n2012-03-08 00:00:00+00:00   -0.038033\n2012-03-09 00:00:00+00:00   -0.125605\n2012-03-10 00:00:00+00:00   -0.893517\nFreq: D, dtype: float64\n\n\n\nts_utc.tz_convert('US/Eastern')\n\n2012-03-05 19:00:00-05:00   -0.960792\n2012-03-06 19:00:00-05:00   -2.119477\n2012-03-07 19:00:00-05:00   -0.038033\n2012-03-08 19:00:00-05:00   -0.125605\n2012-03-09 19:00:00-05:00   -0.893517\nFreq: D, dtype: float64\n\n\n\n17.14.1 时间区间和频率转换\n\nrng = pd.date_range('1/1/2012', periods=5, freq='M')\nts = pd.Series(np.random.randn(len(rng)), index=rng)\nts\n\nC:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_56080\\3446765465.py:1: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n  rng = pd.date_range('1/1/2012', periods=5, freq='M')\n\n\n2012-01-31   -0.054797\n2012-02-29    1.442388\n2012-03-31    0.846941\n2012-04-30    0.750070\n2012-05-31   -0.466189\nFreq: ME, dtype: float64\n\n\n\nps = ts.to_period()\nps\n\n2012-01   -0.054797\n2012-02    1.442388\n2012-03    0.846941\n2012-04    0.750070\n2012-05   -0.466189\nFreq: M, dtype: float64\n\n\n\nps.to_timestamp()\n\n2012-01-01   -0.054797\n2012-02-01    1.442388\n2012-03-01    0.846941\n2012-04-01    0.750070\n2012-05-01   -0.466189\nFreq: MS, dtype: float64\n\n\n\nprng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\nts = pd.Series(np.random.randn(len(prng)), index=prng)\nts.head()\n\n1990Q1   -0.275693\n1990Q2   -1.237097\n1990Q3    0.617560\n1990Q4    1.263013\n1991Q1   -1.938149\nFreq: Q-NOV, dtype: float64\n\n\n\nts.index = ts.index.asfreq('M', how='end')\nts.head()\n\n1990-02   -0.275693\n1990-05   -1.237097\n1990-08    0.617560\n1990-11    1.263013\n1991-02   -1.938149\nFreq: M, dtype: float64",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#categoricals",
    "href": "body/01_py_02_pandas.html#categoricals",
    "title": "17  pandas 快速入门",
    "section": "17.15 Categoricals",
    "text": "17.15 Categoricals\n\ndf = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n                   \"raw_grade\": [\"a\", \"b\", \"b\", \"a\", \"a\", \"e\"]})\ndf[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\ndf[\"grade\"]\n\n0    a\n1    b\n2    b\n3    a\n4    a\n5    e\nName: grade, dtype: category\nCategories (3, object): ['a', 'b', 'e']\n\n\n\ndf[\"grade\"] = df[\"grade\"].cat.set_categories([\"very good\", \"good\", \"very bad\"])\ndf[\"grade\"]\n\n0    NaN\n1    NaN\n2    NaN\n3    NaN\n4    NaN\n5    NaN\nName: grade, dtype: category\nCategories (3, object): ['very good', 'good', 'very bad']\n\n\n\ndf[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"])\ndf[\"grade\"]\n\n0    NaN\n1    NaN\n2    NaN\n3    NaN\n4    NaN\n5    NaN\nName: grade, dtype: category\nCategories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']\n\n\n\ndf.sort_values(by=\"grade\")\n\n\n\n\n\n\n\n\nid\nraw_grade\ngrade\n\n\n\n\n0\n1\na\nNaN\n\n\n1\n2\nb\nNaN\n\n\n2\n3\nb\nNaN\n\n\n3\n4\na\nNaN\n\n\n4\n5\na\nNaN\n\n\n5\n6\ne\nNaN\n\n\n\n\n\n\n\n\ndf.groupby(\"grade\").size()\n\nC:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_56080\\3951628473.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  df.groupby(\"grade\").size()\n\n\ngrade\nvery bad     0\nbad          0\nmedium       0\ngood         0\nvery good    0\ndtype: int64",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#绘图",
    "href": "body/01_py_02_pandas.html#绘图",
    "title": "17  pandas 快速入门",
    "section": "17.16 绘图",
    "text": "17.16 绘图\npandas 集成了 Matplotlib，可直接用 .plot() 快速画图。\n\nimport matplotlib.pyplot as plt\nimport warnings\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n    ts = ts.cumsum()\n    ts.plot()\n    plt.show()\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list(\"ABCD\"))\ndf = df.cumsum()\ndf.plot()\nplt.show()\n\nc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26376 (\\N{CJK UNIFIED IDEOGRAPH-6708}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\nc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26376 (\\N{CJK UNIFIED IDEOGRAPH-6708}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_02_pandas.html#数据读写",
    "href": "body/01_py_02_pandas.html#数据读写",
    "title": "17  pandas 快速入门",
    "section": "17.17 数据读写",
    "text": "17.17 数据读写\n\n支持多种格式导入导出：CSV, HDF5, Excel, SQL, JSON 等\n\n\n# 写入 CSV\ndf.to_csv('foo.csv')\n# 读取 CSV\npd.read_csv('foo.csv').head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nA\nB\nC\nD\n\n\n\n\n0\n2000-01-01\n-0.332295\n0.167448\n1.819971\n0.262984\n\n\n1\n2000-01-02\n-1.154339\n-0.795782\n1.476187\n-0.507846\n\n\n2\n2000-01-03\n-0.130460\n0.149241\n1.797390\n0.417354\n\n\n3\n2000-01-04\n-1.573087\n0.423807\n1.720803\n-0.492286\n\n\n4\n2000-01-05\n-1.842675\n0.541527\n1.728333\n-1.907499\n\n\n\n\n\n\n\n\n# 写入 Excel\ndf.to_excel('foo.xlsx', sheet_name='Sheet1')\n# 读取 Excel\npd.read_excel('foo.xlsx', 'Sheet1').head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nA\nB\nC\nD\n\n\n\n\n0\n2000-01-01\n-0.332295\n0.167448\n1.819971\n0.262984\n\n\n1\n2000-01-02\n-1.154339\n-0.795782\n1.476187\n-0.507846\n\n\n2\n2000-01-03\n-0.130460\n0.149241\n1.797390\n0.417354\n\n\n3\n2000-01-04\n-1.573087\n0.423807\n1.720803\n-0.492286\n\n\n4\n2000-01-05\n-1.842675\n0.541527\n1.728333\n-1.907499",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 快速入门</span>"
    ]
  },
  {
    "objectID": "body/01_py_03_matplotlib.html",
    "href": "body/01_py_03_matplotlib.html",
    "title": "18  Matplotlib简介",
    "section": "",
    "text": "19 实例1：数据的直方图以及散点图\n在 Python 中，可以用 matplotlib 画图。在使用前可以使用 (sudo) pip install matplotlib 安装。\n限于篇幅，我们无法详尽地介绍 Matplot 的用法，仅通过一些实例让诸位感受一下 Matplot 画图的几个思想和语法。\n在使用 Matplotlib 时，如果不知道某个图该怎么画，查看文档可能是最简单的方法，其官网： https://matplotlib.org 上提供了非常详细的示例、文档。此外， https://github.com/rougier/matplotlib-tutorial 也提供了一个非常好的教程，可以参阅。\n在接下来的例子中看我们随机生成了一组期望为 0，方差为 2，包含 500 个观察值的随机数，并画出其直方图：\nz=nprd.normal(0,np.sqrt(2),1000) ## 生成100个均值为0，方差为2的正态分布\n## 导入matplotlib\nimport matplotlib.pyplot as plt \n## 使图形直接插入到jupyter中\n%matplotlib inline\n# 设定图像大小\nplt.rcParams['figure.figsize'] = (15.0, 8.0)\n\nplt.hist(z,bins=40) ##柱状图，40 个柱子\nplt.xlabel('z')\nplt.ylabel(\"Density\")\nplt.title('Normal Distribution')\nplt.show() ## 画图\n而以下代码，产生了 500 个 \\(x \\sim N\\left(0,2\\right)\\)，以及 \\(y=x+u\\)，\\(u\\sim N\\left(0,1\\right)\\)，并将其散点图、和关系图花在了同一张图上：\nx=nprd.normal(0,np.sqrt(2),500) ## 生成100个均值为0，方差为2的正态分布\ny=x+nprd.normal(0,1,500) ## y与x为线性关系\nplt.scatter(x,y,color='pink') ##散点图\nplt.plot(x,x,color='blue') ## 回归曲线\nplt.xlabel('x')\nplt.ylabel(\"y\")\nplt.title('Relationship of x and y')\nplt.show() ## 画图",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Matplotlib简介</span>"
    ]
  },
  {
    "objectID": "body/01_py_03_matplotlib.html#矩估计",
    "href": "body/01_py_03_matplotlib.html#矩估计",
    "title": "18  Matplotlib简介",
    "section": "23.1 矩估计",
    "text": "23.1 矩估计\n如果 \\(x_i \\sim Beta(\\alpha, \\beta)\\)，由于 \\(E(x_i)=\\frac{\\alpha}{\\alpha + \\beta}\\)，而 \\(E(x_i^2)=\\frac{\\alpha ^2}{(\\alpha + \\beta)^2}+\\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha+\\beta+1)}\\)，从而我们的矩估计即联立：\n\\[\\frac{\\hat{\\alpha}}{\\hat{\\alpha} + \\hat{\\beta}}=\\bar{x}\\]\n\\[\\frac{\\hat{\\alpha} ^2}{(\\hat{\\alpha} + \\hat{\\beta})^2}+\\frac{\\hat{\\alpha} \\hat{\\beta}}{(\\hat{\\alpha} + \\hat{\\beta})^2 (\\hat{\\alpha}+\\hat{\\beta}+1)}=\\overline{x^{2}}\n\\]\n即可得到矩估计。在这里，我们将联立方程问题转化为一个最优化问题，即最小化：\n\\[\\min_{\\hat{\\alpha},\\hat{\\beta}}\\left[\\frac{\\hat{\\alpha}}{\\hat{\\alpha} + \\hat{\\beta}}-\\bar{x} \\right]^2+\\left[\\frac{\\hat{\\alpha} ^2}{(\\hat{\\alpha} + \\hat{\\beta})^2}+\\frac{\\hat{\\alpha} \\hat{\\beta}}{(\\hat{\\alpha} + \\hat{\\beta})^2 (\\hat{\\alpha}+\\hat{\\beta}+1)}-\\overline{x^{2}}\\right]^2\n\\]\n我们将会重复抽样、估计M=500次，并根据这500次的结果计算矩估计量的偏差（bias）、标准误(standard error)以及均方误差（mean sqrared error）。\n\nimport numpy as np\nfrom numpy import random as nprd\nfrom scipy.optimize import minimize\nimport scipy as sc\n\ndef sampling(a,b,N):\n    x=nprd.beta(a,b,N)\n    return x\n\ndef estimate(x):\n    meanx=np.mean(x)\n    x2=[xi**2 for xi in x]\n    meanx2=np.mean(x2)\n    def obj(theta):\n        return (theta[0]/(theta[0]+theta[1])-meanx)**2 + ((theta[0]/(theta[0]+theta[1]))**2+(theta[0]*theta[1])/((theta[0]+theta[1])**2*(theta[0]+theta[1]+1))-meanx2)**2\n    res=minimize(obj, np.array([1,1]), method='nelder-mead', options={'xtol': 1e-4, 'disp': False})\n    return res\n\nM=500 ## simulation times\nN=200 ## sample size\na=3\nb=1 ## true value\nRESULT=np.zeros((M,2), np.float64)\nfor m in range(M):\n    x=sampling(a,b,N)\n    res=estimate(x)\n    RESULT[m]=res.x\n\nMEAN_RESULT=np.average(RESULT, 0)\nBIAS=MEAN_RESULT-np.array([a,b])\nSTD=np.std(RESULT, 0)\nMSE2=np.array([i**2 for i in STD])+np.array([i**2 for i in BIAS])\nMSE=np.array([np.sqrt(i) for i in MSE2])\nprint(\"Bias = \", BIAS)\nprint(\"s.e. = \", STD)\nprint(\"RMSE = \", MSE)\n\n## 画图\nimport matplotlib.pyplot as plt\n## 使图形直接插入到jupyter中\n%matplotlib inline\n# 设定图像大小\nplt.rcParams['figure.figsize'] = (10.0, 8.0)\n## 样本均值\nax1 = plt.subplot(1,2,1)\nax2 = plt.subplot(1,2,2)\nax1.hist(RESULT[:,0],bins=30,normed=1)\nax2.hist(RESULT[:,1],bins=30,normed=1)\nplt.show()\n\nBias =  [ 0.04108888  0.01504609]\ns.e. =  [ 0.34001766  0.10260341]\nRMSE =  [ 0.34249132  0.10370075]",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Matplotlib简介</span>"
    ]
  },
  {
    "objectID": "body/01_py_03_matplotlib.html#极大似然估计",
    "href": "body/01_py_03_matplotlib.html#极大似然估计",
    "title": "18  Matplotlib简介",
    "section": "23.2 极大似然估计",
    "text": "23.2 极大似然估计\n由于Beta分布的对数似然函数为\\[\\ln \\left( \\alpha, \\beta | x \\right)=\\sum_{i=1}^N \\left[ -\\ln (Beta(\\alpha,\\beta))+(\\alpha-1) \\ln (x_i) + (\\beta-1)\\ln (1-x_i) \\right]\\] 最大化似然函数，或者最小化负的似然函数，即可得到极大似然估计。\n\nimport numpy as np\nfrom numpy import random as nprd\nfrom scipy.optimize import minimize\nimport scipy as sc\n\ndef sampling(a,b,N):\n    x=nprd.beta(a,b,N)\n    return x\n    \ndef estimate(x):\n    def log_likelihood(theta):\n        likeli=np.array([-1*np.log(sc.special.beta(theta[0],theta[1]))+(theta[0]-1)*np.log(xi)+(theta[1]-1)*np.log(1-xi) for xi in x])\n        return -1*np.mean(likeli)\n    res=minimize(log_likelihood, np.array([1,1]), method='nelder-mead', options={'xtol': 1e-4, 'disp': False})\n    return res\n\nM=500 ## simulation times\nN=200 ## sample size\na=3\nb=1 ## true value\nRESULT=np.zeros((M,2), np.float64)\nfor m in range(M):\n    x=sampling(a,b,N)\n    res=estimate(x)\n    RESULT[m]=res.x\n\nMEAN_RESULT=np.average(RESULT, 0)\nBIAS=MEAN_RESULT-np.array([a,b])\nSTD=np.std(RESULT, 0)\nMSE2=np.array([i**2 for i in STD])+np.array([i**2 for i in BIAS])\nMSE=np.array([np.sqrt(i) for i in MSE2])\nprint(\"Bias = \", BIAS)\nprint(\"s.e. = \", STD)\nprint(\"RMSE = \", MSE)\n\n## 画图\nimport matplotlib.pyplot as plt\n## 使图形直接插入到jupyter中\n%matplotlib inline\n# 设定图像大小\nplt.rcParams['figure.figsize'] = (10.0, 8.0)\n## 样本均值\nax1 = plt.subplot(1,2,1)\nax2 = plt.subplot(1,2,2)\nax1.hist(RESULT[:,0],bins=30,normed=1)\nax2.hist(RESULT[:,1],bins=30,normed=1)\nplt.show()\n\nBias =  [ 0.05519612  0.01536957]\ns.e. =  [ 0.32866097  0.09479056]\nRMSE =  [ 0.33326362  0.09602851]",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Matplotlib简介</span>"
    ]
  },
  {
    "objectID": "body/01_py_04_func_and_module.html",
    "href": "body/01_py_04_func_and_module.html",
    "title": "19  函数",
    "section": "",
    "text": "19.1 作用域\n我们之前已经频繁的使用到了函数。\n函数是一个带有输入和输出的能够完成特定功能的代码块。比如，在某段程序中我们可能需要频繁的使用某一功能，比如，我们可能需要频繁的计算正态分布的密度函数，虽然我们可以使用：\n进行计算，但是以上计算公式仍然十分复杂，每次碰到都输入不仅麻烦，而且容易犯错。更方便的做法时将以上语句写成一个函数（function）。\n在Python中，函数可以方便的使用def来定义，比如，上面计算正态分布的密度函数的函数可以写为：\n在以上语句中，normden是所声明函数的函数名称，后面括号中的“x”、“mu”、“sigma”都是需要用户输入的参数：我们希望计算期望为mu，标准差为sigma的正态分布在x处的密度函数值。\n在函数的最后，有一个return语句，该语句用以给出函数的返回值：在本例中就是我们计算得到的密度函数值。\n注意如果需要函数有返回值，必须加入return语句，如果不加，函数默认返回None：\n此外需要注意的时，在调用函数时必须按照声明函数时的参数顺序传入参数，比如在上例中，normden(0,0,1)即对于期望为0，标准差为1的正态分布，计算x=0处的密度函数值，不能将顺序搞错。从而以下调用方式：\n必然是错的，因为标准差不可能为0。\n有时对于一个足够复杂的函数，可能会有很多参数值需要传入，而有些参数是允许有默认值的，即使用函数时如果不需要改动可以不改动。此时，我们可以可以在声明函数时就给出默认值，比如，在上例中，如果我们默认计算标准正态分布（期望为0、标注差为1）的密度函数，可以这样写：\n如果需要指明mu或者sigma的值，只需要在调用时声明即可，比如：\n就计算了标准差为2、期望为0的正态分布的密度函数值。\n此外，我们之前提到过，为代码加注释是非常好的习惯，在Python中，由于自定义的函数有可能被其他人使用，而其他人不一定会看源代码，因而注释可能不会被看到。Python提供了一种非常方便的方法，即文档字符串（docstring），这个字符串仅仅是在函数体内、放在函数开头、不赋值给任何变量的字符串：\n声明了文档字符串后，可以直接使用function.__doc__进行调阅。\n在创建函数时，必须注意变量的作用域问题。\n作用域即变量的作用范围。比如，我们在normden()函数中定义了两个变量：pi和e，但是由于这两个变量是在函数体内定义的，因而外界无法使用这两个变量：\ndef normden(x,mu=0,sigma=1):\n    pi=3.141592654\n    e=2.718\n    f=1/((2*pi)**0.5*sigma)*e**(-1*(x-mu)**2/(2*sigma**2))\n    return f\ntry:\n    print(pi)\nexcept Exception as e:\n    print(\"错误：\",e)\n\n错误： name 'pi' is not defined\n可见程序出错，并提示pi这个变量没有定义。\n然而反过来，被定义在函数体外的变量，可以被函数所使用，比如，如果我们写成：\npi=3.141592654\ne=2.718\ndef normden(x,mu=0,sigma=1):\n    f=1/((2*pi)**0.5*sigma)*e**(-1*(x-mu)**2/(2*sigma**2))\n    print(\"函数体内，pi=\",pi)\n    return f\ntry:\n    print(\"函数体外，pi=\",pi)\n    print(normden(0))\nexcept Exception as e:\n    print(\"错误：\",e)\n\n函数体外，pi= 3.141592654\n函数体内，pi= 3.141592654\n0.39894228037538715\n不过，如果在函数体内重新定义了pi，则会按照函数体内的定义：\npi=4\ne=2.718\ndef normden(x,mu=0,sigma=1):\n    pi=3.141592654\n    e=2.718\n    f=1/((2*pi)**0.5*sigma)*e**(-1*(x-mu)**2/(2*sigma**2))\n    print(\"函数体内，pi=\",pi)\n    return f\ntry:\n    print(\"函数体外，pi=\",pi)\n    print(normden(0))\nexcept Exception as e:\n    print(\"错误：\",e)\n\n函数体外，pi= 4\n函数体内，pi= 3.141592654\n0.39894228037538715",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "body/01_py_04_func_and_module.html#lambda表达式",
    "href": "body/01_py_04_func_and_module.html#lambda表达式",
    "title": "19  函数",
    "section": "19.2 lambda表达式",
    "text": "19.2 lambda表达式\n函数虽然好用，但是有一个缺点是，有时语句非常简单，但是我们还需要写def、return等语句。\nPython提供了一个语法糖，即lambda表达式，可以让我们很方便的在一行以内定义一个函数。比如刚刚计算标准正态分布的密度函数的函数可以定义为：\n\nstdnormden=lambda x: 1/((2*3.141592654)**0.5)*2.718**(-1*(x**2)/2)\nprint(stdnormden(0))\n\n0.39894228037538715\n\n\n当然，简单的代价是损失方便性，上面的lambda表达式虽然定义了标准正态分布的密度函数，但是并没有定义一般意义的正态分布的密度函数，如果需要传入额外的变量，可以使用：\n\nnormden=lambda x, mu, sigma: 1/((2*3.141592654)**0.5*sigma)*2.718**(-1*((x-mu)**2)/(2*sigma**2))\nprint(normden(0,0,2))\n\n0.19947114018769357\n\n\n在这里，我们不妨回忆一下上一节中有关列表排序的内容，比如对于列表\n\nplayer_list=[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\nprint(player_list)\n\n[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\n\n\n现在该列表的每个元素是一个元组，我们希望的是对每个元组的第二个元素排序。而列表的sort()函数中，key是一个参数，当这个参数不传入任何东西时，默认按照元素值进行排序；但是key参数允许传入一个函数，在进行排序时，先将每个元素带入到key的函数中，计算返回值，再根据返回值排序。比如：\n\ndef sort_list_by_2(t):\n    return t[1]\nplayer_list.sort(key=sort_list_by_2)\nprint(player_list)\n\n[('ter Stegen', 1), ('Pique', 3), ('Busquets', 5), ('Xavi', 6), ('Suárez', 9), ('Messi', 10)]\n\n\n或者，我们可以使用lambda表达式写成更加简洁的形式：\n\nplayer_list.sort(key=lambda x: x[1],reverse=True)\nprint(player_list)\n\n[('Messi', 10), ('Suárez', 9), ('Xavi', 6), ('Busquets', 5), ('Pique', 3), ('ter Stegen', 1)]",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "body/01_py_04_func_and_module.html#python中的函数式编程",
    "href": "body/01_py_04_func_and_module.html#python中的函数式编程",
    "title": "19  函数",
    "section": "19.3 Python中的函数式编程",
    "text": "19.3 Python中的函数式编程\n可能有心的读者已经注意到了，函数是可以通过等号赋予某一个变量的，甚至可以传入另外一个函数。\n实际上在Python中也吸收了函数式编程的一些特点，函数也是“一等公民”，跟数字、字符串一样，也可以传给一个变量、当做参数传入给另外一个函数。比如：\n\ndef normden(x,mu=0,sigma=1):\n    pi=3.141592654\n    e=2.718\n    f=1/((2*pi)**0.5*sigma)*e**(-1*(x-mu)**2/(2*sigma**2))\n    return f\n\nnormden2=normden\nprint(normden2(0))\nprint(normden2 is normden)\n\n0.39894228037538715\nTrue\n\n\n上面的代码中，我们将已经声明的一个函数normden()赋值给了另一个变量,normden2，并使用normden2计算了0处的密度函数值。\n此外，我们还是用is关键字判断两者是否指代一个对象，发现两者实际上指代的同一个对象，是完全等价的。\n以下展示了将函数作为参数传递给另外一个函数：\n\ndef normden(x,mu=0,sigma=1):\n    pi=3.141592654\n    e=2.718\n    f=1/((2*pi)**0.5*sigma)*e**(-1*(x-mu)**2/(2*sigma**2))\n    return f\n\ndef den2(f,x):\n    return f(x)**2\n\nprint(den2(normden,0))\n\n0.159154943071114\n\n\n以上程序中，我们定义了一个新的函数，den2()，该函数接受两个参数：f和x，其中f为一个函数，可用来计算f(x)，并返回f(2)**2。\n随后，我们将刚刚定义的normden()函数以及x=0传入了den2()函数，计算得到了具体数值。\n\n19.3.1 递归\n递归（recursion）是函数是函数值编程一个非常有意思的应用，即一个函数调用其本身。\n比如，为了计算阶乘，我们通常会使用循环：\n\ndef factorial(n):\n    frcn=1\n    for i in range(n):\n        frcn*=(i+1)\n    return frcn\nprint(factorial(5))\n\n120\n\n\n如果使用递归的思路，我们可以这么写：\n\ndef factorial(n):\n    if n==1:\n        return 1\n    else:\n        return n*factorial(n-1)\nprint(factorial(5))\n\n120\n\n\n在以上程序中，我们定义了一个函数factorial()，接受一个数字作为参数：只要该参数不为1，就继续往下乘，直到编程1为止。因而，factorial(5)具体执行了：\n\nfactorial(5), 计算5*factorial(4)\nfactorial(4), 计算4*factorial(3)\nfactorial(3), 计算3*factorial(2)\nfactorial(2), 计算2*factorial(1)\nfactorial(1)=1\n最终依次返回\n\n接下来我们展示了一个二分查找的例子，可以证明，以下的二分查找比线性查找更加快速。\n\nplayer_list=[('Messi', 10), ('Xavi', 6), ('ter Stegen', 1), ('Busquets', 5), ('Pique', 3), ('Suárez', 9)]\nplayer_list.sort(key=lambda x:x[1])\ndef search(num,name_list):\n    l=len(name_list)\n    if l==1:\n        if name_list[0][1]==num:\n            return name_list[0][0]\n        else:\n            return None\n    else:\n        l2=l//2\n        if name_list[l2-1][1]&lt;num:\n            return search(num,name_list[l2:])\n        else:\n            return search(num,name_list[0:l2])\nprint(search(10, player_list))\nprint(search(11, player_list))\n\nMessi\nNone\n\n\n\n\n19.3.2 map()、reduce()以及filter()\n函数式编程另外比较常用的特性时map()、reduce()、filter等函数。\n其中，map(func, list)函数接受一个函数func和一个列表list，其作用是将函数func作用与list的每一个元素中。\n值得注意的是，map()语句之后，计算并不会立即执行，而是会返回一个可迭代的对象，等到需要计算值时才进行计算，比如：\n\nnum_list=list(range(10))\nprint(num_list)\nnum_sq_list=map(lambda x: x**2, num_list)\nprint(num_sq_list)\nnum_sq_list=list(num_sq_list)\nprint(num_sq_list)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n&lt;map object at 0x7fb8acf3be48&gt;\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n在以上程序中，我们先使用range()函数产生了一个0…9的列表，接着使用map函数，计算了每个元素的平方。注意到map()函数被调用之后，计算并没有立即执行，返回的是一个map对象。该对象是可迭代的，因而我们可以使用list()函数将其转化为列表。\n或者，更常用的，我们可能会使用reduce()以及filter()函数处理map对象。其中：\n\nreduce(func,iterable_obj)接受一个二元函数，以及一个可迭代的对象iterable_obj，该函数使用func函数依次计算iterable_obj每个的值。\n\n比如，如果iterable_obj=[x1,x2,x3,x4]，那么reduce()函数计算的是：func(func(func(x1,x2),x3),x4)\n\nfilter(func,iterable_ojb)接受一个逻辑函数，以及一个可迭代的对象iterable_obj，该函数的作用是将iterable_obj中带入func返回值为True的子集挑出来。\n\n比如，以下使用reduce() 函数计算了一个列表的和：\n\nfrom functools import reduce\n\nnum_list=[1,3,8,6,9]\nsums=reduce(lambda x, y: x+y, num_list)\nprint(sums)\n\n27\n\n\n以下使用reduce() 函数计算了一个列表的最大值：\n\nfrom functools import reduce\n\nnum_list=[1,3,8,6,9]\nsums=reduce(lambda x, y: max(x,y), num_list)\nprint(sums)\n\n9\n\n\n以下使用reduce() 函数计算了0…9的平方和：\n\nnum_list=list(range(10))\nnum_sq_list=map(lambda x: x**2, num_list)\nsum_sq=reduce(lambda x,y:x+y, num_sq_list)\nprint(sum_sq)\n\n285\n\n\n以下则挑出了所有1,…,9的平方中的所有的能被3整除的数：\n\nnum_list=list(range(10))\nnum_sq_list=map(lambda x: x**2, num_list)\nsub_sq=filter(lambda x:x%3==0, num_sq_list)\nprint(list(sub_sq))\n\n[0, 9, 36, 81]",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>函数</span>"
    ]
  },
  {
    "objectID": "body/01_py_05_class.html",
    "href": "body/01_py_05_class.html",
    "title": "20  类和对象",
    "section": "",
    "text": "20.1 类和对象介绍\n类 （ class）是面向对象编程的基础。面向对象编程通过对客观世界和问题进行高度的抽象，极大简化了编程工作。\n实际上，Python语言同时支持过程式以及函数式编程，完全可以在不定义类的情况下进行编程，但是不可能不使用类：在Python中，几乎所有数据都是以类的形式存在的：包括我们已经频繁使用的整型、浮点型、字符串、列表等等，都是类。\n类是一个抽象的定义，包括了属性和方法。比如，在客观世界中，当我们提到「猫」这一类动物时时，一方面会通过品种、毛色、体重等描述猫，这些是所谓的属性（property）；而方法（method）即猫的动作，比如猫可以吃饭、喝水、爬树等各种动作。\n在Python中，属性即一个类中所定义的变量，而方法即类中定义的函数。在Python中，可以使用class关键字声明一个类：\nclass Cat:\n    weight=8\n    def get_weight(self):\n        return self.weight\nprint(Cat.weight)\nCat.weight=9\nprint(Cat.weight)\n\n8\n9\n以上通过class关键字定义了一个类，名字叫做Cat。Cat类有一个属性，称为weight，默认值为8；此外还有一个方法，称为get_weight()，这个方法所做的就是返回Cat类的weight属性。\n以上定义的是类，经过定义后，还需要经过实例化，变成对象。注意类和对象的区别：类是一个抽象的、统一的集合，对象是类的具体化，可以具有差异性，比如：\nclass Cat:\n    weight=8\n    def get_weight(self):\n        return self.weight\nlucas=Cat()\nlucas.weight=8.5\nhuahua=Cat()\nhuahua.weight=10\nprint(\"weight of lucas\",lucas.get_weight())\nprint(\"weight of huahua\",huahua.get_weight())\nprint(\"weight of cat class\",Cat.weight)\n\nweight of lucas 8.5\nweight of huahua 10\nweight of cat class 8\n注意以上我们使用Cat()创建了一个新的cat对象的实例，或者对象：lucas和huahua，并分别修改了他们的weight属性，接着使用get_weight()方法获得了分别的weight属性，并将其打印出来。\n注意对于对象的属性的修改不影响类的属性。\n注意以上定义过程中的self关键字。self代表这个对象本身。在定义类时，为了使得对象能够调用自身的属性、方法等，都需要使用self关键字，所以在类里面定义方法时，第一个参数都是self。\n此外，有的属性、方法可能只允许在类内部读写，而不允许外部读写，此时可以在属性或者方法名前面加两个下划线，比如：\nclass Cat:\n    __weight=8.5\n    def get_weight(self):\n        return self.__weight\nlucas=Cat()\ntry:\n    print(\"weight of lucas\",lucas.__weight)\nexcept Exception as e:\n    print(e)\nlucas.__weight=9\nprint(\"weight of lucas\",lucas.__weight)\nprint(\"weight of lucas\",lucas.get_weight())\n\n'Cat' object has no attribute '__weight'\nweight of lucas 9\nweight of lucas 8.5\n从上面的运行结果中可以看到，__weight属性在类外是看不到的，强制读取会导致错误。但是如果直接写lucas.__weight，实际上是在lucas对象中新增了一个属性，而非内部的__weight属性。\n但是如果我们调用get_weight()方法，由于该方法是类里面的成员，因而可以访问__weight属性。\n最后，我们需要搞清楚在对象创建时发生了什么。以上我们使用Cat()创建了一个新的对象，但是我们实际上是没有没有创建Cat()函数的，那么这个创建是怎么执行的呢？\n在Cat()调用时，Python会自动搜索类中定义的两个特殊函数：__new__()以及__init__()，并分别执行他们。__new__()函数用于创建对象，__init__()用于初始化对象，称为构造函数。与之对称的，还有__del__()函数，即当对象被删除时使用，称为析构函数。\n一个例子：\nclass Cat:\n    def __init__(self, name, weight=None, age=None):\n        self.name=name\n        self.__weight=weight\n        self.__age=age\n        print(\"cat \",self.name,\" is created.\")\n    def get_weight(self):\n        return self.__weight\n    def get_age(self):\n        return self.__age\n    def set_weight(self,weight):\n        self.__weight=weight\n    def set_age(self,age):\n        self.__age=age\n\nlucas=Cat('Lucas', weight=8.5, age=1.2)\nprint(lucas.get_age())\nlucas.set_age(2.5)\nprint(lucas.get_age())\n\ncat  Lucas  is created.\n1.2\n2.5\n注意在以上代码中，在类Cat的定义中，我们额外定义了一个函数：__init__()函数，该函数除了self之外，还接受name, weight, age等参数。\n而在创建对象时，我们使用的cat()函数的参数实际上就是__init__()函数的参数（除了self），当Cat()执行时，会默认将参数传给__init__()，执行该函数并创建一个新的对象。\n在__init__()中，我们将weight和age两个参数赋值给了__weight、__age两个私有变量。在使用过程中，如果需要重新设置__weight、__age，需要使用set_weight、set_age两个函数。如果需要读取，需要使用get_weight、get_age两个函数。在面向对象编程中，类定义外不直接修改、读取属性，而是通过函数进行读取、修改是非常好的习惯。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>类和对象</span>"
    ]
  },
  {
    "objectID": "body/01_py_05_class.html#继承",
    "href": "body/01_py_05_class.html#继承",
    "title": "20  类和对象",
    "section": "20.2 继承",
    "text": "20.2 继承\n客观世界中有很多分类都是具有层级关系的，比如对生物的分类，就可以分门、纲、目、科、属、种，属于同一种类别的一般享有共同的特征和行为。比如，猫和虎都属于猫科动物，具有很多相同的特征，但是由于属于不同属，因而也有不同的特征。\n在Python中，构造一个类时，可以声明该类继承了另外一个类，比如使用：\nclass Cat(Felidae):\n    pass\n就生命了一个类Cat，该类继承了类Felidae，即Cat类现在具有所有Felidae类的属性、方法。\n在类的定义体中，可以使用super()函数获得其父类，因而如果我们需要调用父类的__init__()函数，只需要使用：super().__init__()就可以了。\n除了继承父类的所有属性和方法外，子类还可以新增属性、方法，或者重新定义父类的属性、方法。\n以下给出了一个例子：\n\nclass Felidae:\n    def __init__(self, name, weight=None, age=None):\n        self.name=name\n        self.__weight=weight\n        self.__age=age\n        print(\"cat \",self.name,\" is created.\")\n    def get_weight(self):\n        return self.__weight\n    def get_age(self):\n        return self.__age\n    def set_weight(self,weight):\n        self.__weight=weight\n    def set_age(self,age):\n        self.__age=age\n    def catch(self):\n        pass\n        \nclass Cat(Felidae):\n    def __init__(self, name, weight=None, age=None, color=None):\n        super().__init__(name=name, weight=weight, age=age)\n        self.color=color\n    def shout(self):\n        print(\"喵~\")\n    def catch(self):\n        print(\"\\N{rat}\")\n\nclass Lion(Felidae):\n    def __init__(self, name, weight=None, age=None, sex=None):\n        super().__init__(name=name, weight=weight, age=age)\n        self.sex=sex\n    def catch(self):\n        print(\"\\N{rabbit}\")\n        \nlucas=Cat(\"Lucas\", color=\"三花\", age=2)\nlucas.catch()\nlucas.shout()\nprint(lucas.get_age())\nprint(\"---------Simba---------\")\nsimba=Lion('Simba', sex='male', weight=200)\nsimba.catch()\nprint(simba.get_weight())\n\ncat  Lucas  is created.\n🐀\n喵~\n2\n---------Simba---------\ncat  Simba  is created.\n🐇\n200\n\n\n在上面的代码中，我们首先定义了一个类：Felidae，接着创建了Felidae的两个子类：Cat和Lion。\n注意在Cat中我们定义了一个新的方法：shout()，该方法是父类Felidae中所没有的。\n而Cat中的color以及Lion中的sex两个属性都是其父类中没有的。\n此外，虽然在Felidae中定义了catch()方法，但是没有做任何操作，而在两个子类中，都重新定义了该方法。",
    "crumbs": [
      "**Python 基础**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>类和对象</span>"
    ]
  },
  {
    "objectID": "body/data_02_data_type.html",
    "href": "body/data_02_data_type.html",
    "title": "21  数据分析是什么？",
    "section": "",
    "text": "21.1 简介\n在数据科学中，探索性数据分析 (EDA) 是一种用于分析数据集以总结其主要特征的技术，通常使用可视化方法。EDA 是数据分析过程中的一个重要步骤，因为它可以帮助我们了解数据的结构、分布和潜在的关系。\nEDA 通常在数据建模之前进行，以便为后续的建模和分析提供基础。它可以帮助我们识别数据中的模式、趋势和异常值，从而为后续的分析提供指导。 EDA 的主要目标是：\nEDA 通常包括以下步骤：",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据分析是什么？</span>"
    ]
  },
  {
    "objectID": "body/data_02_data_type.html#简介",
    "href": "body/data_02_data_type.html#简介",
    "title": "21  数据分析是什么？",
    "section": "",
    "text": "理解数据的分布和结构\n识别数据中的模式和趋势\n识别数据中的异常值\n识别数据中的缺失值\n识别数据中的相关性\n识别数据中的潜在问题\n\n\n\n数据预处理：\n\n数据清洗：处理缺失值、异常值和重复数据\n数据转换：将数据转换为适合分析的格式\n数据标准化：将数据标准化到相同的尺度\n数据分割：将数据分为训练集和测试集\n\n数据可视化：\n\n使用统计图表（如直方图、箱线图、散点图等）查看数据分布\n使用热图和相关矩阵可视化数据之间的关系\n\n使用时间序列图查看数据随时间的变化\n使用地理图查看数据的地理分布\n使用网络图查看数据之间的关系\n\n数据建模：\n\n使用统计模型（如线性回归、逻辑回归等）分析数据\n使用机器学习模型（如决策树、随机森林、支持向量机等）分析数据\n使用深度学习模型（如神经网络等）分析数据\n使用集成学习模型（如随机森林、XGBoost等）分析数据\n\n数据评估：\n\n使用交叉验证评估模型的性能\n使用混淆矩阵评估分类模型的性能\n使用均方误差、平均绝对误差等评估回归模型的性能\n使用 ROC 曲线、AUC 等评估模型的性能\n使用 F1 分数、精确率、召回率等评估模型的性能",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据分析是什么？</span>"
    ]
  },
  {
    "objectID": "body/data_02_data_type.html#数据长啥样",
    "href": "body/data_02_data_type.html#数据长啥样",
    "title": "21  数据分析是什么？",
    "section": "21.2 数据长啥样？",
    "text": "21.2 数据长啥样？\n在进行统计建模之前，我们通常要先对数据有一个全面的了解，这一步就叫做 探索性数据分析 (exploratory data analysis, EDA)。EDA 的目的不是做推断，而是通过图形和汇总统计等手段，对数据的结构、变量的分布特征、变量之间的关系，以及观测值之间的聚集情况进行初步探索。\n有些时候，我们并不清楚数据中有哪些信息，也还没想好要问什么问题，这时 EDA 可以帮助我们发现线索，启发思路。即便研究目标一开始就很明确，EDA 也仍然是不可跳过的环节。我们需要确认：\n\n数据中是否存在缺失值或异常值；\n各变量的分布是否合理，是否符合模型假设；\n变量之间是否存在相关性，其关系是否与理论一致。\n\n只有对数据的“样貌”做到心中有数，后续的建模和推断工作才可能稳妥有效。\n\n21.2.1 变量类型\n在数据分析中，数值变量大致可以分为两类：分类变量 和 数值变量。\n\n分类变量 (categorical variables)：表示事物的类别属性，常见的如性别、地区、行业等。\n\n名义型变量 (nominal)：类别之间没有顺序，例如血型、国籍；\n有序型变量 (ordinal)：类别之间存在等级或顺序关系，例如学历层次 (小学 &lt; 初中 &lt; 高中 &lt; 本科)。\n\n数值变量 (numeric variables)：表示数量大小，既包括取整数的变量，也包括可以取连续小数的变量。\n\n如果某些整数变量的取值非常有限，例如只有 1 到 5 分，我们也可以把它看作分类变量来处理。\n\n\n准确判断变量类型，有助于我们选择恰当的图形展示方法与统计工具，是数据分析中的基本功之一。",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据分析是什么？</span>"
    ]
  },
  {
    "objectID": "body/data_02_data_type.html#数据长啥样从结构化数据说起",
    "href": "body/data_02_data_type.html#数据长啥样从结构化数据说起",
    "title": "21  数据分析是什么？",
    "section": "21.3 数据长啥样？从结构化数据说起",
    "text": "21.3 数据长啥样？从结构化数据说起\n我们日常接触到的数据，大多以表格形式存储，每一行是一个观测对象，每一列是一个变量。这类数据称为 结构化数据 (structured data)，是数据分析中最常见的形式。\n在结构化数据中，每一个变量（字段）通常表示一种特征或属性。根据变量的表现形式与分析方法，变量大致可以分为两类：分类变量 和 数值变量。除此之外，我们在实际项目中还会遇到 非结构化数据 和 半结构化数据，处理方式与建模策略也会有所不同，下面分别介绍。\n\n21.3.1 分类变量与数值变量\n\n21.3.1.1 分类变量 (categorical variables)\n分类变量表示对象所属的类别或属性，不直接反映数量大小。根据是否有顺序，可以进一步区分为两种：\n\n名义型变量 (nominal)：类别之间没有顺序关系，如性别 (男 / 女)、城市名称、省份等。\n有序型变量 (ordinal)：类别之间存在明确的等级顺序，如学历 (小学 &lt; 初中 &lt; 高中 &lt; 本科 &lt; 研究生)、满意度评分 (不满意 &lt; 一般 &lt; 满意 &lt; 非常满意)。\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"性别\": [\"男\", \"女\", \"女\", \"男\"],\n    \"学历\": [\"本科\", \"硕士\", \"博士\", \"本科\"]\n})\nprint(df)\n\n  性别  学历\n0  男  本科\n1  女  硕士\n2  女  博士\n3  男  本科\n\n\n\n继续介绍「数字-文字对应表」，或字典的概念。 目的：便于存储，便于进行数值分析和分类操作\n\n\n\n\n21.3.2 数字-文字对应表的作用\n在数据分析中，使用数字-文字对应表（字典）可以将分类变量转换为数值变量，从而便于进行数值分析和分类操作。例如，将学历从“小学”、“初中”等文字形式映射为数字形式（如 1, 2, 3 等），可以方便地进行排序、统计和回归分析等操作。\n这种映射方式的优点包括：\n\n便于计算：数值变量可以直接用于数学运算和模型训练。\n节省存储空间：数字编码通常比文字占用更少的存储空间。\n提高效率：在大规模数据处理中，数值编码的处理速度通常比文字更快。\n\n以下代码展示了如何通过字典将学历字段映射为对应的数值编码。\n\n# 定义学历映射字典\neducation_mapping = {\n    \"小学\": 1,\n    \"初中\": 2,\n    \"高中\": 3,\n    \"本科\": 4,\n    \"硕士\": 5,\n    \"博士\": 6\n}\n\n# 将学历字段映射为数值编码\ndf[\"学历编码\"] = df[\"学历\"].map(education_mapping)\nprint(df)\n\n  性别  学历  学历编码\n0  男  本科     4\n1  女  硕士     5\n2  女  博士     6\n3  男  本科     4\n\n\n\n21.3.2.1 数值变量 (numeric variables)\n数值变量表示数量大小，可以进行加减乘除等运算，通常又分为：\n\n离散型变量：只能取有限个整数值，如子女数、评分等级、借款次数等。\n连续型变量：可以取任意实数值，如收入、温度、身高、收益率等。\n\n在下面的数据中，虽然三个变量都是数值型变量，但 月薪 通常被视为连续变量，满意度评分 则被视为离散型变量。至于 年龄，则需要根据具体情况来判断：如果年龄只取整数值且在样本中只有不多的几个取值，通常也被视为离散型变量；如果年龄可以取小数值或取值范围很大，则可以视为连续型变量。\n此外，满意度评分 事实上具有两层含义：\n\n一方面，它可以单纯地作为分类依据，把顾客分成几个不同的人群；\n另一方面，从数值上来讲，3 分确实比 2 分高，4 分比 3 分高，因此它也可以作为数值变量来处理。\n\n\ndf = pd.DataFrame({\n    \"年龄\": [25, 32, 28, 40],\n    \"月薪\": [8000, 12000, 10000, 15000],\n    \"满意度评分\": [3, 4, 5, 2]\n})\nprint(df)\n\n   年龄     月薪  满意度评分\n0  25   8000      3\n1  32  12000      4\n2  28  10000      5\n3  40  15000      2\n\n\n\n\n\n21.3.3 半结构化数据：机器可读的接口与嵌入式格式\n半结构化数据 (semi-structured data) 介于结构化与非结构化之间。它没有固定表格格式，但可以通过规则解析提取信息，常见格式包括 JSON、XML、网页嵌入块等。\n在实际项目中，金融与政府数据平台往往提供 API 接口或 JSON 格式数据。例如，某公司年报摘要的接口可能返回如下内容：\n{\n  \"company_name\": \"贵州茅台\",\n  \"stock_code\": \"600519\",\n  \"report_year\": 2023,\n  \"financials\": {\n    \"revenue\": 1360.5,\n    \"net_profit\": 620.3\n  },\n  \"industries\": [\"食品饮料\", \"白酒\"],\n  \"announcement_date\": \"2024-03-25\"\n}\n这类数据可以方便地转化为结构化表格，常用 Python 代码如下：\n\nimport json\nimport pandas as pd\n\ndata = '''\n{\n  \"company_name\": \"贵州茅台\",\n  \"stock_code\": \"600519\",\n  \"report_year\": 2023,\n  \"financials\": {\n    \"revenue\": 1360.5,\n    \"net_profit\": 620.3\n  }\n}\n'''\ninfo = json.loads(data)  # 解析JSON数据\n\n# 打印解析后的数据\nprint(\"公司名称：\", info[\"company_name\"])\nprint(\"净利润：\", info[\"financials\"][\"net_profit\"], \"亿元\")\n\n# 转换为数据框\ndf_info = pd.DataFrame([flat_info])\nprint('-'*50)\nprint(df_info)\n\n公司名称： 贵州茅台\n净利润： 620.3 亿元\n--------------------------------------------------\n   公司名称    股票代码  报告年度  营业收入(亿元)  净利润(亿元)\n0  贵州茅台  600519  2023    1360.5    620.3\n\n\n这种数据结构非常适合用于系统对接、爬虫采集和接口开发，在财经信息系统中使用极为广泛。\n还有些数据虽然表面上存储的很整齐，但也不是结构化数据。例如，网页中的嵌入式格式（如 HTML、Markdown 等）也可以看作半结构化数据。\n\n\n\n\n21.3.4 非结构化数据与整洁数据\n非结构化数据 (unstructured data) 是指没有固定字段或列名的数据，最常见的是文本、图像、音频等。其中，金融研究中常见的非结构化数据包括公司公告、新闻、研报等自然语言文本。例如：\n\n“本公司于 2023 年 6 月 1 日，与建行深圳分行签署贷款协议，贷款金额为 2 亿元，期限 3 年，利率为年化 4.2%。本次贷款以公司部分机器设备作抵押，由控股股东提供担保。若未能按期偿还，将触发违约条款。”\n\n\n“经查，深圳市汇通科技股份有限公司在 2022 年年度报告中存在虚假记载。公司未如实披露其与下属子公司之间的关联交易情况，涉案金额累计达 1.38 亿元，相关资金部分已通过非正常渠道流出。上述行为违反了《证券法》第六十三条第一款的规定。根据《证券法》第二百二十三条的规定，我会决定：对深圳市汇通科技股份有限公司责令改正，给予警告，并处以 600 万元罚款；对时任董事长兼总经理李某某给予警告，处以 120 万元罚款，并采取 5 年市场禁入措施。有关当事人如对本处罚决定不服，可自收到本决定书之日起 60 日内向国务院申请行政复议，或自收到本决定书之日起 6 个月内依法向人民法院提起诉讼。”\n\n\n今年发展主要预期目标是国内生产总值增长 5% 左右，城镇新增就业 1100 万人以上，居民消费价格涨幅在 3%-5% 之间，单位国内生产总值能耗持续下降。要围绕高质量发展这一首要任务，着力推动先进制造业、数字经济、生物医药等战略性新兴产业集群发展，提升现代化产业体系的韧性与安全性。\n鼓励地方因地制宜发展新质生产力，继续实施新能源汽车下乡、智能家电换代等行动，推动重点领域设备更新和消费品以旧换新。坚持绿水青山就是金山银山，强化重点行业污染治理，推进钢铁、电解铝、水泥等行业节能降碳改造，加快构建以新能源为主体的新型电力系统。稳步推进碳达峰碳中和各项工作，推动形成绿色低碳的生产方式和生活方式。\n\n\n21.3.4.1 整洁数据\n在数据清晰阶段，我们要把「非结构化数据 (脏数据)」处理成「结构化数据 (整洁数据)」。\n整洁数据 有三条核心原则 (Source: R for Data Science, Chap5)：\n\n列独立： 每个变量对应一列，每一列只存储一个变量的信息。\n行独立： 每个观测对应一行，每一行只表示一个观测对象。\n原子性： 每个单元格只存储一个值，不能有多个信息混杂在同一个格子里。\n\n\n此外，整洁数据还应遵循以下结构规范：\n\n命名规范性：变量名称应简洁明了，遵循统一规则。多词变量建议使用下划线（如 loan_amount）或驼峰式命名（如 LoanAmount），避免使用过短或含义不明的变量名。\n信息完整性：每个变量应配有清晰的标签说明，明确其含义、单位、取值范围等，确保使用者理解一致。\n缺失值统一性：全表缺失值标记应统一，如统一使用 .、NA 或 NULL 表示缺失，避免混用。\n量纲一致性：同类变量应统一量纲与单位，如统一使用人民币（元）表示金额，统一使用“米”表示长度，避免混杂导致计算错误。\n\n\n\n\n21.3.5 案例：世纪兴达公司的贷款公告\n假设世纪兴达公司 (股票代码：500288) 发布了一则贷款公告：\n\n“本公司于 2023 年 6 月 1 日，与建行深圳分行签署贷款协议，贷款金额为 2 亿元，期限 3 年，利率为年化 4.2%。本次贷款以公司部分机器设备作抵押，由控股股东提供担保。若未能按期偿还，将触发违约条款。”\n\n\n21.3.5.1 清洁数据处理思路\n这段公告以文本段落呈现，信息分散，难以直接用于数据分析，属于典型的非结构化脏数据。我们需要将其中的关键信息提取并整理成结构化数据。\n\n明确目标字段：目标字段包括贷款银行、贷款金额、贷款时间、利率、期限、是否有抵押、抵押品类型与描述、是否有担保、担保情况、违约条款等。\n信息拆解与归类：\n\n贷款银行：建行深圳分行\n贷款金额：200000000（元）\n贷款时间：2023-06-01\n利率：4.20%（年化）\n期限：3 年\n是否有抵押品：是\n抵押品描述：公司部分机器设备\n是否有担保：是\n担保情况：控股股东提供担保\n违约条款：若未能按期偿还，将触发违约条款\n\n格式标准化：\n\n金额统一为阿拉伯数字（单位为元）\n日期统一为“YYYY-MM-DD”格式\n利率保留两位小数，写作百分比\n\n缺失值处理：如公告未提及抵押品价值或担保方式，可设为“未披露”或留空，后续视业务需求再补全。\n\n\n\n21.3.5.2 半整洁数据\n一位同学经过处理后，提取了如下信息：\n\n\n\n字段\n值\n\n\n\n\n银行名称\n建行深圳分行\n\n\n贷款金额\n2 亿元\n\n\n签署时间\n2023 年 6 月 1 日\n\n\n贷款期限\n3 年\n\n\n利率\n4.2%\n\n\n是否有抵押品\n是\n\n\n是否有担保\n是\n\n\n违约条件\n未能按期偿还\n\n\n\n\n\n21.3.5.3 整洁数据\n虽然处理后的数据已经比较规整了，但还没有达到「整洁数据」的要求。进一步处理后，我们可以得到如下表格：\n\n\n\n字段\n值\n\n\n\n\n公司名称\n世纪兴达\n\n\n股票代码\n500288\n\n\n银行名称\n中国建设银行深圳分行\n\n\n贷款金额\n2000000000\n\n\n货币单位\n人民币\n\n\n签署时间\n2023-06-01\n\n\n贷款期限(年)\n3\n\n\n利率\n0.042\n\n\n是否有抵押品\n是\n\n\n抵押品类型\n固定资产\n\n\n抵押品名称\n部分机器设备\n\n\n是否有担保\n是\n\n\n担保人\n控股股东\n\n\n担保人类型\n自然人/法人\n\n\n违约条件\n未能按期偿还\n\n\n\n相比之下，更新后的表格做了如下修改：\n\n增加了“公司名称”和“股票代码”字段，便于后续数据关联；\n将“银行名称”字段从“建行深圳分行”更改为“中国建设银行深圳分行”，便于后续数据关联；\n将“贷款金额”字段转化为数字格式，并增加了“货币单位”字段；\n将“利率”字段转化为小数格式；\n增加了“抵押品类型”和“抵押品名称”字段，便于后续进行分类；\n增加了“担保人”和“担保人类型”字段，便于后续进行分类；\n\n当然，如果数据量比较大，可以删除“是否有抵押品”和“是否有担保”等字段，因为后续数据处理时可以通过“抵押品类型”和“担保人类型”来判断是否有抵押品和担保。另外，表中的布尔值（是/否）也可以用 0 和 1 来表示，一遍节省存储空间。\n\n\n21.3.5.4 大批量数据的处理\n本例仅包含了一家公司的公告，实际分析中我们可能会遇到数万条公告。通常需要按如下流程处理：\n\n人工分析，找出规律。 我们需要随机挑选 50-100 条记录，进行人工分析。主要目的是总结字段特征，并进行统一命名。此过程可能需要反复修正多轮才能形成最终版本。\n程序化处理。了解数据的基本特征和分布情况后，也可以通过正则表达式、分词处理等方法，自动化地提取出“公司名称”、“银行名称”、“贷款金额” 等字段，也可以采用大模型进行自动提取。\n人工审核。程序化处理后，仍然需要人工审核，确保数据的准确性和完整性。可以随机抽取 1%-5% 的数据进行人工审核。\n统计分析。可以借助均值、标准差、分位数等统计指标，以及直方图、箱型图、密度函数图等工具进行可视化，以便确认是否存在异常值。如有异常，可以返回前述步骤修正。\n\n这类任务称为 信息抽取 (information extraction)，通常会使用自然语言处理 (NLP) 工具包（如 NLTK、spaCy、transformers 等）来实现。\n\n\n21.3.5.5 Python 实操\n以下是一个简单的示例，使用正则表达式从文本中提取贷款金额：\n\nimport pandas as pd\nimport re\n\n# Variables from the notebook\ntext = '贷款金额为 2 亿元人民币，期限 3 年，利率为年化 4.2%。'\n\n# 从文本中提取信息并创建数据框\n\n# 提取贷款金额\nif amount:\n    loan_amount = int(float(amount.group(1)) * 1e8)  # 转换为元\nelse:\n    loan_amount = None\n\n# 提取货币单位\ncurrency = \"人民币\"  # 假设货币单位为人民币\n\n# 提取签署时间\nsign_date = \"2023-06-01\"  # 假设签署时间固定\n\n# 提取贷款期限\nif term:\n    loan_term = int(term.group(1))\nelse:\n    loan_term = None\n\n# 提取利率\nif rate:\n    interest_rate = float(rate.group(1)) / 100  # 转换为小数\nelse:\n    interest_rate = None\n\n# 创建数据框\ndata = {\n    \"字段\": [\"贷款金额\", \"货币单位\", \"签署时间\", \"贷款期限(年)\", \"利率\"],\n    \"值\": [loan_amount, currency, sign_date, loan_term, interest_rate]\n}\ndf_output = pd.DataFrame(data)\n\n# 打印数据框\nprint(df_output)\n\n        字段           值\n0     贷款金额   200000000\n1     货币单位         人民币\n2     签署时间  2023-06-01\n3  贷款期限(年)           3\n4       利率       0.042\n\n\n\n\n\n21.3.6 小结\n不同数据类型的核心特征与处理策略如下：\n\n\n\n\n\n\n\n\n数据类型\n示例\n特点与处理方式\n\n\n\n\n结构化数据\nExcel、CSV、DataFrame 表格\n每列为变量，可直接分析建模\n\n\n非结构化数据\n公告文本、PDF、图像、音频\n需先用 NLP 或图像处理方法进行结构化\n\n\n半结构化数据\nJSON、XML、网页嵌入内容\n用规则或工具解析后可转化为结构化形式\n\n\n\n理解不同数据结构，是进入实际分析工作前的重要准备。后续章节中我们将围绕结构化数据展开建模分析，同时逐步引入处理半结构化与非结构化数据的方法。",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据分析是什么？</span>"
    ]
  },
  {
    "objectID": "body/data_02_data_type.html#后续内容数据清洗",
    "href": "body/data_02_data_type.html#后续内容数据清洗",
    "title": "21  数据分析是什么？",
    "section": "21.4 后续内容：数据清洗",
    "text": "21.4 后续内容：数据清洗\n\n21.4.1 缺失值处理\n缺失值是数据分析中常见的问题，处理缺失值的方法有很多，常用的方法包括： - 删除缺失值：直接删除包含缺失值的行或列 - 填充缺失值：使用均值、中位数、众数等方法填充缺失值 - 插值法：使用插值法估计缺失值 - 预测法：使用机器学习模型预测缺失值\n\n\n21.4.2 异常值处理\n异常值是指与其他数据点显著不同的观测值，处理异常值的方法有很多，常用的方法包括： - 删除异常值：直接删除包含异常值的行或列 - 替换异常值：使用均值、中位数、众数等方法替换异常值 - 转换异常值：使用对数变换、平方根变换等方法转换异常值 - 分箱法：将异常值分到其他类别中 - 使用机器学习模型预测异常值 - 使用聚类算法识别异常值\n\n\n21.4.3 重复值处理\n重复值是指数据集中存在多次重复的观测值，处理重复值的方法有很多，常用的方法包括：\n\n删除重复值：直接删除重复的行\n合并处理：将重复值合并为一个观测值 (需要标注重复次数，以便作为权重或后续恢复数据)\n是否存在误标记问题 (独立报表 v.s. 合并报表)",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据分析是什么？</span>"
    ]
  },
  {
    "objectID": "body/data_02_data_type.html#参考资料",
    "href": "body/data_02_data_type.html#参考资料",
    "title": "21  数据分析是什么？",
    "section": "21.5 参考资料",
    "text": "21.5 参考资料\n\n李东风 - 29 探索性数据分析",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据分析是什么？</span>"
    ]
  },
  {
    "objectID": "body/data_02_get_data_GMD.html",
    "href": "body/data_02_get_data_GMD.html",
    "title": "22  获取数据：GMD",
    "section": "",
    "text": "22.1 将数据下载到本地\n数据分析的第一步是获取数据。本章将介绍如何从 Global Macro Data 获取全球宏观经济数据。该数据库涵盖了 243 个国家和地区的 46 个宏观经济变量，包括投资占GDP比重（inv_GDP）、出口占GDP 比重（exports_GDP）、政府支出占 GDP 比重（govexp_GDP）等。 有关该数据库的详细介绍参见：GMD：最新全球宏观数据库-243个国家46个宏观变量。\n我们将详细讲解以下内容：\n通过本章的学习，您将掌握从数据获取到可视化分析的完整流程，为后续的深入研究奠定基础。\n我们需要为本项目设定一个文件夹，将所有数据与脚本统一存放，例如 D:\\Github\\dslian\\body。用 os.chdir() 切过去后，接着通过 pd.read_csv() 直接从网址读取 GMD.csv，约 9 MB，十余秒即可载入为 DataFrame。最后用 to_csv() 保存到本地 data 子目录，并设定 index=False，既留备份，也便于离线复现。\nimport pandas as pd\nimport os\n\nos.chdir(r\"D:\\Github\\dslian\\body\")  # 修改为你的工作路径\n\n# 获取数据并加载到 DataFrame\n''' 9M 左右，下载需要 10-15 秒\nurl = \"https://www.globalmacrodata.com/GMD.csv\"\ndata = pd.read_csv(url)\n\n# 保存数据到 data 文件夹下\ndata.to_csv(\"data/GMD.csv\", index=False)\n'''\n\n# 从 data 文件夹读取数据\ndata = pd.read_csv(\"data/GMD.csv\")\n\n# 查看前几行数据\n# print(data.tail(5))\n\n# 以列表形式输出所有列名\ndata.columns.to_list()\n\n['countryname',\n 'ISO3',\n 'year',\n 'nGDP',\n 'rGDP',\n 'rGDP_pc',\n 'rGDP_USD',\n 'deflator',\n 'cons',\n 'rcons',\n 'cons_GDP',\n 'inv',\n 'inv_GDP',\n 'finv',\n 'finv_GDP',\n 'exports',\n 'exports_GDP',\n 'imports',\n 'imports_GDP',\n 'CA',\n 'CA_GDP',\n 'USDfx',\n 'REER',\n 'govexp',\n 'govexp_GDP',\n 'govrev',\n 'govrev_GDP',\n 'govtax',\n 'govtax_GDP',\n 'govdef',\n 'govdef_GDP',\n 'govdebt',\n 'govdebt_GDP',\n 'HPI',\n 'CPI',\n 'infl',\n 'pop',\n 'unemp',\n 'strate',\n 'ltrate',\n 'cbrate',\n 'M0',\n 'M1',\n 'M2',\n 'M3',\n 'M4',\n 'SovDebtCrisis',\n 'CurrencyCrisis',\n 'BankingCrisis']",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>获取数据：GMD</span>"
    ]
  },
  {
    "objectID": "body/data_02_get_data_GMD.html#中国的数据",
    "href": "body/data_02_get_data_GMD.html#中国的数据",
    "title": "22  获取数据：GMD",
    "section": "22.2 中国的数据",
    "text": "22.2 中国的数据\n\nimport matplotlib.pyplot as plt\n\n# 选择变量列表和国家\nvlist = [\"inv_GDP\", \"exports_GDP\", \"imports_GDP\", \"govexp_GDP\"]\ncname = \"CHN\"\n\n# 筛选出指定国家的数据\nchina_data = data[data[\"ISO3\"] == cname]\n\n# 选择样本范围\nchina_data = china_data[(china_data[\"year\"] &gt;= 1978) & (china_data[\"year\"] &lt;= 2024)]\n\n# 绘制简单的时序图\nplt.figure(figsize=(4,2.5))\nplt.plot(china_data[\"year\"], china_data[\"inv_GDP\"], label=\"inv_GDP\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Value\")\nplt.title(\"Time Series of inv_GDP\")\nplt.legend(loc=\"upper left\")\nplt.grid()\nplt.show()\n\n# 绘制多变量时序图\nplt.figure(figsize=(6, 3))\nfor var in vlist:\n    plt.plot(china_data[\"year\"], china_data[var], label=var)\nplt.xlabel(\"Year\")\nplt.ylabel(\"Value\")\nplt.title(\"Time Series of Multiple Variables\")\nplt.xticks(range(1980, 2026, 5), rotation=40)\nplt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), ncol=1)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n22.2.1 出口份额占比\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# 读取数据\ndata = pd.read_csv(\"data/GMD.csv\")\n\n# 定义年份范围与国家代码\nstart_year = 1900\nend_year = 2024\ncname = [\"USA\", \"DEU\", \"FRA\", \"GBR\", \"JPN\", \"CHN\"]\n\n# 创建以美元计价的出口数据\ndata[\"exports_USD\"] = data[\"exports\"] / data[\"USDfx\"]\n\n# 删除数据质量较差的国家\ninvalid_countries = [\"MMR\", \"SLE\", \"ROU\", \"ZWE\", \"POL\", \"YUG\"]\ndata = data[~data[\"ISO3\"].isin(invalid_countries)]\n\n# 保留必要变量并选择样本区间\ndata = data[[\"ISO3\", \"year\", \"exports_USD\"]].dropna()\ndata = data[(data[\"year\"] &gt;= start_year) & (data[\"year\"] &lt;= end_year)]\n\n# 等价写法\ndata = data.query(\"@start_year &lt;= year &lt;= @end_year\")\n# 筛选出年份在指定范围内的数据\n# 使用 start_year 和 end_year 变量定义的年份范围进行过滤\n# 这里使用了 @varname 的方式来引用变量，@ 符号用于在 query 方法中直接引用 Python 变量\n# 这种写法允许我们在 Pandas 的 query 方法中使用 Python 变量进行动态过滤\n\n# 计算每年全球总出口额\ndata[\"total_exports\"] = data.groupby(\"year\")[\"exports_USD\"].transform(\"sum\")\n\n# 计算每个国家出口占比\ndata[\"export_share\"] = (data[\"exports_USD\"] / data[\"total_exports\"]) * 100\n\n# 保留目标国家与其他国家\ndata = data[data[\"ISO3\"].isin(cname) | (data[\"ISO3\"] != \"\")]\n\n# 计算其他国家（ROW）的出口占比\ndata[\"selected_sum\"] = data.groupby(\"year\")[\"export_share\"].transform(\n    lambda x: x if data[\"ISO3\"].isin(cname).any() else 0\n)\ndata[\"ROW_sum\"] = data.groupby(\"year\")[\"export_share\"].transform(\n    lambda x: x if ~data[\"ISO3\"].isin(cname).any() else 0\n)\n\n# 创建排名变量并标注 ROW 与各国家\nrank_map = {\"USA\": 1, \"FRA\": 2, \"GBR\": 3, \"JPN\": 4, \"CHN\": 5, \"DEU\": 6}\ndata[\"rank\"] = data[\"ISO3\"].map(rank_map)\ndata.loc[~data[\"ISO3\"].isin(cname), \"ISO3\"] = \"ROW\"\ndata.loc[data[\"ISO3\"] == \"ROW\", \"export_share\"] = data[\"ROW_sum\"]\n\n# 保留唯一值并排序，计算累计占比\ndata = data.drop_duplicates(subset=[\"ISO3\", \"year\"]).sort_values(by=[\"year\", \"rank\"])\ndata[\"cum_share\"] = data.groupby(\"year\")[\"export_share\"].cumsum()\n\n# 设置图形样式\nmpl.rcParams.update({\n    \"font.size\": 12,\n    \"axes.titlesize\": 14,\n    \"axes.labelsize\": 12,\n    \"legend.fontsize\": 11,\n    \"xtick.labelsize\": 11,\n    \"ytick.labelsize\": 11,\n    \"figure.dpi\": 100,\n    \"figure.facecolor\": \"white\",\n    \"axes.facecolor\": \"white\",\n    \"axes.edgecolor\": \"black\",\n    \"axes.grid\": True,\n    \"grid.linestyle\": \"--\",\n    \"grid.alpha\": 0.5\n})\n\n# 定义配色方案（对比度高）\nbright_colors = {\n    \"ROW\": \"#33FF00\",    # lime green\n    \"DEU\": \"#0072B2\",    # blue\n    \"CHN\": \"#FF0000\",    # red\n    \"JPN\": \"#CC79A7\",    # purple pink\n    \"GBR\": \"#E69F00\",    # orange\n    \"FRA\": \"#56B4E9\",    # sky blue\n    \"USA\": \"#000000\",    # black\n}\n\n# 定义图例名称映射（替换 ISO3 为更易懂的国家名）\nlabel_map = {\n    \"ROW\": \"Rest of World\",\n    \"USA\": \"United States\",\n    \"DEU\": \"Germany\",\n    \"FRA\": \"France\",\n    \"GBR\": \"United Kingdom\",\n    \"JPN\": \"Japan\",\n    \"CHN\": \"China\"\n}\n\n# 绘制图形\nplt.figure(figsize=(8, 5))\nfor country in [\"ROW\", \"DEU\", \"CHN\", \"JPN\", \"GBR\", \"FRA\", \"USA\"]:\n    subset = data[data[\"ISO3\"] == country]\n    plt.fill_between(subset[\"year\"], \n                     subset[\"cum_share\"],\n                     label=label_map[country],\n                     color=bright_colors[country],\n                     alpha=0.85)\n\n# 设置标题、标签和图例\nplt.xlabel(\"Year\")\nplt.ylabel(\"Share of Global Exports (%)\")\nplt.title(\"Share of Global Exports by Country\", pad=12)\nplt.ylim(0, 100)\nplt.xlim(start_year, end_year)\n\n# 图例设置：右上角、白色背景、透明框\nplt.legend(title=\"Country\", loc=\"upper right\", \n           frameon=True, framealpha=0.9, facecolor=\"white\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n22.2.2 动态图形\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport matplotlib.animation as animation\n\n# 下载数据\n# url = \"https://www.globalmacrodata.com/GMD.csv\"\n# data = pd.read_csv(url)\n\n# 读取数据\ndata = pd.read_csv(\"data/GMD.csv\")\n\n# 参数设置\nstart_year = 1900\nend_year = 2024\nyear_interval = 2  # 动画间隔\nyears = list(range(start_year, end_year + 1, year_interval))\ncname = [\"USA\", \"DEU\", \"FRA\", \"GBR\", \"JPN\", \"CHN\"]\n\n# 数据处理\n# 将出口数据转换为以美元计价\ndata[\"exports_USD\"] = data[\"exports\"] / data[\"USDfx\"]\n\n# 删除数据质量较差的国家\ndata = data[~data[\"ISO3\"].isin([\"MMR\", \"SLE\", \"ROU\", \"ZWE\", \"POL\", \"YUG\"])]\n\n# 保留必要的变量并删除缺失值\ndata = data[[\"ISO3\", \"year\", \"exports_USD\"]].dropna()\n\n# 筛选出指定年份范围内的数据\ndata = data[(data[\"year\"] &gt;= start_year) & (data[\"year\"] &lt;= end_year)]\n\n# 计算每年全球总出口额\ndata[\"total_exports\"] = data.groupby(\"year\")[\"exports_USD\"].transform(\"sum\")\n\n# 计算每个国家的出口占比\ndata[\"export_share\"] = data[\"exports_USD\"] / data[\"total_exports\"] * 100\n\n# 保留目标国家和其他国家的数据\ndata = data[data[\"ISO3\"].isin(cname) | (data[\"ISO3\"] != \"\")]\n\n# 计算目标国家的出口占比总和\ndata[\"selected_sum\"] = data.groupby(\"year\")[\"export_share\"].transform(\n    lambda x: x if data[\"ISO3\"].isin(cname).any() else 0\n)\n\n# 计算其他国家（ROW）的出口占比总和\ndata[\"ROW_sum\"] = data.groupby(\"year\")[\"export_share\"].transform(\n    lambda x: x if ~data[\"ISO3\"].isin(cname).any() else 0\n)\n\n# 将非目标国家标记为 \"ROW\" 并更新其出口占比\ndata.loc[~data[\"ISO3\"].isin(cname), \"ISO3\"] = \"ROW\"\ndata.loc[data[\"ISO3\"] == \"ROW\", \"export_share\"] = data[\"ROW_sum\"]\n\n# 删除重复值，确保每个国家每年只有一条记录\ndata = data.drop_duplicates(subset=[\"ISO3\", \"year\"])\n\n# 设置样式\nmpl.rcParams.update({\n    \"font.size\": 11,\n    \"axes.titlesize\": 15,\n    \"axes.labelsize\": 12,\n    \"figure.dpi\": 100,\n    \"figure.facecolor\": \"white\",\n    \"axes.grid\": True,\n    \"grid.linestyle\": \"--\",\n    \"grid.alpha\": 0.5\n})\n\n# 颜色与国家名映射\nbright_colors = {\n    \"ROW\": \"#33FF00\",\n    \"DEU\": \"#0072B2\",\n    \"CHN\": \"#FF0000\",\n    \"JPN\": \"#CC79A7\",\n    \"GBR\": \"#E69F00\",\n    \"FRA\": \"#56B4E9\",\n    \"USA\": \"#000000\",\n}\nlabel_map = {\n    \"ROW\": \"Others\",\n    \"USA\": \"USA\",\n    \"DEU\": \"Germany\",\n    \"FRA\": \"France\",\n    \"GBR\": \"UK\",\n    \"JPN\": \"Japan\",\n    \"CHN\": \"China\"\n}\n\n# 创建动画\nfig, ax = plt.subplots(figsize=(6, 6))\n\ndef update(year):\n    ax.clear()\n    year_data = data[data[\"year\"] == year].copy()\n    year_data = year_data.groupby(\"ISO3\")[\"export_share\"].sum().reset_index()\n    year_data = year_data.sort_values(\"export_share\", ascending=True)\n    \n    bars = ax.barh(\n        [label_map[c] for c in year_data[\"ISO3\"]],\n        year_data[\"export_share\"],\n        color=[bright_colors.get(c, \"#999999\") for c in year_data[\"ISO3\"]],\n        alpha=0.85\n    )\n    \n    for bar, val in zip(bars, year_data[\"export_share\"]):\n        ax.text(val + 0.5, bar.get_y() + bar.get_height()/2,\n                f\"{val:.1f}%\", va='center', fontsize=10)\n\n    ax.set_xlim(0, 60)\n    ax.set_title(f\"Global Export Share by Country - {year}\")\n    ax.set_xlabel(\"Export Share (%)\")\n    ax.set_ylabel(\"Country\")\n    ax.grid(True, axis=\"x\", linestyle=\"--\", alpha=0.5)\n\nani = animation.FuncAnimation(fig, update, frames=years, interval=600, repeat=False)\n\n# 保存动画（也可改为 .mp4 需要 ffmpeg）\nani.save(\"figs/export_share_animation.gif\", writer=\"pillow\", dpi=120)\n\n\n\n\n\n\n\n\n\n# 显示 GIF 动图\nfrom IPython.display import Image\nImage(filename=\"figs/export_share_animation.gif\")\n\n\n\n\nExport Share Animation",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>获取数据：GMD</span>"
    ]
  },
  {
    "objectID": "body/data_02_get_data_GMD.html#出口份额排名分析",
    "href": "body/data_02_get_data_GMD.html#出口份额排名分析",
    "title": "22  获取数据：GMD",
    "section": "22.3 出口份额排名分析",
    "text": "22.3 出口份额排名分析\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport numpy as np\n\n# 读取数据\ndata = pd.read_csv(\"data/GMD.csv\")\n\n# 主要国家列表\ncname = [\"USA\", \"DEU\", \"FRA\", \"GBR\", \"JPN\", \"CHN\", \"SGP\", \"NLD\", \"ITA\", \"IND\", \"KOR\", \"CAN\"]\nlabel_map = {\n    \"GBR\": \"UK\"\n}\nstart_year = 1980\nend_year = 2024\n\n# 计算出口占比\ndata = data.copy()\nif \"exports_USD\" not in data.columns:\n    data[\"exports_USD\"] = data[\"exports\"] / data[\"USDfx\"]\ndata[\"total_exports\"] = data.groupby(\"year\")[\"exports_USD\"].transform(\"sum\")\ndata[\"export_share\"] = data[\"exports_USD\"] / data[\"total_exports\"] * 100\n\n# 只保留主要国家和年份范围\nrank_data = data[data[\"ISO3\"].isin(cname) & (data[\"year\"] &gt;= start_year) & (data[\"year\"] &lt;= end_year)].copy()\n\n# 计算每年出口排名（1为最大）\nrank_data[\"rank\"] = rank_data.groupby(\"year\")[\"export_share\"].rank(ascending=False, method=\"min\")\n\n# 绘制 bump chart\nplt.figure(figsize=(8, 5))\nfor country in cname:\n    country_data = rank_data[rank_data[\"ISO3\"] == country]\n    plt.plot(\n        country_data[\"year\"],\n        country_data[\"rank\"],\n        label=label_map.get(country, country),\n        linewidth=2\n    )\n    # 标注起止年份的国家名\n    if not country_data.empty:\n        plt.text(\n            country_data[\"year\"].min() - 1,\n            country_data[\"rank\"].iloc[0],\n            label_map.get(country, country),\n            va=\"center\", ha=\"right\", fontsize=10\n        )\n        plt.text(\n            country_data[\"year\"].max() + 1,\n            country_data[\"rank\"].iloc[-1],\n            label_map.get(country, country),\n            va=\"center\", ha=\"left\", fontsize=10\n        )\n\nplt.gca().invert_yaxis()  # 排名1在上\nplt.yticks(np.arange(1, len(cname) + 1))\nplt.xlabel(\"Year\")\nplt.ylabel(\"Rank of Export Share\")\nplt.title(\"Export Share Ranking of Major Countries (1900-2024)\")\nplt.xlim(start_year - 5, end_year + 5)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport numpy as np\n\n# 读取数据\ndata = pd.read_csv(\"data/GMD.csv\")\n\n# 主要国家列表\ncname = [\"USA\", \"DEU\", \"FRA\", \"GBR\", \"JPN\", \"CHN\", \"SGP\", \"NLD\", \"ITA\", \"IND\", \"KOR\", \"CAN\"]\nlabel_map = {\n    \"GBR\": \"UK\"\n}\nstart_year = 1980\nend_year = 2024\n\n# 地区分组与颜色映射\ncountry_region = {\n    \"USA\": \"North America\", \"CAN\": \"North America\",\n    \"DEU\": \"Europe\", \"FRA\": \"Europe\", \"GBR\": \"Europe\",\n    \"ITA\": \"Europe\", \"NLD\": \"Europe\",\n    \"CHN\": \"Asia\", \"JPN\": \"Asia\", \"KOR\": \"Asia\",\n    \"IND\": \"Asia\", \"SGP\": \"Asia\"\n}\nregion_colors = {\n    \"North America\": \"tab:blue\",\n    \"Europe\": \"tab:green\",\n    \"Asia\": \"tab:red\"\n}\n\n# 计算出口占比\ndata = data.copy()\nif \"exports_USD\" not in data.columns:\n    data[\"exports_USD\"] = data[\"exports\"] / data[\"USDfx\"]\ndata[\"total_exports\"] = data.groupby(\"year\")[\"exports_USD\"].transform(\"sum\")\ndata[\"export_share\"] = data[\"exports_USD\"] / data[\"total_exports\"] * 100\n\n# 筛选数据\nrank_data = data[data[\"ISO3\"].isin(cname) & (data[\"year\"] &gt;= start_year) & (data[\"year\"] &lt;= end_year)].copy()\n\n# 计算排名（1为最大）\nrank_data[\"rank\"] = rank_data.groupby(\"year\")[\"export_share\"].rank(ascending=False, method=\"min\")\n\n# 绘图\nplt.figure(figsize=(8, 5))\n\nfor country in cname:\n    country_data = rank_data[rank_data[\"ISO3\"] == country]\n    region = country_region.get(country, \"Other\")\n    color = region_colors.get(region, \"gray\")\n    label = label_map.get(country, country)\n\n    plt.plot(\n        country_data[\"year\"],\n        country_data[\"rank\"],\n        label=label,\n        linewidth=2,\n        color=color\n    )\n\n    # 添加起止年份标签\n    if not country_data.empty:\n        plt.text(\n            country_data[\"year\"].min() - 1,\n            country_data[\"rank\"].iloc[0],\n            label,\n            va=\"center\", ha=\"right\", fontsize=10,\n            color=color\n        )\n        plt.text(\n            country_data[\"year\"].max() + 1,\n            country_data[\"rank\"].iloc[-1],\n            label,\n            va=\"center\", ha=\"left\", fontsize=10,\n            color=color\n        )\n\n# 图形美化\nplt.gca().invert_yaxis()  # 排名 1 在顶部\nplt.yticks(np.arange(1, len(cname) + 1))\nplt.xlabel(\"Year\")\nplt.ylabel(\"Rank of Export Share\")\nplt.title(\"Export Share Ranking of Major Countries (1980–2024)\")\nplt.xlim(start_year - 5, end_year + 5)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n\n# 自定义图例（按地区）\nfrom matplotlib.lines import Line2D\nlegend_elements = [\n    Line2D([0], [0], color=\"tab:blue\", lw=2, label=\"North America\"),\n    Line2D([0], [0], color=\"tab:green\", lw=2, label=\"Europe\"),\n    Line2D([0], [0], color=\"tab:red\", lw=2, label=\"Asia\")\n]\nplt.legend(handles=legend_elements, loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=3)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>获取数据：GMD</span>"
    ]
  },
  {
    "objectID": "body/data_02_get_data_GMD.html#柱状图",
    "href": "body/data_02_get_data_GMD.html#柱状图",
    "title": "22  获取数据：GMD",
    "section": "22.4 柱状图",
    "text": "22.4 柱状图\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 假设 cname 顺序为：[\"USA\", \"CHN\", \"DEU\", \"JPN\", \"FRA\", \"GBR\"]\n# label_map 是国家名映射，如 {\"USA\": \"美国\", ...}\n\n# 筛选 2000 和 2024 年\nselected_years = [2000, 2024]\nfiltered_data = data[data[\"year\"].isin(selected_years) & data[\"ISO3\"].isin(cname)]\nfiltered_data = filtered_data.sort_values(by=[\"year\", \"ISO3\"])\n\n# 准备数据\ndata_2000 = filtered_data[filtered_data[\"year\"] == 2000][\"export_share\"].values\ndata_2024 = filtered_data[filtered_data[\"year\"] == 2024][\"export_share\"].values\n\n# 位置设置\nx = np.arange(len(cname))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(6, 3))\n\n# 绘图（采用 Figure 9B 的配色风格）\nbars1 = ax.bar(x - width / 2, data_2000, width, label=\"2000\", color=\"#174c88\")  # 深蓝色\nbars2 = ax.bar(x + width / 2, data_2024, width, label=\"2024\", color=\"#ec7d31\")  # 橙色\n\n# 添加文字标签\ndef autolabel(bars):\n    for bar in bars:\n        height = bar.get_height()\n        ax.annotate(f'{height:.0f}',\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),  # 垂直偏移\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', fontsize=10)\n\nautolabel(bars1)\nautolabel(bars2)\n\n# 设定坐标轴和标题\nax.set_ylabel(\"Export Share (%)\", fontsize=12)\nax.set_title(\"Shares of Aggregate Export, 2000 and 2024\", fontsize=14, weight='bold')\nax.set_xticks(x)\nax.set_xticklabels([label_map[c] for c in cname], rotation=0)\nax.legend(title=\"Year\")\n\n# 添加 y 轴网格线\nax.yaxis.grid(True, linestyle=\"--\", alpha=0.6)\n\n# 清理图框边线\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n在上图中，export_share 是每个国家的出口额占全球总出口额的百分比，其定义公式如下：\n\\[\n\\text{export\\_share} = \\frac{\\text{exports\\_USD}}{\\text{total\\_exports}} \\times 100\n\\]\n其中： - exports_USD 是该国家的出口额（以美元计价）。 - total_exports 是当年全球所有国家的出口总额（以美元计价）。 - 结果乘以 100，将比例转换为百分比。\n这个指标表示某个国家在全球出口总额中所占的份额，用于衡量该国家在全球贸易中的相对重要性。\nexport_share 和 cum_share 的区别在于它们的计算方式和用途：\n\nexport_share:\n\n表示某个国家在某一年中，其出口额占全球总出口额的百分比。\n是一个单独国家的指标，直接反映该国家在全球出口中的相对重要性。\n计算公式为：\n\\[\n\\mathrm{export\\_share} = \\frac{\\mathrm{exports\\_USD}}{\\mathrm{total\\_exports}} \\times 100\n\\]\n\ncum_share:\n\n表示某一年中，按国家排名累加的出口占比。\n是一个累计指标，反映从排名靠前的国家开始，逐步累加的出口占比。\n例如，如果某一年中：\n\n国家 A 的 export_share 是 10%，\n国家 B 的 export_share 是 15%，\n国家 C 的 export_share 是 20%，\n那么它们的 cum_share 分别是：\n\n国家 A：10%\n国家 B：10% + 15% = 25%\n国家 C：10% + 15% + 20% = 45%\n\n\n\n\n\n22.4.1 总结\n\nexport_share 是单个国家的出口占比。\ncum_share 是按排名累加的出口占比，用于展示多个国家的累计贡献。",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>获取数据：GMD</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html",
    "href": "body/TS_SZ_index.html",
    "title": "23  上证指数的时序特征",
    "section": "",
    "text": "23.1 获取数据\n本讲使用 akshare 库获取上证指数的历史数据，并使用 statsmodels 库进行时间序列分析。主要包括： - 在线获取上证指数的历史数据，包括：收盘价、开盘价、最高价、最低价、成交量等。 - 计算日收益率、周收益率和年化收益率，并采用 matplotlib 库进行可视化。 - 图示收益率的分布特征 - 收益率的直方图、密度函数图等 - 收益率的自相关图、偏自相关图等 - 收益率的波动性分析 - 收益率标准差、方差等\n# 设置起始时间和结束时间\nstart_date = '1991-01-01'\nend_date = datetime.now().strftime('%Y-%m-%d')  # 设置为当前日期\n\n# 获取上证指数的历史数据\nsz_index = ak.stock_zh_index_daily(symbol=\"sh000001\")  # 上证指数代码为 \"sh000001\"\n\n# 重命名列名以便后续处理\nsz_index.rename(columns={'date': 'day', 'close': 'close'}, inplace=True)\n\n# 筛选指定起止时间的数据\nsz_index['day'] = pd.to_datetime(sz_index['day'])  # 确保日期列为 datetime 类型\nsz_index = sz_index[(sz_index['day'] &gt;= pd.to_datetime(start_date)) & (sz_index['day'] &lt;= pd.to_datetime(end_date))]\n\nprint('\\n' + '='*10 + ' Head' + '='*10)\nprint(sz_index.head())  # 显示前几行数据\n\nprint('\\n' + '='*10 + ' Tail' + '='*10)\nprint(sz_index.tail())  # 显示后几行数据\n\n\n========== Head==========\n          day    open    high     low   close  volume\n9  1991-01-02  127.61  128.84  127.61  128.84    9100\n10 1991-01-03  128.84  130.14  128.84  130.14   14100\n11 1991-01-04  131.27  131.44  130.14  131.44   42000\n12 1991-01-07  131.99  132.06  131.45  132.06   21700\n13 1991-01-08  132.62  132.68  132.06  132.68  292600\n\n========== Tail==========\n            day      open      high       low     close       volume\n8387 2025-04-28  3292.056  3296.932  3279.877  3288.415  41066586300\n8388 2025-04-29  3281.445  3294.982  3277.627  3286.655  38896167200\n8389 2025-04-30  3284.081  3292.200  3277.550  3279.031  43579433500\n8390 2025-05-06  3295.250  3316.448  3286.989  3316.114  47436961700\n8391 2025-05-07  3354.974  3356.688  3324.809  3342.665  51115960600",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html#收盘价走势图",
    "href": "body/TS_SZ_index.html#收盘价走势图",
    "title": "23  上证指数的时序特征",
    "section": "23.2 收盘价走势图",
    "text": "23.2 收盘价走势图\n\n23.2.1 静态图形\n\n# 绘制收盘价走势图\nplt.figure(figsize=(14, 7))\nplt.subplot(2, 1, 1)\nplt.plot(sz_index['day'], sz_index['close'], label='Close Price', color='blue')\nplt.title('Shanghai Composite Index Daily Close Price') \nplt.legend()\nplt.grid()\n\n\n\n\n\n\n\n\n\n\n23.2.2 交互图\n接下来，我们使用 plotly 扩展包创建一个交互式折线图。顾名思义，这类图形可以在在鼠标悬停时，显示该时点的日期、收益率等信息。要点如下：\n\n数据准备\n\n时间筛选：通过 start_date 和 end_date 设置起始时间和结束时间，结合 pandas.to_datetime() 函数将日期列转换为标准时间格式，并筛选出指定时间区间内的数据。\n数据合并：使用 merge() 函数将包含日收益率的 DataFrame 与主数据表按照日期列进行合并，使得每一日的收盘价配套显示对应的日收益率。\n\n图形绘制\n\n图层添加：调用 go.Scatter() 添加一条收盘价的折线图（mode='lines' 表示仅显示折线，不显示节点）。\n交互信息：利用 hovertemplate 参数自定义鼠标悬停时显示的内容，包括：日期（格式化为 年-月-日）、收盘价（保留两位小数）、日收益率（百分号格式，保留两位小数）等。\n\n图表布局设置\n\n通过 fig.update_layout() 设置图表标题、坐标轴标题、交互模式等：\n\nhovermode='x unified'：使得交互提示在同一垂直线上统一显示\ntemplate='plotly_white'：采用白色背景模板\n\n设置 margin 确保图形四周留有足够的空间，避免遮挡\n\n\n该图表可嵌入网页或 Jupyter Notebook 中动态展示，是教学、报告与展示金融时间序列数据的有力工具。\n\n# 安装必要的库（如未安装）\n# !pip install plotly akshare pandas\n\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom datetime import datetime\nimport akshare as ak\n\n# 设置起始时间和结束时间\nstart_date = '2005-01-01'\nend_date = datetime.now().strftime('%Y-%m-%d')  # 设置为当前日期\n\n# 获取上证指数的历史数据\nsz_index = ak.stock_zh_index_daily(symbol=\"sh000001\")  # 上证指数代码为 \"sh000001\"\n\n# 重命名列名以便后续处理\nsz_index.rename(columns={'date': 'day', 'close': 'close'}, inplace=True)\n\n# 将日期列转换为 datetime 类型\nsz_index['day'] = pd.to_datetime(sz_index['day'])\n\n# 计算日收益率\nsz_index['daily_return'] = sz_index['close'].pct_change()\n\n# 筛选指定时间区间内的数据\nfiltered_data = sz_index.query(\" @start_date &lt;= day &lt;= @end_date \")\n\n# 创建交互式图形对象\nfig = go.Figure()\n\n# 添加收盘价的折线图\nfig.add_trace(go.Scatter(\n    x=filtered_data['day'],\n    y=filtered_data['close'],\n    mode='lines',  # 只显示线条\n    name='收盘价',\n    line=dict(color='blue'),\n    customdata=filtered_data[['daily_return']].values,\n    hovertemplate=(\n        '&lt;b&gt;日期：&lt;/b&gt; %{x|%Y-%m-%d}&lt;br&gt;'\n        '&lt;b&gt;收盘价：&lt;/b&gt; %{y:.2f}&lt;br&gt;'\n        '&lt;b&gt;日收益率：&lt;/b&gt; %{customdata[0]:.2%}&lt;extra&gt;&lt;/extra&gt;'\n    )\n))\n\n# 设置图表整体布局\nfig.update_layout(\n    title='上证指数交互图',\n    xaxis_title='日期',\n    yaxis_title='收盘价',\n    hovermode='x unified',\n    template='plotly_white',\n    margin=dict(l=60, r=40, t=60, b=50)\n)\n\n# 显示图表\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n23.2.3 钉形图\n钉形图（candlestick chart）是一种常用的金融图表，用于显示某一时间段内的价格波动情况。它通过“钉子”形状的图形来表示开盘价、收盘价、最高价和最低价。钉形图的主要优点在于能够直观地展示价格走势和波动范围，便于分析市场情绪和趋势。\n\n有关钉形图的详细解释，参见 Everything you can do with a time series\n\n钉形图的构建主要包括以下几个步骤： 1. 数据准备：从 akshare 获取上证指数的历史数据，包括开盘价、收盘价、最高价和最低价等。将数据转换为 pandas DataFrame 格式，并设置日期为索引。 2. 图形绘制：使用 plotly.graph_objects 中的 go.Candlestick() 函数创建钉形图。该函数需要传入开盘价、收盘价、最高价和最低价等数据，并设置相应的颜色（上涨为绿色，下跌为红色）。 3. 图表布局设置：通过 fig.update_layout() 设置图表的标题、坐标轴标签、背景颜色等属性。可以使用 plotly 提供的多种模板来美化图表。 4. 交互功能：钉形图支持鼠标悬停时显示详细信息，包括日期、开盘价、收盘价、最高价和最低价等。可以通过设置 hovertemplate 来定制显示内容。\n\nimport plotly.graph_objects as go\n\n# 设置起始时间和结束时间\nstart_date = '2025-01-01'\nend_date = '2025-03-30'\n\n# 筛选绘图所需的列\ncandlestick_data = sz_index.query(\" @start_date &lt;= day &lt;= @end_date \")[['day', 'open', 'high', 'low', 'close']]\n\n# 创建钉形图\nfig = go.Figure(data=[go.Candlestick(\n    x=candlestick_data['day'],       # 日期\n    open=candlestick_data['open'],   # 开盘价\n    high=candlestick_data['high'],   # 最高价\n    low=candlestick_data['low'],     # 最低价\n    close=candlestick_data['close'], # 收盘价\n    increasing_line_color='green',   # 上涨颜色\n    decreasing_line_color='red'      # 下跌颜色\n)])\n\n# 设置图表标题和布局\nfig.update_layout(\n    title='上证指数钉形图',\n    template='plotly_white',\n    xaxis_rangeslider_visible=False,  # 隐藏范围滑块\n    xaxis_tickformat='%Y-%m-%d',  # 设置横轴刻度格式\n    xaxis_tickangle=-30,  # 旋转横轴刻度 -30 度\n)\n\n# 设置横轴刻度间隔\nfig.update_xaxes(\n    tickmode='array',\n    tickvals=candlestick_data['day'][::5],  # 每隔 5 天显示一个刻度\n    ticktext=candlestick_data['day'][::5].dt.strftime('%Y-%m-%d')  # 格式化日期\n)\n\n# 显示图表\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html#收益率",
    "href": "body/TS_SZ_index.html#收益率",
    "title": "23  上证指数的时序特征",
    "section": "23.3 收益率",
    "text": "23.3 收益率\n收益率是金融时间序列分析中的重要指标，通常用于衡量资产价格变动的幅度和速度。我们将计算上证指数的日收益率、周收益率和年化收益率，并进行可视化展示。 - 日收益率：表示某一天的收盘价与前一天收盘价的比值变化，通常用百分比表示。 - 周收益率：表示某一周的收盘价与前一周收盘价的比值变化，通常用百分比表示。 - 年化收益率：表示某一年内的收益率，通常用百分比表示。年化收益率可以通过将日收益率乘以交易天数来计算。\n\n23.3.1 日收益率时序图\n\n计算方法：日收益率 = (今日收盘价 - 昨日收盘价) / 昨日收盘价\n可视化：\n\n使用 plt.plot(x, y) 绘制日收益率的折线图，观察其波动趋势。\n使用 matplotlib 绘制日收益率的直方图和密度函数图，观察其分布特征。\n\n\n\n# 计算日收益率\ndaily_return = sz_index['close'].pct_change()  # 计算日收益率\n\n# 绘制日收益率走势图\n#-- 控制绘图的时间范围\n#start_plot_date = '1991-01-01'\nstart_plot_date = '2019-01-01'\nend_plot_date   = '2025-05-01'\nsz_index_plot = sz_index.query(\" @start_date &lt;= day &lt;= @end_date \")\n\n# 绘制日收益率走势图\nplt.figure(figsize=(16, 8))  # 调整图形尺寸\nplt.subplot(2, 1, 2)\nplt.plot(sz_index_plot['day'], \n         sz_index_plot['daily_return'], \n         label='Daily Return', \n         color='red')\nplt.title('Shanghai Composite Index Daily Return')\nplt.xlabel('Date')\nplt.ylabel('Daily Return')\nplt.legend()\nplt.grid()\nplt.tight_layout()  # 调整子图间距\n\n\n\n\n\n\n\n\n\n\n23.3.2 箱线图（Boxplot）\n箱线图用于展示数据的分布特征，常用于识别数据的集中趋势、离散程度以及可能存在的异常值（outliers）。它特别适合金融数据的分布分析，比如收益率、资产波动率等。\n详情参见：\n箱线图由以下几个核心部分组成：\n\n中位数（Median）：箱体中间的横线，表示数据的第 50 个百分位数。\n第一四分位数（Q1）：箱体下缘，表示数据的第 25 个百分位数。\n第三四分位数（Q3）：箱体上缘，表示数据的第 75 个百分位数。\n四分位距（IQR）：\\(IQR = Q3 - Q1\\)，表示数据的中间 50% 的范围。\n上胡须：延伸至 \\(Q1 - 1.5 \\times IQR\\) 的位置，用于捕捉非异常值的最大范围。\n下胡须：延伸至 \\(Q3 + 1.5 \\times IQR\\) 的位置，用于捕捉非异常值的最小范围。\n异常值（Outliers）：胡须之外的黑点，表示极端收益波动的观察值。\n\n\n     Q1-1.5IQR   Q1   median  Q3   Q3+1.5IQR\n                  |-----:-----|\n  o      |--------|     :     |--------|    o  o\n                  |-----:-----|\nflier             &lt;-----------&gt;            fliers\n                       IQR\n\n# 筛选 20XX 年的数据\nbox_year = 2024\ndf_box_year = sz_index[sz_index['year'] == box_year]['daily_return'].dropna()\n\nplt.figure(figsize=(5, 3))\nplt.boxplot(df_box_year)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n23.3.3 同时呈现多个箱线图\n在实际应用中，可以同时呈现多个箱线图，以便比较不同时间段或不同资产的收益率分布特征。可以使用 matplotlib 的 subplots() 函数创建多个子图，并在每个子图上绘制箱线图。\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 提取年份列\nsz_index['year'] = sz_index['day'].dt.year\n\n# 筛选指定年份的数据\nselected_years = [2000, 2005, 2010, 2015, 2020, 2024]\nfiltered_data = sz_index[sz_index['year'].isin(selected_years)]\n\n# 绘制多个年度的箱型图\nplt.figure(figsize=(6, 3))\nsns.boxplot(x='year', y='daily_return', data=filtered_data, palette='Set3')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\nplt.show()",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html#直方图",
    "href": "body/TS_SZ_index.html#直方图",
    "title": "23  上证指数的时序特征",
    "section": "23.4 直方图",
    "text": "23.4 直方图\n\n23.4.1 何谓直方图？\n直方图（Histogram）是一种用于展示数值型变量分布情况的图形工具。其原理是将数据划分为若干连续、不重叠的区间（称为“bin”或“箱子”），统计每个区间内数据点的数量，并以矩形的高度表示频数或频率。\n设有一组日收益率数据 \\(\\{r_1, r_2, \\ldots, r_n\\}\\)，我们将其划分为 \\(K\\) 个等宽的区间，每个区间的宽度为：\n\\[\nh = \\frac{\\max(r) - \\min(r)}{K}\n\\]\n第 \\(k\\) 个区间为 \\([a_k, a_{k+1})\\)，其频数记为 \\(f_k\\)，那么对应的矩形高度就是 \\(f_k\\)（或标准化后的频率）。绘图过程中，横轴表示收益率区间，纵轴表示该区间的频数或频率。\n\n\n23.4.2 核心代码说明\n以下代码用于绘制上证指数的日收益率直方图：\nsz_index_plot['daily_return'].dropna().hist(bins=200, figsize=(8, 5))\n说明如下：\n\ndaily_return：表示日收益率列。\ndropna()：删除缺失值，避免影响绘图。\nhist()：调用 pandas.DataFrame.hist() 方法，底层封装了 matplotlib.pyplot.hist()。\nbins=200：将数据划分为 200 个等宽区间，越大越平滑，但过大可能导致过度拟合。\n\n\n\n23.4.3 常用参数汇总\n\n\n\n\n\n\n\n\n参数名\n说明\n示例\n\n\n\n\nbins\n设置箱子的数量或箱边界\nbins=50，或 bins=[-0.1, -0.05, 0, 0.05, 0.1]\n\n\ndensity\n是否标准化为概率密度（面积为 1）\ndensity=True\n\n\nfigsize\n图形大小（宽, 高）\nfigsize=(10, 6)\n\n\ncolor\n设置柱体颜色\ncolor='skyblue'\n\n\nalpha\n设置透明度（0~1）\nalpha=0.7\n\n\ngrid\n是否显示网格\ngrid=True\n\n\n\n\n\n23.4.4 实用建议\n\n若要观察收益率的分布是否对称，建议加上垂直参考线，例如均值或中位数。\n若需与正态分布对比，可叠加核密度曲线（使用 seaborn.histplot 或 sns.kdeplot）。\n若数据包含极端值，可调整 xlim 参数限制横轴范围，聚焦主要密度区域。\n\n直方图有助于识别收益率分布的偏态、厚尾特征，是金融时间序列分析中不可或缺的工具之一。\n\n# 绘制日收益率的基本直方图\nsz_index_daily_return = sz_index_plot['daily_return'].dropna()\nsz_index_daily_return.hist(bins=100,  # 设置直方图的柱子数量\n                           color='green', \n                           alpha=0.7, # 设置透明度\n                           figsize=(8, 3))",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html#核密度函数",
    "href": "body/TS_SZ_index.html#核密度函数",
    "title": "23  上证指数的时序特征",
    "section": "23.5 核密度函数",
    "text": "23.5 核密度函数\n核密度函数 (Kernel Density Estimation, KDE) 是一种用于估计未知概率密度函数的非参数方法，适用于连续型数据且不依赖于事先指定的分布形式。其基本思想是：在密度函数的每一个估计点上，根据样本点到该点的距离，使用核函数分配权重并加权平均，从而构建平滑的密度曲线。\n设样本为 \\(x_1, x_2, \\dots, x_n\\)，其密度函数在任意点 \\(x\\) 上的估计形式为：\n\\[\n\\hat{f}_h(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left( \\frac{x - x_i}{h} \\right)\n\\]\n其中：\n\n\\(K(\\cdot)\\) 是核函数（kernel function），通常是一个对称的概率密度函数；\n\\(h &gt; 0\\) 是带宽参数（bandwidth），控制核函数的缩放程度和平滑水平；\n\\(\\hat{f}_h(x)\\) 是点 \\(x\\) 处的密度估计值。\n\n\n23.5.1 核函数\n在实际应用中，核函数的选择对估计结果的影响相对较小，而带宽的设置对估计曲线的光滑程度影响较大。\n核函数的作用可以理解为：在估计点 \\(x\\) 处，根据样本点 \\(x_i\\) 与 \\(x\\) 之间的距离，赋予不同的权重。距离 \\(x\\) 越近的样本点，其权重越大；距离越远，权重越小。通过对所有样本点的加权平均，得到该点的密度估计。将所有位置的估计值拼接起来，即可得到整体的密度函数曲线。\n为了更清楚地理解核函数的加权机制，我们可以对距离进行标准化处理，设：\n\\[\nu_i = \\frac{X_i - c}{h}\n\\]\n则以下两式等价：\n\\[\n|u_i| \\leq 1 \\Longleftrightarrow |X_i - c| \\leq h\n\\]\n记 \\(D_i = |X_i - c|\\)，表示第 \\(i\\) 个观察值与估计点 \\(c\\) 的距离。核函数的任务就是为每个 \\(D_i\\) 分配权重。\n如下图所示，三种典型核函数的权重分配机制具有显著差异：\n\n\nUniform 核：在 \\(|u| \\leq 1\\) 范围内赋予所有观察值相同的权重，超出范围的样本点权重为 0 (相当于弃之不用)。对应的密度估计不具有平滑性，常用于教学演示。\nTriangle 核：采用线性下降的加权方式，距离估计点越近权重越大，边界处权重为 0，估计结果具有一定的连续性。\nEpanechnikov 核：采用抛物线型权重函数，在 \\(u=0\\) 处取得最大值，具有最小均方误差（MSE）性质，估计曲线光滑、效率较高。\nGaussian 核：采用正态分布函数，所有样本点均有非零权重，平滑程度高，适用于大多数实际应用场景。\n\n\n\n23.5.2 核函数的性质\n常见核函数及其表达式：\n\nUniform 核函数 \\(K(u) = \\frac{1}{2} \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\) （也称为 Rectangular 核函数）\nTriangle 核函数 \\(K(u) = (1 - \\left|u\\right|) \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nEpanechnikov 核函数 \\(K(u) = \\frac{3}{4}(1 - u^2) \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nQuartic 核函数 \\(K(u) = \\frac{15}{16}(1 - u^2)^2 \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nTriweight 核函数 \\(K(u) = \\frac{35}{32}(1 - u^2)^3 \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nGaussian 核函数 \\(K(u) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right)\\)\nCosinus 核函数 \\(K(u) = \\frac{\\pi}{4} \\cos\\left(\\frac{\\pi}{2} u\\right) \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\n\n\n核函数通常需要满足以下数学性质：\n\n非负性：\\(K(u) \\geq 0\\)\n单位积分：\\(\\int_{-\\infty}^{\\infty} K(u) \\, du = 1\\)\n对称性：\\(K(u) = K(-u)\\)\n有限的二阶矩：\\(\\int u^2 K(u) \\, du &lt; \\infty\\)\n\n实际使用中，还有一些细节需要注意。例如，部分文献或软件将 \\(\\mathbf{1}\\{|u| \\leq 1\\}\\) 写为 \\(\\mathbf{1}\\{|u| &lt; 1\\}\\)。对于连续变量，两者几乎没有区别；但若数据是离散型的（如整数型变量），则可能影响边界值是否被纳入计算。\n核密度估计的构造可以理解为：以每一个样本点为中心放置一个缩放后的核函数，然后在每一个估计位置 \\(x\\) 上，取所有样本点的核值加权平均。因此，它是一种基于样本加权“局部贡献”的整体平滑过程。\n总结而言：\n\n核函数定义了如何根据样本点与估计点之间的距离分配权重；\n带宽参数决定了每个样本点的影响范围；\n合理选择核函数和带宽参数是核密度估计中最关键的步骤；\n核密度估计为我们提供了一种平滑、灵活且无需模型假设的分布估计方法，广泛应用于经济学、金融学、机器学习等领域的探索性数据分析任务中。\n\n\nimport seaborn as sns\n\n# 日收益率的核密度函数图\nsz_index_plot['daily_return'].plot(kind='kde')  #内置函数\n\n\n\n\n\n\n\n\n\n'''提示词\n用最简单的命令同时呈现 2005, 2010, 2015, 2020 和 2024 年的收益率密度函数图\n'''\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 筛选指定年份的数据\n#selected_years = [2005, 2010, 2015, 2020, 2024]\nselected_years = [2005, 2015, 2024]\nfiltered_data = sz_index[sz_index['day'].dt.year.isin(selected_years)]\n\n# 创建图形对象\nplt.figure(figsize=(5, 3))\n\n# 绘制每个年份的核密度估计图\nfor year in selected_years:\n    sns.kdeplot(\n        data=filtered_data[filtered_data['day'].dt.year == year]['daily_return'].dropna(),\n        label=f'{year}'\n    )\n\n# 添加标题和图例\nplt.title(f'各年度收益率密度函数图)', fontsize=12)\nplt.xlabel('日收益率', fontsize=10)\nplt.ylabel('密度', fontsize=10)\nplt.legend(title='年份')\nplt.grid()\nplt.show()",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html#周收益率和月收益率",
    "href": "body/TS_SZ_index.html#周收益率和月收益率",
    "title": "23  上证指数的时序特征",
    "section": "23.6 周收益率和月收益率",
    "text": "23.6 周收益率和月收益率\n\n周收益率：(本周收盘价 - 上周收盘价) / 上周收盘价\n月收益率：(本月收盘价 - 上月收盘价) / 上月收盘价\n\n\n# 计算每周的收益率\nsz_index['week'] = sz_index['day'].dt.isocalendar().week  # 提取周数\nsz_index['year_week'] = sz_index['day'].dt.year.astype(str) \\\n                        + '-w' \\\n                        + sz_index['week'].astype(str).str.zfill(2)  # 组合年份和周数，周数补零\n\n# 计算每周的收益率\nweekly_return = sz_index.groupby('year_week')['close'].apply(lambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0])\nweekly_return = weekly_return.reset_index()  # 重置索引\nweekly_return.columns = ['Year_Week', 'Weekly_Return']  # 重命名列\n\n# 打印结果\nprint(weekly_return.sort_values(by='Year_Week').tail(10))  # 按时间顺序显示最后20周的收益率\n\n     Year_Week  Weekly_Return\n1729  2025-w09      -0.015455\n1730  2025-w10       0.016769\n1731  2025-w11       0.015863\n1732  2025-w12      -0.017891\n1733  2025-w13      -0.005555\n1734  2025-w14       0.001877\n1735  2025-w15       0.045744\n1736  2025-w16       0.004267\n1737  2025-w17       0.001102\n1738  2025-w18      -0.002854\n\n\n\n# 设置起始时间和结束时间\nstart_week = '2005-w01'\nend_week = '2028-w16'\n\n# 筛选指定时间范围内的数据\nfiltered_weekly_return = weekly_return[(weekly_return['Year_Week'] &gt;= start_week) & \n                                       (weekly_return['Year_Week'] &lt;= end_week)]\n\n# 绘制每周收益率走势图\nplt.figure(figsize=(14, 7))\nplt.plot(filtered_weekly_return['Year_Week'], filtered_weekly_return['Weekly_Return'], label='Weekly Return', color='green')\nplt.title('Shanghai Composite Index Weekly Return')\nplt.xlabel('Year')\nplt.ylabel('Weekly Return')\n\n# 修改 x 轴标签，仅显示年份\nyear_labels = [label.split('-')[0] if label.endswith('-w01') else '' for label in filtered_weekly_return['Year_Week']]\nplt.xticks(ticks=range(len(year_labels)), labels=year_labels, rotation=0)\n\n# 添加 y=0 的水平线\nplt.axhline(y=0, color='red', linestyle='--', linewidth=1)\n\n# 设置 grid，仅显示主要的 grid\nplt.grid(visible=True, which='major', linestyle='-', linewidth=0.3)\n\nplt.legend()\nplt.tight_layout()  # 调整子图间距\nplt.show()  # 显示图形\n\n\n\n\n\n\n\n\n\n23.6.0.1 核心代码解读：\n\nsz_index['day'].dt.isocalendar().week：获取日期的周数。具体而言，dt.isocalendar() 返回一个 DataFrame，其中包含 ISO 日历的年、周和星期几。我们只需要周数，因此使用 .week 来提取它。类似的，可以使用 .dt.isocalendar().month 来获取月份；用 .dt.isocalendar().year 来获取年份。\n\nsz_index['day'].dt.isocalendar().year：获取日期的年份。类似地，使用 .year 来提取年份。\n\nweekly_return = sz_index.groupby('year_week')['close'].apply(lambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0])：对每个周进行分组，计算该周的收益率。具体而言，groupby('year_week') 将数据按年和周进行分组，然后使用 apply() 函数对每个组应用一个 lambda 函数。这个 lambda 函数计算该组的最后一个收盘价和第一个收盘价之间的收益率。\n\napply() 函数的用法：apply() 函数可以对 DataFrame 或 Series 的每一行或每一列应用一个函数。它可以用于数据转换、聚合和其他操作。在这里，我们使用 apply() 函数来计算每个组的收益率。apply() 函数的语法格式为： python       DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwds)\n\nfunc：要应用的函数，可以是 Python 内置函数或自定义函数。\naxis：指定应用函数的轴，0 表示按列应用，1 表示按行应用。默认值为 0。\nraw：如果为 True，则传递原始数据而不是 Series 对象。默认值为 False。\n\nlambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0]：这是一个匿名函数，用于计算每个组的收益率。x 是传递给 lambda 函数的参数，表示当前组的数据。x.iloc[-1] 表示该组的最后一个收盘价，x.iloc[0] 表示该组的第一个收盘价。通过计算这两个值之间的差值并除以第一个收盘价，我们得到了该组的收益率。\n\n\n\n# 列出周收益率绝对值大于 0.2 的周\nhigh_weekly_return = weekly_return[weekly_return['Weekly_Return'].abs() &gt; 0.2]\n\n# 按收益率排序\nhigh_weekly_return = high_weekly_return.sort_values(by='Weekly_Return', ascending=False)  \nprint('\\n' + '---'*5 + 'high weekly return' + '---'*5)\nprint(high_weekly_return)  # 打印结果\n\n# 按时间排序\nhigh_weekly_return = high_weekly_return.sort_values(by='Year_Week')  # 按时间排序\nprint('\\n' + '---'*5 + 'sorted by Year_Week' + '---'*5)\nprint(high_weekly_return)  # 打印结果\n\n\n---------------high weekly return---------------\n     Year_Week  Weekly_Return\n72    1992-w21       1.343377\n0     1991-w01       1.272198\n259   1996-w01       0.704906\n99    1992-w48       0.553815\n1159  2014-w01       0.533468\n186   1994-w31       0.532717\n226   1995-w20       0.470363\n118   1993-w14       0.311382\n309   1997-w01       0.298735\n1415  2019-w01       0.237227\n507   2001-w01      -0.217497\n854   2008-w01      -0.654681\n\n---------------sorted by Year_Week---------------\n     Year_Week  Weekly_Return\n0     1991-w01       1.272198\n72    1992-w21       1.343377\n99    1992-w48       0.553815\n118   1993-w14       0.311382\n186   1994-w31       0.532717\n226   1995-w20       0.470363\n259   1996-w01       0.704906\n309   1997-w01       0.298735\n507   2001-w01      -0.217497\n854   2008-w01      -0.654681\n1159  2014-w01       0.533468\n1415  2019-w01       0.237227",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/TS_SZ_index.html#年化收益率和标准差",
    "href": "body/TS_SZ_index.html#年化收益率和标准差",
    "title": "23  上证指数的时序特征",
    "section": "23.7 年化收益率和标准差",
    "text": "23.7 年化收益率和标准差\n\n\n# 各个年度的收益率和标准差\nsz_index['year'] = sz_index['day'].dt.year  # 提取年份\nannual_stats = sz_index.groupby('year').agg({'daily_return': ['mean', 'std']}).reset_index()\n\n# 重命名列名\nannual_stats.columns = ['Year', 'Mean Daily Return', 'Std Daily Return']\n# 将收益率和标准差转换为百分比，并计算年化收益率和年化标准差\nannual_stats['Mean Daily Return'] = annual_stats['Mean Daily Return'] * 100  # 转换为百分比\nannual_stats['Std Daily Return'] = annual_stats['Std Daily Return'] * 100  # 转换为百分比\nannual_stats['Annualized Return'] = annual_stats['Mean Daily Return'] * 252 / 100  # 年化收益率\nannual_stats['Annualized Std'] = annual_stats['Std Daily Return'] * (252 ** 0.5) / 100  # 年化标准差\n# 打印单数年份的收益率和标准差，小数点后保留三位，四列在同一行呈现\nprint(annual_stats[annual_stats['Year'] % 2 == 1][['Year', 'Mean Daily Return', 'Std Daily Return', 'Annualized Return', 'Annualized Std']].round(3).to_string(index=False))\n\n Year  Mean Daily Return  Std Daily Return  Annualized Return  Annualized Std\n 1991              0.326             0.662              0.821           0.105\n 1993              0.096             3.781              0.243           0.600\n 1995             -0.016             3.103             -0.041           0.493\n 1997              0.133             2.194              0.335           0.348\n 1999              0.089             1.773              0.224           0.281\n 2001             -0.087             1.387             -0.218           0.220\n 2003              0.047             1.143              0.118           0.181\n 2005             -0.027             1.378             -0.067           0.219\n 2007              0.305             2.216              0.768           0.352\n 2009              0.259             1.901              0.653           0.302\n 2011             -0.093             1.156             -0.235           0.183\n 2013             -0.023             1.159             -0.057           0.184\n 2015              0.067             2.447              0.169           0.388\n 2017              0.028             0.547              0.069           0.087\n 2019              0.089             1.140              0.224           0.181\n 2021              0.023             0.881              0.058           0.140\n 2023             -0.013             0.729             -0.033           0.116\n 2025             -0.021             1.152             -0.054           0.183\n\n\n\n# 图示各个年度收益率和标准差\nplt.figure(figsize=(14, 7))\nplt.subplot(2, 1, 1)\nplt.bar(annual_stats['Year'], annual_stats['Mean Daily Return'], color='blue', label='Mean Daily Return')\nplt.title('Annual Mean Daily Return of Shanghai Composite Index')\nplt.xlabel('Year')\nplt.ylabel('Mean Daily Return')\nplt.legend()\nplt.grid()\nplt.subplot(2, 1, 2)\nplt.bar(annual_stats['Year'], annual_stats['Std Daily Return'], color='orange', label='Std Daily Return')\nplt.title('Annual Std Daily Return of Shanghai Composite Index')\nplt.xlabel('Year')\nplt.ylabel('Std Daily Return')\nplt.legend()\nplt.grid()\nplt.tight_layout()  # 调整子图间距\nplt.show()  # 显示图形\n\n\n\n\n\n\n\n\n\n\n# 图示波动率\nplt.figure(figsize=(14, 7))\nplt.subplot(2, 1, 1)\nplt.plot(sz_index['day'], \n         sz_index['daily_return'].rolling(window=30).std(), \n         label='30-Day Rolling Volatility', \n         color='red')\nplt.title('SZ Index Daily Return Volatility')\nplt.xlabel('Date')\nplt.ylabel('Volatility')\nplt.legend()\nplt.grid()\nplt.show()  # 显示图形\n\n\n\n\n\n\n\n\n\n\n# 将日期列转换为 datetime 类型\nsz_index['day'] = pd.to_datetime(sz_index['day'])\n\n# 将收盘价列转换为浮点数类型\nsz_index['close'] = sz_index['close'].astype('float')\n\n# 创建一个示例 DataFrame，用于合并\ndata = pd.DataFrame({'time': sz_index['day'], 'pos_p': [0] * len(sz_index)})\n\n# 合并两个 DataFrame，基于时间列进行内连接\ndata = data.merge(sz_index, left_on='time', right_on='day', how='inner')\n\n# 绘制图表\nplt.figure(figsize=(4, 3))  # 设置图表大小\ndata.index = data['time']  # 将时间列设置为索引\ndata[['pos_p', 'close']].plot(secondary_y=['close'])  # 绘制双 Y 轴图表\nplt.title('SH000001 15min K-line')  # 设置图表标题\nplt.show()  # 显示图表\n\n&lt;Figure size 400x300 with 0 Axes&gt;",
    "crumbs": [
      "**数据分析**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>上证指数的时序特征</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html",
    "href": "body/graph_01_intro.html",
    "title": "24  Python 可视化：简介",
    "section": "",
    "text": "24.1 可视化的目的\n本章简要介绍 Python 可视化的基本概念和一些常用的可视化库。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#可视化的目的",
    "href": "body/graph_01_intro.html#可视化的目的",
    "title": "24  Python 可视化：简介",
    "section": "",
    "text": "数据分布：了解数据的分布情况，识别异常值和趋势。\n数据关系：探索变量之间的关系，识别相关性和因果关系。\n数据模式：识别数据中的模式和规律，帮助进行预测和决策。\n数据传达：通过图形化的方式传达数据的含义和故事，帮助观众理解数据。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#理念和原则",
    "href": "body/graph_01_intro.html#理念和原则",
    "title": "24  Python 可视化：简介",
    "section": "24.2 理念和原则",
    "text": "24.2 理念和原则\n\n颜国强, 2024, 相同的数据、不同的视角：可视化如何影响数据解读, 连享会 No.1503.",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#主要图形类型",
    "href": "body/graph_01_intro.html#主要图形类型",
    "title": "24  Python 可视化：简介",
    "section": "24.3 主要图形类型",
    "text": "24.3 主要图形类型\n\ndata-to-viz.com - 最全面的图形分类\nmatplotlib - 图形种类概览\nseaborn - 图形种类概览\n单变量图：展示单个变量的分布情况，如直方图、箱线图等。\n双变量图：展示两个变量之间的关系，如散点图、热力图等。\n多变量图：展示多个变量之间的关系，如气泡图、平行坐标图等。\n时间序列图：展示随时间变化的数据，如折线图、面积图等。\n地理图：展示地理数据，如地图、热力图等。\n网络图：展示网络数据，如社交网络图、关系图等。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#同一组数据可以用不同的图形展示",
    "href": "body/graph_01_intro.html#同一组数据可以用不同的图形展示",
    "title": "24  Python 可视化：简介",
    "section": "24.4 同一组数据可以用不同的图形展示",
    "text": "24.4 同一组数据可以用不同的图形展示\n\nStory - 各种实例\nVisualizing the world population\nLife expectancy, gdp per capita and population size\n\n可以用 GMD 数据替换这个例子中的数据",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#学习资源",
    "href": "body/graph_01_intro.html#学习资源",
    "title": "24  Python 可视化：简介",
    "section": "24.5 学习资源",
    "text": "24.5 学习资源\n五大扩展包：https://zhuanlan.zhihu.com/p/148748125\n帮我补充\n\n在线教程\n\nMatplotlib 官方文档\n\n实例\n\nThe Python Graph Gallery\nMatplotlib Gallery\nSeaborn 示例\nPlotly 示例\nBokeh 示例\nAltair 示例\n\n各类图形展示\n\n直方图\n散点图\n函数图\n地图\n绘图 notebooks\n\n\n\n24.5.1 在线实例\n\ndata-to-viz.com：提供了多种图表类型的在线实例和解释，适合初学者。\n【pyecharts教程】应该是全网最全的教程了。展示了各种使用 pyecharts 绘制的图表实例，适合初学者和进阶用户。\n\n\n\n24.5.2 官方可视化专栏\n\n美国农业部网站 USDA - Economic Research Service, Charts of Note 专栏提供了很多专业的统计图形展示，附带数据和解释。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#python-绘图命令的基本语法和逻辑",
    "href": "body/graph_01_intro.html#python-绘图命令的基本语法和逻辑",
    "title": "24  Python 可视化：简介",
    "section": "24.6 Python 绘图命令的基本语法和逻辑",
    "text": "24.6 Python 绘图命令的基本语法和逻辑\n\nfile:///D:/Rbook/DSFinance/books/VanderPlas_2023_PDSH_Python_Data_Science_Handbook-2E.pdf#page=281.11，Chap29-35 介绍了很多绘图的语法知识。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#常用的可视化库",
    "href": "body/graph_01_intro.html#常用的可视化库",
    "title": "24  Python 可视化：简介",
    "section": "24.7 常用的可视化库",
    "text": "24.7 常用的可视化库\n\nMatplotlib：最常用的 Python 可视化库，功能强大，支持多种图表类型。\nSeaborn：基于 Matplotlib 的高级可视化库，提供更美观的默认样式和更简便的接口。\nPlotly：交互式可视化库，支持多种图表类型，适合 Web 应用。\nBokeh：另一种交互式可视化库，适合大数据集和实时数据流。\nAltair：基于 Vega-Lite 的声明式可视化库，适合快速创建复杂的图表。\nggplot：基于 Grammar of Graphics 的可视化库，适合统计图表的创建。\nPygal：适合创建 SVG 图表的库，支持多种图表类型。\nFolium：用于创建交互式地图的库，适合地理数据可视化。\nGeopandas：用于处理地理数据的库，支持空间数据的可视化。\nNetworkX：用于创建和可视化网络图的库，适合社交网络分析。\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Ellipse\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\nNUM = 250\n\nells = [Ellipse(xy=np.random.rand(2) * 10,\n                width=np.random.rand(), height=np.random.rand(),\n                angle=np.random.rand() * 360)\n        for i in range(NUM)]\n\nfig, ax = plt.subplots()\nax.set(xlim=(0, 10), ylim=(0, 10), aspect=\"equal\")\n\nfor e in ells:\n    ax.add_artist(e)\n    e.set_clip_box(ax.bbox)\n    e.set_alpha(np.random.rand())\n    e.set_facecolor(np.random.rand(3))\n\nplt.show()",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#手绘风格的图形",
    "href": "body/graph_01_intro.html#手绘风格的图形",
    "title": "24  Python 可视化：简介",
    "section": "24.8 手绘风格的图形",
    "text": "24.8 手绘风格的图形\n\nmatplotlib - 手绘风格的图形",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#按在地上摩擦",
    "href": "body/graph_01_intro.html#按在地上摩擦",
    "title": "24  Python 可视化：简介",
    "section": "24.9 按在地上摩擦",
    "text": "24.9 按在地上摩擦\n\nMake a beautiful scatterplot in a few lines in Python to make your report outstanding\n\n\n\n\n20250512002745",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#动图-交互图",
    "href": "body/graph_01_intro.html#动图-交互图",
    "title": "24  Python 可视化：简介",
    "section": "24.10 动图-交互图",
    "text": "24.10 动图-交互图\n\nPlotly and cufflinks : Advanced Python Data Visualization Libraries",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_01_intro.html#文字标注",
    "href": "body/graph_01_intro.html#文字标注",
    "title": "24  Python 可视化：简介",
    "section": "24.11 文字标注",
    "text": "24.11 文字标注\n\nmatplotlib - 文字标注\nseaborn - 文字标注\n\n\n24.11.1 实例\n举一个小例子，说明如何在图形上标注说明文字，涉及：字号，颜色，位置等特征的设定\n\nimport matplotlib.pyplot as plt\n\n# 创建一个简单的折线图\nplt.plot(x, y, marker='o', label='Data Line')\n\n# 找到最大值点\nmax_x = x[-1]\nmax_y = y[-1]\n\n# 在最大值点标注说明文字\nplt.text(max_x, max_y, f'Max Value\\n({max_x}, {max_y})', \n         fontsize=12, color='green', ha='left', va='bottom')\n\n# 设置标题和轴标签\nplt.title('Line Plot with Annotation')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# 显示图例\nplt.legend()\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# 生成标准正态分布数据\nx = np.linspace(-4, 4, 500)\ny = norm.pdf(x, loc=0, scale=1)\n\n# 绘图\nplt.figure(figsize=(6, 4))\nplt.plot(x, y, label=\"Standard Normal\", color=\"blue\", linewidth=2)\n\n# 设置坐标轴标题和主标题\nplt.xlabel(\"Value\", fontsize=12, color=\"darkred\")     # x 轴标题\nplt.ylabel(\"Density\", fontsize=12, color=\"darkgreen\")  # y 轴标题\nplt.title(\"Standard Normal Distribution\", fontsize=14, color=\"navy\", loc=\"center\")  # 主标题\n\n# 添加图例\nplt.legend(loc=\"upper left\", fontsize=10, frameon=True)\n\n# 添加注释（note）\nplt.annotate(\"Peak at mean = 0\", xy=(0, norm.pdf(0)),\n             xytext=(1, 0.3), fontsize=10,\n             arrowprops=dict(arrowstyle=\"-&gt;\", color=\"red\"))\n\n# 添加自定义文字 text\nplt.text(-3.5, 0.35, \"Note: $\\\\mu = 0$, $\\\\sigma = 1$\",\n         fontsize=10, color=\"black\", style=\"italic\")\n\n# 美化\nplt.grid(True, linestyle=\":\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# 创建一个简单的散点图\nx = [1, 2, 3, 4, 5]\ny = [2, 4, 6, 8, 10]\nplt.scatter(x, y, color='blue')\n\n# 添加说明文字\nplt.text(3, 6, 'This is a point', fontsize=12, color='red', ha='center', va='bottom')\n\n# 设置标题和轴标签\nplt.title('Scatter Plot with Annotation')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\n\n# 显示图形\nplt.show()",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Python 可视化：简介</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html",
    "href": "body/graph_dis_box_violin.html",
    "title": "25  箱型图和小提琴图",
    "section": "",
    "text": "25.1 箱线图（Boxplot）\n数据分析过程中，均值和标准差只能粗略地描述数据的集中趋势和离散程度，但不能反映数据的分布形态、偏态和峰态等特征。本讲介绍两种常用的可视化工具：箱型图（Box Plot）和小提琴图（Violin Plot）。它们能够直观地呈现中位数、25% 分位数、75% 分位数等统计量，更为全面地描述数据的分布特征和可能存在的离群值。\n对于变量 \\(x\\)，我们将其中位数记为 \\(p50\\) 或 \\(Q2\\)，第一四分位数（\\(p25\\)）和第三四分位数（\\(p75\\)）分别记为 \\(Q1\\) 和 \\(Q3\\)。同时，其最大值和最小值分别记为 \\(x_{Max}\\) 和 \\(x_{Min}\\)。\n箱线图由箱体、胡须和异常值三部分组成。\n此处，\\(1.5 \\times IQR\\) 是一个常用的经验值，用于判断数据的异常值。参数 1.5 取决于我们对异常值的定义，通常取值范围在 1.5 到 3 之间。取值越大，表示我们对异常值的定义越宽松。\n下图展示了箱线图结构（上图）与正态分布概率密度函数（下图）之间的对应关系。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#箱线图boxplot",
    "href": "body/graph_dis_box_violin.html#箱线图boxplot",
    "title": "25  箱型图和小提琴图",
    "section": "",
    "text": "箱体：\n\n箱体的上下边缘分别是数据的第一四分位数（\\(Q1\\)）和第三四分位数（\\(Q3\\)）。\n中间的横线表示数据的中位数（Median）。\n箱体的高度表示数据的四分位距（IQR），即 \\(IQR = Q3 - Q1\\)。\n\n胡须：\n\n箱体的上（右）胡须延伸至 \\(B^H = Q3 + 1.5 \\times IQR\\) 的位置 (若 \\(x_{Max} &lt; B^H\\)，则上（右）胡须延伸至 \\(x_{Max}\\))。\n箱体的下（左）胡须延伸至 \\(B_L = Q1 - 1.5 \\times IQR\\) 的位置 (若 \\(x_{Min} &gt; B_L\\)，则下（左）胡须延伸至 \\(x_{Min}\\))。\n\n异常值：\n\n异常值是指超出胡须范围的观测值，通常用圆圈表示。\n\n\n\n\n\n下半部分为标准正态分布曲线，并在横轴上标注了与箱线图中 Q1、Q3 所对应的 \\(\\pm 0.6745\\sigma\\) 位置。可以看到：\n\n红色区域覆盖中间的 50%，对应箱体内部；\n两侧蓝色区域各占 24.65%，与胡须区间一致；\n超出 \\(\\pm 2.698\\sigma\\) 的区域仅占 0.35%，对应箱线图之外的极端值。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#直观感受",
    "href": "body/graph_dis_box_violin.html#直观感受",
    "title": "25  箱型图和小提琴图",
    "section": "25.2 直观感受",
    "text": "25.2 直观感受\n下面，我们模拟生成一个服从 \\(N(0,1)\\) 分布的随机数，\\(N=5000\\)，然后分别绘制其直方图 (核密度函数图)、箱线图和小提琴图 (查看 Codes)。\n📊 数据分布摘要\n├─ 核心趋势\n│  ├─ 均值：  0.02\n│  └─ 中位数：0.03\n├─ 四分位距\n│  ├─ Q1：-0.65\n|  ├─ Q3： 0.69\n│  └─ IQR：1.34 (Q3-Q1)\n├─ 理论边界\n│  ├─ 下限：Q1-1.5IQR = -2.66\n│  └─ 上限：Q3+1.5IQR =  2.70\n└─ 实际极值\n   ├─ 最小值：-3.80\n   └─ 最大值： 3.57\n\n\n%reset -f",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#小提琴图",
    "href": "body/graph_dis_box_violin.html#小提琴图",
    "title": "25  箱型图和小提琴图",
    "section": "25.3 小提琴图",
    "text": "25.3 小提琴图\n小提琴图是箱线图的扩展，除了展示数据的分布特征外，还能显示数据的密度分布。它通过在箱线图的基础上添加一个核密度估计（Kernel Density Estimation, KDE）曲线来实现。小提琴图可以更好地揭示数据的分布形态，尤其是在数据量较大时。\n小提琴图的核心部分与箱线图类似，但它还包含了以下几个要素：\n\n核密度估计（KDE）：小提琴图的两侧展示了数据的密度分布，通常使用高斯核密度估计来平滑数据分布。\n小提琴形状：小提琴图的形状表示数据的分布特征，宽度越大表示数据在该位置的密度越高。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#箱型图与小提琴图的对比",
    "href": "body/graph_dis_box_violin.html#箱型图与小提琴图的对比",
    "title": "25  箱型图和小提琴图",
    "section": "25.4 箱型图与小提琴图的对比",
    "text": "25.4 箱型图与小提琴图的对比\n箱型图和小提琴图都是用于展示数据分布的可视化工具，但它们在信息传达和视觉效果上有所不同。以下是它们的主要区别： - 信息传达：箱型图主要关注数据的集中趋势和离散程度，而小提琴图则同时展示了数据的分布形态和密度信息。 - 视觉效果：箱型图通常较为简洁，适合快速识别数据的基本特征；小提琴图则提供了更丰富的信息，但可能在视觉上显得复杂。 - 数据量：在数据量较小的情况下，箱型图可能更易于理解；而在数据量较大的情况下，小提琴图能够更好地揭示数据的分布特征。\n\n25.4.1 同时呈现多个箱线图\n在实际应用中，可以同时呈现多个箱线图，以便比较不同时间段或不同资产的收益率分布特征。可以使用 matplotlib 的 subplots() 函数创建多个子图，并在每个子图上绘制箱线图。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#模拟分析",
    "href": "body/graph_dis_box_violin.html#模拟分析",
    "title": "25  箱型图和小提琴图",
    "section": "25.5 模拟分析",
    "text": "25.5 模拟分析\n模拟四个序列：N = 100，Python，seed = 42，分布如下： 1. 标准正态分布 2. 左偏分布，有少量离群值 (10%) 3. 右偏分布，有少量离群值 (10%) 4. 对称分布，有大量离群值 (30%)\n统计： 1. 计算四个序列：均值、标准差、min, max, p25, p50, p75, 偏度、峰度； 2. 呈现： - 一张表格，各列为统计量，行索引为序列名称； - 统计量小数点后保留一位有效数字 - 调用必要的包，确保表格美观，统计量最好能在小数点处对齐\n绘图： 1. 1 行 4 列的子图：呈现四个序列的箱线图 2. 1 行 4 列的子图：呈现四个序列的小提琴图 3. 图形尺寸：8x2；y_titck: 取整数，疏密有度； 4. 子图标题用中文，字体为黑体，请假在必要的库 5. 屏蔽警告信息\n\n# 清空内存\n%reset -f \n\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import skew, kurtosis\nfrom tabulate import tabulate\nimport matplotlib.pyplot as plt\n\n# 屏蔽警告信息\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# 设置随机种子以确保结果可复现\nnp.random.seed(42)\n\n# 模拟四个序列\nN = 200\ndata = {\n    \"x1\": np.random.normal(0, 1, N),\n    \"x2\": np.concatenate([np.random.exponential(1, N - 10), np.random.normal(-3, 0.5, 10)]),\n    \"x3\": np.concatenate([np.random.exponential(1, N - 10) * -1, np.random.normal(3, 0.5, 10)]),\n    \"x4\": np.concatenate([np.random.normal(0, 1, N - 30), np.random.normal(0, 5, 30)])\n}\n\n# 统计计算\n# 使用 numpy 计算统计量\nstats = {}\nfor name, values in data.items():\n    stats[name] = {\n        \"Mean\": np.mean(values),\n        \"SD\": np.std(values),\n        \"Min\": np.min(values),\n        \"Max\": np.max(values),\n        \"P25\": np.percentile(values, 25),\n        \"P50\": np.percentile(values, 50),\n        \"P75\": np.percentile(values, 75),\n        \"Skew\": skew(values),\n        \"Kurt\": kurtosis(values)\n    }\n\n# 构建 DataFrame 并保留一位小数\nstats_df = pd.DataFrame(stats).T.round(1)\n\n# 使用 tabulate 美化表格输出\nprint(tabulate(stats_df, headers=\"keys\", \n      stralign=\"right\", floatfmt=\".1f\"))\n\n# 绘制箱线图\nfig, axes = plt.subplots(1, 4, figsize=(8, 2))\nfor ax, (label, values) in zip(axes, data.items()):\n    sns.boxplot(y=values, ax=ax, color=\"gold\")\n    ax.set_title(label, fontsize=10)\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n\nplt.tight_layout()\nplt.show()\n\n# 绘制小提琴图\nfig, axes = plt.subplots(1, 4, figsize=(8, 2))\nfor ax, (label, values) in zip(axes, data.items()):\n    sns.violinplot(y=values, ax=ax, color=\"gold\")\n    ax.set_title(label, fontsize=10)\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n\nplt.tight_layout()\nplt.show()\n\n      Mean    SD    Min    Max    P25    P50    P75    Skew    Kurt\n--  ------  ----  -----  -----  -----  -----  -----  ------  ------\nx1    -0.0   0.9   -2.6    2.7   -0.7   -0.0    0.5     0.1    -0.0\nx2     0.8   1.2   -3.5    4.7    0.2    0.7    1.4    -0.6     3.3\nx3    -0.9   1.4   -8.2    4.0   -1.4   -0.6   -0.2    -0.5     5.1\nx4    -0.0   2.0   -7.8    8.8   -0.9   -0.1    0.8    -0.1     4.6",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#应用实例上证综合指数收益率年度分布",
    "href": "body/graph_dis_box_violin.html#应用实例上证综合指数收益率年度分布",
    "title": "25  箱型图和小提琴图",
    "section": "25.6 应用实例：上证综合指数收益率年度分布",
    "text": "25.6 应用实例：上证综合指数收益率年度分布\n\n# 完整代码：TS_SZ_index.ipynb\n\n\n# 安装必要的库（如未安装）\n# !pip install plotly akshare pandas\n\nimport pandas as pd\nimport akshare as ak\n\n# 获取上证指数的历史数据\nsz_index = ak.stock_zh_index_daily(symbol=\"sh000001\")  # 上证指数代码为 \"sh000001\"\n\n# 重命名列名以便后续处理\nsz_index.rename(columns={'date': 'day', 'close': 'close'}, inplace=True)\n\n# 将日期列转换为 datetime 类型\nsz_index['day'] = pd.to_datetime(sz_index['day'])\n\n# 计算日收益率\nsz_index['daily_return'] = sz_index['close'].pct_change()\n\n# 提取年份列\nsz_index['year'] = sz_index['day'].dt.year\n\n# 去除 open, high, low 列\nsz_index.drop(columns=['open', 'high', 'low'], inplace=True)\n\n# Display the first 3 rows and the last 3 columns\nprint(sz_index.head(3))\nprint('-' * 50)\nprint(sz_index.tail(3))\n\n         day   close  volume  daily_return  year\n0 1990-12-19   99.98  126000           NaN  1990\n1 1990-12-20  104.39   19700      0.044109  1990\n2 1990-12-21  109.13    2800      0.045407  1990\n--------------------------------------------------\n            day     close       volume  daily_return  year\n8391 2025-05-07  3342.665  51115960600      0.008007  2025\n8392 2025-05-08  3351.996  42837776600      0.002791  2025\n8393 2025-05-09  3341.999  39890919100     -0.002982  2025\n\n\n接下来，我们挑选几个特定的年份，绘制其日收益率的箱型图。\n注意，此处，我们使用的是 seaborn 库中的 boxplot() 函数，而不是 matplotlib 中的 boxplot() 函数。前者可以更好地处理数据的分组和分类，并且提供了更多的可视化选项。\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 筛选指定年份的数据\n#selected_years = [1995, 1997, 2005, 2006, 2007, 2014, 2015, 2021, 2024]\nselected_years = [1997, 2005, 2006, 2007, 2014, 2015, 2021, 2024]\nfiltered_data = sz_index[sz_index['year'].isin(selected_years)]\n\n# 绘制多个年度的箱型图\nplt.figure(figsize=(6, 3))\nsns.boxplot(x='year', y='daily_return', \n            data=filtered_data, palette='Set3')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n该图为多个特定年份的深证成指日收益率的箱线图，涵盖了 1997、2005、2006、2007、2014、2015、2021 和 2024 年等八个代表性年份，展示了每年交易日中日收益率的分布情况。\n从中位数线（箱体中间的横线）来看：\n\n中位数大于零。1997年、2006 年、2007 年和 2015 年的中位收益率明显高于零，说明这些年份中有超过一半的交易日呈现正收益，整体市场偏强。\n中位数接近于零。2014 年、2021 年和 2024 年中位数趋近于零，意味着正负收益天数接近持平。\n中位数小于零。2005 年中位收益率低于零，表明该年中大部分交易日处于负收益区间，市场情绪低迷。\n\n从箱体的高度 (即 \\(IQR = Q3 - Q1\\)) 和胡须长度来看： - 箱体高度较高，胡须较长。1997 年、2007 年和 2015 年的箱体高度较高，且胡须较长，表明这几年的年内收益波动性较大，市场情绪起伏明显。 - 箱体高度较低，胡须较短。2021 年的箱体很低，胡须也很短，上下胡须外侧的离群值也很少。可以推断，该年是一个大熊市，市场情绪低迷，整体波动性较小。\n从离群点来看： - 1997 年的箱型图中，上下胡须外侧的离群值点都比较多，说明当年市场波动剧烈，存在较多极端收益的交易日 (如果你绘制 1995 年以前的箱线图，会发现波动更为剧烈，当时没有 10% 日内涨跌幅限制，市场波动性更大)。 - 2007 年和 2015 年的分布特征非常相似，都是在下胡须方向上有较多的离群点，说明存在较多单日大幅下跌的情况。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#特定年份分析",
    "href": "body/graph_dis_box_violin.html#特定年份分析",
    "title": "25  箱型图和小提琴图",
    "section": "25.7 特定年份分析：",
    "text": "25.7 特定年份分析：\n\n2005 年 vs 2006 年：\n\n2005 年的箱体整体较低，中位数为负，且上胡须较短，反映当年大部分交易日处于负收益区间，市场情绪低迷。\n2006 年则大为反转，中位数跃升至零之上，箱体明显上移，收益分布更偏向正区间，显示出市场在牛市初期的积极走势。这一变化与当年“股权分置改革推进、人民币升值预期增强”等政策背景密切相关。\n\n2024 年：\n\n箱体高度极窄，即 Q75 与 Q25 非常接近，说明日收益率的四分位间距（IQR）很小，波动性低；\n同时，存在较多离群点分布在上下两侧，提示虽然整体震荡区间狭窄，但偶发性的大涨或大跌依然存在，这可能与 AI、芯片等概念股轮动剧烈，但整体指数运行平稳有关。\n\n\n下图呈现了几个特定年份的沪市综合指数的时序图 (codes)，大家可以挑选一些年份，将其收盘价的时序图与上图中对应年份的箱型图进行对比，以便更深入地理解箱型图的含义。\n\n\n\n# 绘制小提琴图\nplt.figure(figsize=(6, 3))\nsns.violinplot(x='year', y='daily_return', \n               data=filtered_data, palette='Set3')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n# https://matplotlib.org/stable/gallery/statistics/boxplot_vs_violin.html\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\n# generate some random test data\nall_data = [np.random.normal(0, std, 100) for std in range(6, 10)]\n\n# plot violin plot\naxs[0].violinplot(all_data,\n                  showmeans=False,\n                  showmedians=True)\naxs[0].set_title('Violin plot')\n\n# plot box plot\naxs[1].boxplot(all_data)\naxs[1].set_title('Box plot')\n\n# adding horizontal grid lines\nfor ax in axs:\n    ax.yaxis.grid(True)\n    ax.set_xticks([y + 1 for y in range(len(all_data))],\n                  labels=['x1', 'x2', 'x3', 'x4'])\n    ax.set_xlabel('Four separate samples')\n    ax.set_ylabel('Observed values')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n25.7.1 Add Jitter\nBy adding a stripplot, you can show all observations along with some representation of the underlying distribution.\n\nSource: Hidden Data Under Boxplot\n\n\n# libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\n \n# Dataset:\na = pd.DataFrame({ 'group' : np.repeat('A',500), 'value': np.random.normal(10, 5, 500) })\nb = pd.DataFrame({ 'group' : np.repeat('B',500), 'value': np.random.normal(13, 1.2, 500) })\nc = pd.DataFrame({ 'group' : np.repeat('B',500), 'value': np.random.normal(18, 1.2, 500) })\nd = pd.DataFrame({ 'group' : np.repeat('C',20), 'value': np.random.normal(25, 4, 20) })\ne = pd.DataFrame({ 'group' : np.repeat('D',100), 'value': np.random.uniform(12, size=100) })\ndf = pd.concat([a,b,c,d,e])\n\n# boxplot\nax = sns.boxplot(x='group', y='value', data=df)\n# add stripplot\nax = sns.stripplot(x='group', y='value', data=df, color=\"orange\", jitter=0.2, size=2.5)\n\n# add title\nplt.title(\"Boxplot with jitter\", loc=\"left\")\n\n# show the graph\nplt.show()",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#小提琴图两个组别",
    "href": "body/graph_dis_box_violin.html#小提琴图两个组别",
    "title": "25  箱型图和小提琴图",
    "section": "25.8 小提琴图：两个组别",
    "text": "25.8 小提琴图：两个组别\n\nseaborn.violinplot\n\n\nimport seaborn as sns\n\ndf = sns.load_dataset(\"titanic\")\nsns.violinplot(x=df[\"age\"])\nsns.violinplot(data=df, x=\"class\", y=\"age\", hue=\"alive\", fill=False)\n\n\n\n\n\n\n\n\n\nsns.violinplot(data=df, x=\"class\", y=\"age\", hue=\"alive\", split=True, inner=\"quart\")",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_box_violin.html#参考资料",
    "href": "body/graph_dis_box_violin.html#参考资料",
    "title": "25  箱型图和小提琴图",
    "section": "25.9 参考资料",
    "text": "25.9 参考资料\n\nMatplotlib Documentation\nSeaborn Documentation\nSeaborn Boxplot\nSeaborn Violinplot\nSeaborn Boxplot and Violinplot\nSeaborn - Visualizing categorical data\nBoxplot and Violinplot",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>箱型图和小提琴图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html",
    "href": "body/graph_dis_histogram.html",
    "title": "26  直方图",
    "section": "",
    "text": "26.1 基本原理\n直方图（Histogram）是一种常用的数据可视化工具，用于展示数据的分布情况。通过将数据分成若干区间（bins），并统计每个区间中的数据点数目，并以矩形的高度表示频数、频率或密度。直方图能够直观地反映数据的集中趋势、离散程度以及分布形态。\n设有一组日收益率数据 \\(\\{r_1, r_2, \\ldots, r_n\\}\\)，我们将其划分为 \\(K\\) 个等宽的区间，每个区间的宽度为：\n\\[\nh = \\frac{\\max(r) - \\min(r)}{K}\n\\]\n第 \\(k\\) 个区间为 \\([a_k, a_{k+1})\\)，其频数记为 \\(f_k\\)，那么对应的矩形高度就是 \\(f_k\\)（或标准化后的频率）。绘图过程中，横轴表示收益率区间，纵轴表示该区间的频数或频率。\n# clear all variables\n%reset -f",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html#一个简单的例子",
    "href": "body/graph_dis_histogram.html#一个简单的例子",
    "title": "26  直方图",
    "section": "26.2 一个简单的例子",
    "text": "26.2 一个简单的例子\n为了理解直方图的用途，我们先看一个简单的例子。某学习小组包括 10 名学生，年龄介于 16 岁到 26 岁之间。\n\nimport numpy as np\n\n# Generate the age distribution array\nages = np.array([16] + [18] * 4 + [19] * 4 + [26])\nprint(\"Generated Ages:\", ages)\nprint(\"Number of Students:\", len(ages))\n\nGenerated Ages: [16 18 18 18 18 19 19 19 19 26]\nNumber of Students: 10\n\n\n由于数据量很小，细心的读者可能已经算出了每个年龄的学生人数：16 岁 1 人，18 岁 4 人，19 岁 4 人，26 岁 1 人，甚至会列出如下表格：\n\n\n\n年龄\n16\n18\n19\n26\n\n\n\n\n人数\n1\n4\n4\n1\n\n\n\n通过这种方式，我们可以清楚地看到每个年龄段的学生人数分布情况。在制作上述表格的过程中，我们其实是对原数据进行了分组统计：将原数据分成四组，进而统计每组的人数。采用图形的方式可以更直观地展示上述信息：",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html#频数频率与密度",
    "href": "body/graph_dis_histogram.html#频数频率与密度",
    "title": "26  直方图",
    "section": "26.3 频数、频率与密度",
    "text": "26.3 频数、频率与密度\n频数（Frequency）是指在某个区间内观察值的个数。\n频率 是指该区间内观察值的个数 (\\(n_k\\)) 占总观察值个数 (\\(n\\)) 的比例。有时也会把「频率」称为「相对频数 (Relative Frequency)」或「占比 (proportion)」，计算公式为：\n\\[\nf_k = \\frac{n_k}{n}\n\\]\n显然，频率的总和为 1，即 \\(\\sum_{k=1}^{K} f_k = 1\\)。\n密度（Density）是指单位区间内的频率，通常用于归一化处理。密度可以通过以下公式计算： \\[\nd_k = \\frac{f_k}{h}\n\\]\n其中，\\(d_k\\) 是第 \\(k\\) 个区间的密度，\\(h\\) 是区间宽度。密度的总和不一定为 1，而是满足 \\(\\sum_{k=1}^{K} d_k \\cdot h = 1\\)。对于连续变量，当区间宽度趋近于 0 时，密度函数的极限就是概率密度函数（PDF）。\n此外，绘制直方图时，若纵轴是频率，则取值范围为 \\([0, 1]\\)；若纵轴是密度，则取值范围为 \\([0, \\infty)\\) (因为，当 \\(h\\) 趋近于 0 时，\\(d_k\\) 可以趋近于无穷大)。\n从三者的定义也可以看出，无论纵轴为频数、频率还是密度，最终的直方图形状是一样的，只是纵轴的数值不同。\n\n# 列表呈现频数、频率和密度\n\nimport pandas as pd\n\n# 计算唯一值及其计数\nunique, counts = np.unique(ages, return_counts=True)\n\n# 计算频率\nfrequencies = counts / counts.sum()\n\n# 计算带宽 h\nK = 4  # Number of bins\nh = (ages.max() - ages.min()) / K\nprint(\"Bandwidth (h):\", h)\n\n# 计算密度\ndensity = frequencies / h\n\n# 创建一个 DataFrame 包含计数、频率和密度\ntabulated_ages = pd.DataFrame({\n    \"count\": counts,\n    \"frequency\": frequencies,\n    \"density\": density\n}, index=unique)\n\n# 显示更新后的表格\nprint(tabulated_ages)\n\nBandwidth (h): 2.5\n    count  frequency  density\n16      1        0.1     0.04\n18      4        0.4     0.16\n19      4        0.4     0.16\n26      1        0.1     0.04\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 绘制图形\nfig, axes = plt.subplots(1, 3, figsize=(9, 3))\n\n# 子图 1: 频数分布柱状图\naxes[0].bar(unique, counts, color='skyblue', edgecolor='black')\naxes[0].set_ylabel('Frequency')\naxes[0].set_yticks(range(max(counts) + 1))\n\n# 子图 2: 频率分布柱状图\naxes[1].bar(unique, frequencies, color='lightgreen', edgecolor='black')\naxes[1].set_ylabel('Relative Frequency')\n\n# 子图 3: 密度分布柱状图\naxes[2].bar(unique, density, color='salmon', edgecolor='black')\naxes[2].set_ylabel('Density')\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html#直方图的绘制",
    "href": "body/graph_dis_histogram.html#直方图的绘制",
    "title": "26  直方图",
    "section": "26.4 直方图的绘制",
    "text": "26.4 直方图的绘制\n简单而言，绘制直方图的基本步骤为：\n\n选择区间数：根据数据的范围和分布情况，选择合适的区间数 \\(K\\)。\n计算区间宽度：根据数据的最大值和最小值，计算每个区间的宽度 \\(h\\)。\n统计频数：统计每个区间内的数据点数量，得到频数 \\(f_k\\)。\n绘制直方图：使用绘图工具将频数、频率或密度绘制成直方图，横轴表示区间，纵轴表示频数、频率或密度。\n\n下面做详细介绍。\n假设我们有一组数据 \\(\\{x_1, x_2, \\ldots, x_N\\}\\)，绘制直方图的主要步骤如下： &gt;Step 1： 确定区间总数（K）\n将数据划分为 \\(K\\) 个区间。常见的选择区间总数的方法有：\n\n经验法则：通常取 \\(K = 10\\) 或 \\(K=20\\)。\n斯特金斯法则（Sturges’ Rule）\n\\[K = \\lceil \\log_2 N + 1 \\rceil\\]\n其中，\\(\\lceil z \\rceil\\) 表示对 \\(z\\) 向上取整。\n费根纳法则（Freedman-Diaconis Rule）\n\\[K = \\lceil \\frac{2 \\cdot IQR \\cdot N^{-\\frac{1}{3}}}{h} \\rceil\\]\n其中，\\(IQR\\) 为四分位距，\\(h\\) 为区间宽度。\n相机调整法则（Rice Rule） 在 Stata 中，区间总数 \\(K\\) 的选取与样本数 \\(N\\) 有关：\n\\[K = \\min \\left\\{\\sqrt{N}, \\frac{10 \\ln(N)}{\\ln(10)}\\right\\}\\]\n该方法结合平方根法则和对数法则，适用于不同规模的数据集。当 \\(N&lt;784\\) 时，可直接采用 \\(\\sqrt{N}\\) 快速计算。\n\n\nStep 2： 确定区间宽度\n\n区间宽度 \\(h\\) 根据数据的范围和区间总数 \\(K\\) 确定： \\[\nh = \\frac{\\max(x) - \\min(x)}{K}\n\\]\n\nStep 3： 确定区间边界\n\n设数据的最小值为 \\(x_{\\min}\\)，最大值为 \\(x_{\\max}\\)，则区间的边界可以表示为：\n\\[\nb_k = x_{\\min} + (k-1) \\cdot h \\quad \\text{for } k = 1, 2, \\ldots, K+1\n\\]\n每个区间为 \\([b_k, b_{k+1})\\)，最后一个区间为 \\([b_K, b_{K+1}]\\)。\n\nStep 4： 统计每个区间的观察值个数\n\n统计每个区间内的观察值个数，即每个区间的频数 \\(f_k\\)：\n\\[\nf_k = \\sum_{j=1}^{N} I(b_k \\leq x_j &lt; b_{k+1}) \\quad \\text{for } k = 1, 2, \\ldots, K\n\\]\n其中 \\(I(\\cdot)\\) 为指示函数，当条件为真时，取值为 \\(1\\)，否则取值为 \\(0\\)。\n\nStep 5： 绘制直方图\n\n绘制直方图时，将每个区间的频数 \\(f_k\\) 作为柱状图的高度。对于区间 \\([b_k, b_{k+1})\\)，其对应的柱状图高度为 \\(f_k\\)，宽度为 \\(h\\)。\n当然，也可以根据需要用频率或密度来绘制直方图。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html#python-实操",
    "href": "body/graph_dis_histogram.html#python-实操",
    "title": "26  直方图",
    "section": "26.5 Python 实操",
    "text": "26.5 Python 实操\n\n'''\n**提示词**\n生成 age 变量，取值范围 16-35 岁，N = 100，基本服从正态分布。\n然后绘制直方图，并给出解释，尤其是带宽的选择。\n'''\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 生成年龄分布数据\nnp.random.seed(1234)  # For reproducibility\nage = np.random.normal(loc=21, scale=7, size=100).astype(int)\nage = age[(age &gt;= 16) & (age &lt;= 35)]  # Restrict values to the range 16-35\n\n# 绘制直方图\nplt.figure(figsize=(3, 3))\nplt.hist(age, edgecolor='black', alpha=0.7) \nplt.show()\n\n\n\n\n\n\n\n\n本例中，我们只在 plt.hist() 函数中指定了变量名 age，而没有指定 bins 和 rwidth 参数。此时，函数会自动选择合适的区间数量和宽度。根据数据的分布情况，函数会将数据划分为 10 个区间，并计算每个区间内的数据点数量。\n我们也可以自行制定 bins 和 rwidth 参数。如下命令的效果与上面相同：\nK = 10                           # Number of bins\nh = (age.max() - age.min()) / K  # Bandwidth\n\n# 指定 bins 数量\nplt.hist(age, bins=K,   edgecolor='black', alpha=0.7)\n\n# 指定 rwidth\nplt.hist(age, rwidth=h, edgecolor='black', alpha=0.7)\n\n'''Prompt\n绘制一行图形，3 个子图，分别设定 K=4, K=10, K=20。\n横轴刻度采用图形标题，横轴和纵轴标题等信息，做最基本的图形即可\n'''\n\nfig, axes = plt.subplots(1, 3, figsize=(6, 2)) # 3 个子图\n\nK_values = [4, 10, 20]   # 设置三种 K 值\n\n# Plot histograms for each K\nfor i, K in enumerate(K_values):\n    axes[i].hist(age, bins=K, edgecolor='black', alpha=0.7)\n    axes[i].set_title(f'K={K}')          # 设置标题\n    axes[i].set_yticks(range(0, 32, 5))  # 重要！三个子图的 y 轴刻度一致\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n从上图中可以看出：\n\n不同的 bins 会导致直方图的分组方式不同，从而影响数据分布的可视化效果。较少的 bins 会导致信息的过度简化，而较多的 bins 则可能使图形过于复杂，难以观察整体趋势。\n为了增加对比对，我们设定了 axes[i].set_yticks(range(0, 32, 5))。可以看出，当我们划分的组数较多时 (bins 值较大)，落入每个区间的数据点数量自然会相对变少，导致直方图的高度不均匀，且可能出现一些区间的高度为 0 的情况。因此，过大的 bins 值虽然能够提供更精细的分布信息，但也可能导致我们「只见树木，不见森林」。\n\n多数情况下，我们都无需手动指定 bins 和 rwidth 参数，直接使用 plt.hist() 函数自动选择的最优值即可。\n\n26.5.1 plt.hist() 函数详解\nplt.hist() 函数是 matplotlib 库中用于绘制直方图的函数。其基本语法如下：\nplt.hist(x, bins=None, range=None, density=False, \n         weights=None, cumulative=False, bottom=None, \n         histtype='bar', align='mid', orientation='vertical', \n         rwidth=None, \n         color=None, edgecolor=None, alpha=None, \n         label=None, stacked=False, **kwargs)\n其中，常用参数如下：\n\nx：表示要绘制直方图的数据，可以是列表、数组或 pandas 的 Series 对象。\nbins：表示区间的数量或边界，可以是整数或列表。若为整数，则表示将数据划分为 bins 个等宽区间；若为列表，则表示指定每个区间的边界。如 bins=20，或 bins=[-0.1, -0.05, 0, 0.05, 0.1]\ndensity：布尔值，表示是否将直方图标准化为概率密度（面积为 1）。默认为 False。\nweights：表示每个数据点的权重，可以是与 x 等长的数组。\ncumulative：布尔值，表示是否绘制累积直方图。默认为 False。\nbottom：表示每个柱子的底部位置，可以是与 x 等长的数组。\nhisttype：表示直方图的类型，可以是 'bar'、'step' 或 'stepfilled'。\nalign：表示柱子的对齐方式，可以是 'left'、'mid' 或 'right'。\norientation：表示柱子的方向，可以是 'vertical' 或 'horizontal'。\nrwidth：表示柱子的宽度，可以是一个浮点数，表示相对于区间宽度的比例。\ncolor：表示柱子的颜色，可以是字符串或 RGB 值。\nedgecolor：表示柱子的边框颜色。\nalpha：表示柱子的透明度，可以是一个浮点数，范围在 0 到 1 之间。\nlabel：表示图例标签。\nstacked：布尔值，表示是否堆叠直方图。默认为 False。\nkwargs：其他参数，可以传递给 matplotlib 的绘图函数，例如 figsize=(10, 6)。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html#注意事项",
    "href": "body/graph_dis_histogram.html#注意事项",
    "title": "26  直方图",
    "section": "26.6 注意事项",
    "text": "26.6 注意事项\n在比较直方图时，为了便于观察差异，建议将直方图垂直排列，以便更直观地观察横向变化。例如，尝试比较图中顶部的两个直方图。若将两个直方图水平排列，通常会因横向偏移而难以识别它们之间的差异。\n\n\n\n直方图对比示例\n\n\n\n图：当排列直方图以便于比较时，建议垂直对齐以观察横向变化。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_histogram.html#扩展阅读",
    "href": "body/graph_dis_histogram.html#扩展阅读",
    "title": "26  直方图",
    "section": "26.7 扩展阅读",
    "text": "26.7 扩展阅读\n\n26.7.1 直方图实例\nThis Python code creates a histogram using the Matplotlib library to visualize data about salaries in France. It was originally produced by the INSEE.\n\n\nSource: Histogram with custom style and annotations\n\n\n\n26.7.2 Python\n\nmatplotlib - Histogram bins, density, and weight。详细介绍了 bins 的选择对直方图形状的影响，以及密度的概念。\nScatter plot with histograms\nseaborn - distribution\n\n\n\n26.7.3 Stata\n\n万莉, 2020, Stata绘图全解：绘图语法-条形图-箱型图-散点图-矩阵图-直方图-点图-饼图, 连享会 No.34.\n万莉, 2020, Stata：读懂直方图, 连享会 No.479.\n刘欣妍, 史柯, 2022, Stata：描述性统计分析新命令-dstat, 连享会 No.926.\n孙晓艺, 2024, Stata绘图大礼包：27个常用的可视化范例及代码, 连享会 No.1372.\n汪京, 2024, multihistogram-多变量直方图, 连享会 No.1457.\n袁子晴, 2021, 史上最牛Stata绘图模板-schemepack：酷似R中的ggplot2, 连享会 No.819.\n谢嘉伟, 2024, Stata 绘图：binscatterhist-分仓散点图+直方图, 连享会 No.1506.\n郑宇, 2024, Stata绘图：加权直方图, 连享会 No.1425.",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>直方图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_kdensity.html",
    "href": "body/graph_dis_kdensity.html",
    "title": "27  核密度函数图",
    "section": "",
    "text": "27.1 核密度估计\n核密度估计 (Kernel Density Estimation, KDE) 是一种用于估计未知概率密度函数的非参数方法，适用于连续型数据且不依赖于事先指定的分布形式。其基本思想是：在密度函数的每一个估计点上，根据样本点到该点的距离，使用核函数分配权重并加权平均，从而构建平滑的密度曲线。\n设样本为 \\(x_1, x_2, \\dots, x_n\\)，其密度函数在任意点 \\(x\\) 上的估计形式为：\n\\[\n\\hat{f}_h(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left( \\frac{x - x_i}{h} \\right)\n\\]\n其中：",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>核密度函数图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_kdensity.html#核密度估计",
    "href": "body/graph_dis_kdensity.html#核密度估计",
    "title": "27  核密度函数图",
    "section": "",
    "text": "\\(K(\\cdot)\\) 是核函数（kernel function），通常是一个对称的概率密度函数；\n\\(h &gt; 0\\) 是带宽参数（bandwidth），控制核函数的缩放程度和平滑水平；\n\\(\\hat{f}_h(x)\\) 是点 \\(x\\) 处的密度估计值。\n\n\n27.1.1 核函数\n在实际应用中，核函数的选择对估计结果的影响相对较小，而带宽的设置对估计曲线的光滑程度影响较大。\n核函数的作用可以理解为：在估计点 \\(x\\) 处，根据样本点 \\(x_i\\) 与 \\(x\\) 之间的距离，赋予不同的权重。距离 \\(x\\) 越近的样本点，其权重越大；距离越远，权重越小。通过对所有样本点的加权平均，得到该点的密度估计。将所有位置的估计值拼接起来，即可得到整体的密度函数曲线。\n为了更清楚地理解核函数的加权机制，我们可以对距离进行标准化处理，设：\n\\[\nu_i = \\frac{X_i - c}{h}\n\\]\n则以下两式等价：\n\\[\n|u_i| \\leq 1 \\Longleftrightarrow |X_i - c| \\leq h\n\\]\n记 \\(D_i = |X_i - c|\\)，表示第 \\(i\\) 个观察值与估计点 \\(c\\) 的距离。核函数的任务就是为每个 \\(D_i\\) 分配权重。\n如下图所示，三种典型核函数的权重分配机制具有显著差异：\n\n\nUniform 核：在 \\(|u| \\leq 1\\) 范围内赋予所有观察值相同的权重，超出范围的样本点权重为 0 (相当于弃之不用)。对应的密度估计不具有平滑性，常用于教学演示。\nTriangle 核：采用线性下降的加权方式，距离估计点越近权重越大，边界处权重为 0，估计结果具有一定的连续性。\nEpanechnikov 核：采用抛物线型权重函数，在 \\(u=0\\) 处取得最大值，具有最小均方误差（MSE）性质，估计曲线光滑、效率较高。\nGaussian 核：采用正态分布函数，所有样本点均有非零权重，平滑程度高，适用于大多数实际应用场景。\n\n\n\n27.1.2 核函数的性质\n常见核函数及其表达式：\n\nUniform 核函数 \\(K(u) = \\frac{1}{2} \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\) （也称为 Rectangular 核函数）\nTriangle 核函数 \\(K(u) = (1 - \\left|u\\right|) \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nEpanechnikov 核函数 \\(K(u) = \\frac{3}{4}(1 - u^2) \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nQuartic 核函数 \\(K(u) = \\frac{15}{16}(1 - u^2)^2 \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nTriweight 核函数 \\(K(u) = \\frac{35}{32}(1 - u^2)^3 \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\nGaussian 核函数 \\(K(u) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right)\\)\nCosinus 核函数 \\(K(u) = \\frac{\\pi}{4} \\cos\\left(\\frac{\\pi}{2} u\\right) \\cdot \\mathbf{1}\\{\\left|u\\right| \\leq 1\\}\\)\n\n\n核函数通常需要满足以下数学性质：\n\n非负性：\\(K(u) \\geq 0\\)\n单位积分：\\(\\int_{-\\infty}^{\\infty} K(u) \\, du = 1\\)\n对称性：\\(K(u) = K(-u)\\)\n有限的二阶矩：\\(\\int u^2 K(u) \\, du &lt; \\infty\\)\n\n实际使用中，还有一些细节需要注意。例如，部分文献或软件将 \\(\\mathbf{1}\\{|u| \\leq 1\\}\\) 写为 \\(\\mathbf{1}\\{|u| &lt; 1\\}\\)。对于连续变量，两者几乎没有区别；但若数据是离散型的（如整数型变量），则可能影响边界值是否被纳入计算。\n核密度估计的构造可以理解为：以每一个样本点为中心放置一个缩放后的核函数，然后在每一个估计位置 \\(x\\) 上，取所有样本点的核值加权平均。因此，它是一种基于样本加权“局部贡献”的整体平滑过程。\n总结而言：\n\n核函数定义了如何根据样本点与估计点之间的距离分配权重；\n带宽参数决定了每个样本点的影响范围；\n合理选择核函数和带宽参数是核密度估计中最关键的步骤；\n核密度估计为我们提供了一种平滑、灵活且无需模型假设的分布估计方法，广泛应用于经济学、金融学、机器学习等领域的探索性数据分析任务中。",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>核密度函数图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_kdensity.html#单变量核密度函数图",
    "href": "body/graph_dis_kdensity.html#单变量核密度函数图",
    "title": "27  核密度函数图",
    "section": "27.2 单变量核密度函数图",
    "text": "27.2 单变量核密度函数图\n\n\n\n\n\n\n提示词\n\n\n\n目的：生成模拟数据，绘制核密度函数图 - 语言：Python - N = 1000, x ~ N(10, 3), lnx = ln(x) - 绘制 x 和 lnx 的核密度函数图 - 布局：1 行 2 列\n\n\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 生成模拟数据\nN = 1000\nnp.random.seed(142)  # For reproducibility\nx = np.random.normal(loc=10, scale=3, size=N)\nlnx = np.log(x)\n\nplt.figure(figsize=(8, 4))\n\nplt.subplot(1, 2, 1)\nsns.kdeplot(x, label='x ~ N(10, 3)')\nplt.title('KDE of x')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nsns.kdeplot(lnx, label='ln(x)', color='orange')\nplt.title('KDE of ln(x)')\nplt.xlabel('ln(x)')\nplt.ylabel('Density')\nplt.legend()\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>核密度函数图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_kdensity.html#多变量核密度函数图",
    "href": "body/graph_dis_kdensity.html#多变量核密度函数图",
    "title": "27  核密度函数图",
    "section": "27.3 多变量核密度函数图",
    "text": "27.3 多变量核密度函数图\n\n不同时期的收入分布 - 时序\n不同种族的收入分布 - 截面\n联合分布\n\n\nimport requests\nimport pyreadstat\n\n# 设置 User-Agent 模拟浏览器访问\nurl = \"https://www.stata-press.com/data/r17/nlsw88.dta\"\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0\"\n}\n\n# 下载文件并保存到本地\nr = requests.get(url, headers=headers)\nwith open(\"data/nlsw88.dta\", \"wb\") as f:\n    f.write(r.content)\n\n# 用 pyreadstat 读取本地文件\ndf, meta = pyreadstat.read_dta(\"data/nlsw88.dta\")\n\n# 显示前几行\nprint(df.head())\n\n   idcode  age  race  married  never_married grade  collgrad  south  smsa  \\\n0       1   37     2        0              0    12         0      0     1   \n1       2   37     2        0              0    12         0      0     1   \n2       3   42     2        0              1    12         0      0     1   \n3       4   43     1        1              0    17         1      0     1   \n4       6   42     1        1              0    12         0      0     1   \n\n   c_city industry occupation union       wage hours    ttl_exp     tenure  \n0       0        5          6     1  11.739125    48  10.333334   5.333333  \n1       1        4          5     1   6.400963    40  13.621795   5.250000  \n2       1        4          3   NaN   5.016723    40  17.730770   1.250000  \n3       0       11         13     1   9.033813    42  13.211537   1.750000  \n4       0        4          6     0   8.083731    48  17.820513  17.750000  \n\n\n\n\n\n\n\n\n提示词\n\n\n\n\n绘制 White (race==1) 和 Black (race==2) 的 wage 变量的核密度函数图\n尺寸：5 x 3\n布局：1 行 1 列，将两个核密度函数图叠加\n颜色：White = blue, Black = red (lpattern: dash)\n透明度：0.8\n标题字号: 12, 图例字号: 10, 横轴和纵轴字号: 10\n\n\n\n\nplt.figure(figsize=(5, 3))\nsns.kdeplot(df.loc[df['race'] == 1, 'wage'], \n            label='White', color='blue', alpha=0.8)\nsns.kdeplot(df.loc[df['race'] == 2, 'wage'], \n            label='Black', color='red', alpha=0.8, linestyle='--')\nplt.title('KDE of Wage: White vs Black', fontsize=12)\nplt.xlabel('Wage', fontsize=10)\nplt.ylabel('Density', fontsize=10)\nplt.legend(fontsize=10)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n练习： 绘制 White 和 Black 两个种族的妇女的 ln(wage) 的核密度函数图\n\n27.3.1 多变量核密度函数图：山脊图\n\n\n\n\n\n\n提示词\n\n\n\n\n目的：绘制多只股票 xxx 年日收益率的山脊图\n数据来源：你选择合适的 package，适合中国大陆用户，自动在线下载\n股票：中国移动，贵州茅台，万科A，比亚迪, 宁德时代, 南方航空, 格力电器\n年份：2015 年 或 2024 年 或 2025 年 (可以指定一个 year 变量，我随后根据需要填写)\n\n\n\n\nimport akshare as ak\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport joypy\n\n# 设置 matplotlib 字体\nplt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\nplt.rcParams['axes.unicode_minus'] = False\nplt.rcParams['font.size'] = 12\n\n# 股票代码字典\nstock_dict = {\n    '中国移动': 'sh600941',\n    '贵州茅台': 'sh600519',\n    '万科A': 'sz000002',\n    '比亚迪': 'sz002594',\n    '宁德时代': 'sz300750',\n    '南方航空': 'sh600029',\n    '格力电器': 'sz000651'\n}\n\nyear = 2024  # 指定年份\nstart_date = f'{year}0101'\nend_date = f'{year}1231'\n\nreturns_list = []\n\nfor name, code in stock_dict.items():\n    try:\n        df = ak.stock_zh_a_daily(symbol=code, start_date=start_date, end_date=end_date)\n        if df.empty:\n            print(f\"{name}（{code}）在 {year} 年无数据，跳过。\")\n            continue\n        df = df[['date', 'close']]\n        df['date'] = pd.to_datetime(df['date'])\n        df.sort_values('date', inplace=True)\n        df['close'] = df['close'].astype(float)\n        # 计算对数收益率\n        df['log_ret'] = np.log(df['close']).diff()\n        df['stock'] = name\n        returns_list.append(df[['date', 'log_ret', 'stock']])\n    except Exception as e:\n        print(f\"下载 {name}（{code}）时出错：{e}\")\n\nif len(returns_list) &gt; 0:\n    returns_df = pd.concat(returns_list, axis=0)\n    returns_df = returns_df.dropna(subset=['log_ret'])\n    data_long = returns_df[['stock', 'log_ret']]\n    plt.figure(figsize=(8, 6))\n    joypy.joyplot(data_long, by=\"stock\", column=\"log_ret\", \n                  figsize=(12, 8), \n                  bins=50,\n                  range_style='own',\n                  legend=False,\n                  overlap=1, \n                  linewidth=1,\n                  fade=True)\n    plt.title(f\"{year} 年多只股票日收益率分布山脊图\", fontsize=18)\n    plt.xlabel(\"日对数收益率\", fontsize=14)\n    plt.ylabel(\"股票名称\", fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"未能获得任何股票数据，无法绘图。\")\n\n&lt;Figure size 800x600 with 0 Axes&gt;",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>核密度函数图</span>"
    ]
  },
  {
    "objectID": "body/graph_dis_kdensity.html#进阶用法",
    "href": "body/graph_dis_kdensity.html#进阶用法",
    "title": "27  核密度函数图",
    "section": "27.4 进阶用法",
    "text": "27.4 进阶用法\n\n27.4.1 散点图 + 核密度函数图\npenguins 数据集是一个经典的数据集，包含了三种企鹅物种（Adelie、Chinstrap 和 Gentoo）的生物测量数据。该数据集常用于统计分析和机器学习建模的教学和研究。本例中，我们抽取了三个变量：\n\nspecies：企鹅的物种（Adelie、Chinstrap 或 Gentoo）。\nflipper_length_mm：鳍的长度（单位：毫米）。\nbill_length_mm：喙的长度（单位：毫米）。\nbody_mass_g：体重（单位：克）。\n\n下图中，我们使用 seaborn 中的 jionplot 函数绘制了散点图和核密度函数图。散点图展示了每个物种的鳍长和喙长的分布情况，而核密度函数图则呈现了横轴变量 (flipper_length_mm) 和纵轴变量 (bill_length_mm) 的分布情况。\n散点图反映了企鹅的喙长 (\\(y\\)) 与鳍长 (\\(x\\)) 之间的关系。可以看出，虽然三种企鹅的 \\(y \\sim x\\) 之间都是正相关的，但 Chinstrap 类和 Gentoo 类企鹅的喙长和鳍长之间的正相关关系更强一些，而 Adelie 类企鹅的喙长和鳍长之间的正相关关系相对较弱。\n密度函数图则揭示了单变量的分布特征。可以看出，平均而言，Adelie 类企鹅的喙长和鳍长都较小，而 Gentoo 类企鹅的喙长和鳍长都较大。Chinstrap 类企鹅的喙长 (\\(y\\)) 与 Gentoo 类企鹅的长度范围差不多，但平均而言，前者的喙更长一些；有趣的是，Chinstrap 类企鹅的鳍长 (\\(x\\)) 与 Adelie 类企鹅的长度范围差不多，但平均而言，前者的鳍更长一些。\n虽然尚未看到三种企鹅的真实照片，但我们已经能够大致判断它们的体型特征了。\n\nAdelie：体型较小，喙长和鳍长都较小。\nChinstrap：体型中等，喙长与 Gentoo 差不多；而鳍长则与 Adelie 相近。\nGentoo：体型较大，喙长和鳍长都较大。\n\n简言之，Adelie 是「短嘴短翅」，Chinstrap 是「长嘴短翅」，Gentoo 是「长嘴长翅」。若进一步结合散点图来看，则可以推断出：Gentoo 类企鹅群体身材较为均匀，而 Adelie 类企鹅个体之间的身材差异较大。\n\n# Source: https://seaborn.pydata.org/tutorial/introduction.html\nimport seaborn as sns\nsns.jointplot(data=penguins, \n              x=\"flipper_length_mm\", \n              y=\"bill_length_mm\", \n              hue=\"species\", \n              height=6)\n\n\n\n\n\n\n\n\n\n它们到底长啥样？\n\n你可以在 这里 找到它们的详细介绍。有位热心的网友特意绘制了它们的合影 (从左到右依次为 Adelie、Chinstrap 和 Gentoo)，如下图所示：\n\n\n\n27.4.2 多个变量的情形：pairplot\n在上面的例子中，我们只考虑了两个变量之间的关系。实际上，数据集中可能有多个变量，此时可以使用 seaborn 中的 pairplot 函数来绘制多个变量之间的关系图。\n下面的例子中，我们同时呈现了三个变量 (flipper_length_mm、bill_length_mm 和 body_mass_g) 之间的两两配对散点图，以及单个变量的核密度函数图。与此同时，我们还使用了不同的颜色来区分不同的物种。\n\n# Source：https://seaborn.pydata.org/tutorial/introduction.html\nvlist = [\"flipper_length_mm\", \"bill_length_mm\", \"body_mass_g\"]\nsns.pairplot(data=penguins, vars=vlist, \n             hue=\"species\", \n             corner=True)\n\n\n\n\n\n\n\n\n\n\n27.4.3 联合分布图\nhttps://seaborn.pydata.org/generated/seaborn.kdeplot.html\n\n\n27.4.4 3D 核密度函数图\n\n\nSource: matplotlib - Fill under 3D line graphs\n\n\n\n27.4.5 密度函数图+条形码\nseaborn.rugplot\n\nimport seaborn as sns; sns.set_theme()\ntips = sns.load_dataset(\"tips\")\nsns.kdeplot(data=tips, x=\"total_bill\")\nsns.rugplot(data=tips, x=\"total_bill\")",
    "crumbs": [
      "**可视化**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>核密度函数图</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html",
    "href": "body/TS_FRED_US_unemploy_rate.html",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "",
    "text": "28.1 下载美国失业率数据\n本讲以 pandas_datareader 为例，介绍如何获取宏观数据，以及时间序列的基本特征和分析流程。\nFRED 是美国联邦储备银行提供的宏观经济数据，包含了大量的经济指标。 FRED 提供了一个 API 接口，可以通过 pandas_datareader 来获取数据。\n本文写作过程中借助了 AI，包括 ChatGPT (提示词) 和 Github Coplilot。\nimport os\nos.chdir(r\"D:\\github\\dslian\\body\")\n# 基本设定\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas_datareader.data import DataReader\nimport datetime\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")  # 屏蔽警告信息\n\n# 设置起止日期 (后续其他宏观变量也采用这个设置)\nstart_date = datetime.datetime(1960, 1, 1)\nend_date = datetime.datetime.today()\nstart_year = start_date.year\n# 失业率\n\n# 从 FRED 获取“Unemployment Rate”数据（代码为 UNRATE）\ndf_unemp = DataReader(\"UNRATE\", \"fred\", start_date, end_date)\n\n# 绘图\nplt.figure(figsize=(8, 4))\nplt.plot(df_unemp.index, df_unemp[\"UNRATE\"], \n         color='blue', linewidth=2, label='Unemployment Rate')\n\n# 图形美化\nplt.title(f\"Unemployment Rate in the U.S. ({start_year} - Present)\", fontsize=12)\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Percent\", fontsize=12)\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.legend()\nplt.tight_layout()\n\n# 显示图形\nplt.show()",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#下载美国失业率数据",
    "href": "body/TS_FRED_US_unemploy_rate.html#下载美国失业率数据",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "",
    "text": "Source: U.S. Bureau of Labor Statistics, Unemployment Rate [UNRATE], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UNRATE, May 5, 2025.",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#美国失业率的时序特征",
    "href": "body/TS_FRED_US_unemploy_rate.html#美国失业率的时序特征",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.2 美国失业率的时序特征",
    "text": "28.2 美国失业率的时序特征\n上图展示了自 1960 年以来美国的月度失业率变化趋势。总体来看，美国失业率呈现出显著的周期性波动，其高峰通常与经济衰退期相吻合，低谷则出现在经济扩张阶段。\n\n周期波动明显：失业率大致每 8-10 年出现一次较大波动，与美国历次经济衰退（如 1974、1982、1991、2008 和 2020 年）高度对应。\n历史极值：2020 年新冠疫情爆发初期，失业率迅速飙升至超过 14%，为图中最高点，反映出突发公共卫生事件对劳动市场的巨大冲击。\n长期下行趋势：尽管存在周期性波动，但在部分阶段（如 1982-2000 年间、2010-2019 年间）可观察到失业率逐步下降的趋势，显示出结构性改善可能性。\n\n\n28.2.1 问题：如何分析失业率的时序特征？\n从图中失业率的走势出发，我们可以从以下几个角度提出计量建模中需要关注的核心问题：\n\n平稳性与周期性： 失业率呈现一定的均值回复特征 (在上图中，均值约为 6Z%)，但是否真正平稳？如何通过单位根检验（如 ADF 检验）判断？如果该序列非平稳，我们是否应进行差分处理以便后续建模？\n结构性突变： 例如 2020 年的断崖式上升显然并非常态波动，这提示我们应考虑模型中可能存在的结构突变（structural break）。在传统 ARIMA 模型之外，我们可能需要引入 regime-switching 或 dummy 变量来捕捉这类异质性。\n滞后依赖结构： 当前失业率是否受到过去若干期值的影响？其滞后项在建模中如何体现？这正是 AR(p) 或 ARMA(p, q) 模型关注的核心。\n长期关系与协整： 若将失业率与其他宏观变量（如通货膨胀率、GDP 增长率）联合考虑，它们之间是否存在协整关系？若存在，应如何建立误差修正模型（ECM）？\n波动性建模： 某些阶段的波动显著大于其他时期，例如 1970s 或 2008 危机期间。如何刻画这种条件异方差特征？这将引出 ARCH/GARCH 及其扩展模型的讨论。\n\n\n# 失业率的基本统计特征\numemp = df_unemp[\"UNRATE\"]\nprint(\"失业率的基本统计特征：\")\nprint(umemp.describe().round(2))\n\n失业率的基本统计特征：\ncount    784.00\nmean       5.88\nstd        1.70\nmin        3.40\n25%        4.60\n50%        5.60\n75%        7.00\nmax       14.80\nName: UNRATE, dtype: float64\n\n\n\n# 分时段统计 (表格版)\nperiods = {\n    \"1960-1980年\": (\"1960-01-01\", \"1980-12-31\"),\n    \"1980-2000年\": (\"1980-01-01\", \"2000-12-31\"),\n    \"2000-2010年\": (\"2000-01-01\", \"2010-12-31\"),\n    \"2010-2020年\": (\"2010-01-01\", \"2020-12-31\"),\n    \"2020-2025年\": (\"2020-01-01\", \"2025-12-31\"),\n}\n\n# 创建一个列表来存储结果\nstats_list = []\n\nfor period, (start, end) in periods.items():\n    stats = umemp[start:end].agg(['mean', 'std', 'min', 'max']).round(2)\n    stats_list.append({\n        \"Period\": period,\n        \"Mean\": stats[\"mean\"],\n         \"Std\": stats[\"std\"],\n         \"Min\": stats[\"min\"],\n         \"Max\": stats[\"max\"]\n    })\n\n# 将结果转换为 DataFrame\nstats_table = pd.DataFrame(stats_list)\n\n# 显示结果表格\nprint(stats_table)\n\n       Period  Mean   Std  Min   Max\n0  1960-1980年  5.58  1.35  3.4   9.0\n1  1980-2000年  6.40  1.55  3.8  10.8\n2  2000-2010年  5.91  1.81  3.8  10.0\n3  2010-2020年  6.39  2.29  3.5  14.8\n4  2020-2025年  4.90  2.28  3.4  14.8\n\n\n\n\n28.2.2 10 年移动平均\n我们可以使用 rolling 函数来计算 10 年移动平均，以便从更长时间尺度上观察失业率的变化趋势。\n\n# 10 年和 5 年滚动平均\nrolling_mean_umemp_10yr = umemp.rolling(window=120).mean()  # 120 个月 = 10 年\n\n# 绘图\nplt.figure(figsize=(8, 4))\nplt.plot(df_unemp.index, umemp, \n         color='blue', linewidth=2, label='Unemployment Rate')\nplt.plot(df_unemp.index, rolling_mean_umemp_10yr, \n         color='red', linewidth=4, label='10-Year Rolling Mean')\nplt.legend() # 添加图例\nplt.grid(True, linestyle='--', linewidth=0.5) # 添加网格线",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#消费者物价指数cpi",
    "href": "body/TS_FRED_US_unemploy_rate.html#消费者物价指数cpi",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.3 消费者物价指数（CPI）",
    "text": "28.3 消费者物价指数（CPI）\n\nSource: U.S. Bureau of Labor Statistics, Consumer Price Index for All Urban Consumers: All Items in U.S. City Average, Not Seasonally Adjusted [CPIAUCNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CPIAUCNS, May 5, 2025.\n\n\n# CPI（消费者物价指数）\n\n# 从 FRED 获取 CPI 数据（代码为 CPIAUCNS）\ndf_CPI = DataReader(\"CPIAUCNS\", \"fred\", start_date, end_date)\n\n# 绘图\nplt.figure(figsize=(8, 4))\nplt.plot(df_CPI.index, df_CPI[\"CPIAUCNS\"], \n         color='darkred', linewidth=2, label='CPI: All Urban Consumers')\n\n# 图形美化\nplt.title(f\"Consumer Price Index (CPI-U): All Items in U.S. City Average ({start_year} - Present)\", fontsize=12)\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Index (1982-1984 = 100)\", fontsize=12)\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.legend()\nplt.tight_layout()\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n\n28.3.1 美国消费者物价指数（CPI）趋势图解读\n上图展示了自 1960 年以来美国城市居民的消费者物价指数（CPI-U）的长期变化趋势，数据来自 FRED 数据库，基期设为 1982-1984 年的平均水平（指数 = 100）。\n从图中可以观察到以下几个重要特征：\n\n总体呈上升趋势：说明过去几十年美国总体价格水平持续上升，具有显著的通货膨胀特征。\n1970s 的急剧上升：受石油危机影响，1970 年代出现了显著的高通胀，CPI 增速明显加快。\n1980s 以后趋于稳定增长：随着货币政策收紧（如沃尔克加息），通胀得到控制，CPI 增长变得更加平缓。\n2020 年以后的陡峭上升：反映出疫情后期以及地缘政治冲击下，美国面临新一轮较高通胀压力，物价上涨速度明显加快。\n\n接下来，我们可以看看最近 10-20 年的 CPI 变化趋势。\n\n# 2005 以来的 CPI 变化\nstart_year = 2005\nend_year = 2025\n\ndf_CPI_period = df_CPI[\"CPIAUCNS\"][f\"{start_year}-01-01\":f\"{end_year}-12-31\"]\n\n# 绘图\nplt.figure(figsize=(8, 4))\nplt.plot(df_CPI_period.index, df_CPI_period, \n         color='darkred', linewidth=2, label=f'CPI: {start_year}-{end_year}')\n\n# 图形美化\nplt.title(f\"CPI Changes ({start_year}-{end_year})\", fontsize=12)\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Index (1982-1984 = 100)\", fontsize=12)\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.legend()\nplt.tight_layout()\n\n# 显示图形\nplt.show()\n\n\n\n\n\n\n\n\n\n# 基于 CPI 计算通货膨胀率\n\n# 计算通货膨胀率（基于 CPI 的同比变化率）\ndf_CPI['Inflation Rate'] = df_CPI['CPIAUCNS'].pct_change(periods=12) * 100\n\n# 绘图\nplt.figure(figsize=(8, 4))\nplt.plot(df_CPI.index, df_CPI['Inflation Rate'], \n         color='green', linewidth=2, label='Inflation Rate')\n\n# 图形美化\nplt.title(f\"Inflation Rate in the U.S. ({start_year} - Present)\", fontsize=12)\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Inflation Rate (%)\", fontsize=12)\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.legend()\nplt.tight_layout()\n\n# 显示图形\nplt.show()",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#失业率和通货膨胀率的关系",
    "href": "body/TS_FRED_US_unemploy_rate.html#失业率和通货膨胀率的关系",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.4 失业率和通货膨胀率的关系",
    "text": "28.4 失业率和通货膨胀率的关系\n接下来，我们将失业率和通货膨胀率结合起来，分析它们之间的关系。我们可以使用 pandas 和 matplotlib 来绘制散点图和线性回归线，以便更好地理解它们之间的关系。\n\n# 绘图：失业率 + 通货膨胀率\nplt.figure(figsize=(8, 4))\n\n# 绘制失业率\nplt.plot(df_unemp.index, df_unemp[\"UNRATE\"], \n         color='blue', linewidth=2, label='Unemployment Rate')\n\n# 绘制通货膨胀率\nplt.plot(df_CPI.index, df_CPI['Inflation Rate'], \n         color='green', linewidth=2, label='Inflation Rate')\n\n# 添加图例\nplt.legend(loc='upper left')\n\n# 添加数据来源说明\nplt.figtext(0.5, -0.05, \"Source: U.S. Bureau of Labor Statistics, FRED (https://fred.stlouisfed.org/)\", \n            wrap=True, horizontalalignment='center', fontsize=10)\n\nText(0.5, -0.05, 'Source: U.S. Bureau of Labor Statistics, FRED (https://fred.stlouisfed.org/)')\n\n\n\n\n\n\n\n\n\n这幅图展示了 1960 年至今美国 失业率（Unemployment Rate） 与 通胀率（Inflation Rate） 的时间序列走势。可以从以下几个方面进行解读：\n\n趋势与波动性差异：\n\n失业率（蓝线）表现出相对平稳的周期性波动，具有一定的周期长度；\n通胀率（绿线）波动幅度更大，尤其在 1970s 至 1980s 初期，有显著的尖峰。\n\n结构性事件的影响：\n\n1970s：石油危机期间，通胀迅速上升至 13% 以上（即“滞涨”现象），而失业率也居高不下；\n2008 金融危机：失业率大幅上升，而通胀保持较低水平；\n2020 疫情冲击：失业率暴涨，通胀短暂回落，随后于 2021-2022 再次激增。\n\n负相关性阶段：\n\n在部分阶段（例如 1980s 中后期、1990s、2010s），通胀与失业呈现出某种程度的负相关，符合传统的菲利普斯曲线（Phillips Curve）设定。\n\n\n\n28.4.1 建模思路\n如果我们想建立一个模型来刻画失业率与通胀率之间的关系，有哪些可行的建模思路呢？\n\n线性回归\nARMA 模型\nVAR 模型\nVECM 模型",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#线性回归模型",
    "href": "body/TS_FRED_US_unemploy_rate.html#线性回归模型",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.5 线性回归模型",
    "text": "28.5 线性回归模型\n\n# UNRATE 和 Inflation Rate 的关系\n\n## 相关系数\ncorrelation = df_unemp[\"UNRATE\"].corr(df_CPI['Inflation Rate'])\nprint(f\"Correlation between Unemployment Rate and Inflation Rate: {correlation:.2f}\")\n\n## OLS 回归分析\nimport statsmodels.api as sm\n# Align the indices of X and Y\nX = df_CPI['Inflation Rate'].dropna()   # 自变量\nY = df_unemp[\"UNRATE\"]                  # 因变量\nX, Y = X.align(Y, join='inner')         # Align indices\nX = sm.add_constant(X)                  # 添加常数项\nmodel = sm.OLS(Y, X).fit()              # OLS 回归\nmodel_summary = model.summary()       # 回归结果\nprint(model_summary)\n\nCorrelation between Unemployment Rate and Inflation Rate: 0.06\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 UNRATE   R-squared:                       0.004\nModel:                            OLS   Adj. R-squared:                  0.003\nMethod:                 Least Squares   F-statistic:                     3.016\nDate:                Mon, 12 May 2025   Prob (F-statistic):             0.0829\nTime:                        15:47:57   Log-Likelihood:                -1505.1\nNo. Observations:                 771   AIC:                             3014.\nDf Residuals:                     769   BIC:                             3024.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==================================================================================\n                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nconst              5.7423      0.103     55.657      0.000       5.540       5.945\nInflation Rate     0.0380      0.022      1.737      0.083      -0.005       0.081\n==============================================================================\nOmnibus:                      104.203   Durbin-Watson:                   0.065\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              155.789\nSkew:                           0.926   Prob(JB):                     1.48e-34\nKurtosis:                       4.190   Cond. No.                         8.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#单变量分析",
    "href": "body/TS_FRED_US_unemploy_rate.html#单变量分析",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.6 单变量分析",
    "text": "28.6 单变量分析\n我们先采用 ARMA 模型来分析失业率和通货膨胀率的单变量特征。进而使用单位根检验（如 ADF 检验）来判断序列的平稳性。 在下一小节中，将采用 VAR 模型来分析失业率和通货膨胀率的关系。\n\n28.6.1 ARMA(1,1) 模型\n\\[y_t = \\alpha + \\beta y_{t-1} + \\epsilon_t + \\theta \\epsilon_{t-1}\\]\n其中，\\(\\epsilon_t \\sim N(0, \\sigma^2)\\)。\n我们可以使用 statsmodels 库，分别针对失业率序列和通货膨胀序列来拟合 ARMA 模型。\n\n'''ARMA(1,1) 模型：失业率'''\n\nfrom statsmodels.tsa.arima.model import ARIMA\n\n# 确保索引有频率信息\nif not isinstance(df_unemp.index, pd.PeriodIndex):\n    df_unemp.index = df_unemp.index.to_period('M')  # 将索引设置为月度频率\n\n# 然后重新运行 ARIMA 模型\nmodel_unemp = ARIMA(df_unemp['UNRATE'], order=(1, 0, 1))\nmodel_unemp_fit = model_unemp.fit()\nprint(model_unemp_fit.summary())\n\n                               SARIMAX Results                                \n==============================================================================\nDep. Variable:                 UNRATE   No. Observations:                  784\nModel:                 ARIMA(1, 0, 1)   Log Likelihood                -446.406\nDate:                Mon, 12 May 2025   AIC                            900.812\nTime:                        15:49:15   BIC                            919.469\nSample:                    01-31-1960   HQIC                           907.986\n                         - 04-30-2025                                         \nCovariance Type:                  opg                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          5.8040      1.075      5.397      0.000       3.696       7.912\nar.L1          0.9640      0.012     82.124      0.000       0.941       0.987\nma.L1          0.0508      0.012      4.417      0.000       0.028       0.073\nsigma2         0.1822      0.002     94.889      0.000       0.178       0.186\n===================================================================================\nLjung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):           6130464.69\nProb(Q):                              0.96   Prob(JB):                         0.00\nHeteroskedasticity (H):              11.77   Skew:                            17.73\nProb(H) (two-sided):                  0.00   Kurtosis:                       434.75\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\n\n\n'''ARMA(1,1) 模型：通胀率'''\n\nmodel = ARIMA(df_CPI['Inflation Rate'].dropna(), order=(1, 0, 1))\nmodel_fit = model.fit()     # Fit the ARIMA model\nprint(model_fit.summary())  # Print the model summary\n\n                               SARIMAX Results                                \n==============================================================================\nDep. Variable:         Inflation Rate   No. Observations:                  771\nModel:                 ARIMA(1, 0, 1)   Log Likelihood                -327.515\nDate:                Mon, 12 May 2025   AIC                            663.030\nTime:                        15:54:35   BIC                            681.621\nSample:                    01-31-1961   HQIC                           670.185\n                         - 03-31-2025                                         \nCovariance Type:                  opg                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.5391      1.139      3.108      0.002       1.307       5.771\nar.L1          0.9847      0.005    197.487      0.000       0.975       0.995\nma.L1          0.2964      0.026     11.248      0.000       0.245       0.348\nsigma2         0.1362      0.004     31.231      0.000       0.128       0.145\n===================================================================================\nLjung-Box (L1) (Q):                   2.49   Jarque-Bera (JB):               406.03\nProb(Q):                              0.11   Prob(JB):                         0.00\nHeteroskedasticity (H):               1.14   Skew:                            -0.16\nProb(H) (two-sided):                  0.28   Kurtosis:                         6.54\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n\n\n\n\n28.6.2 单位根检验\n从上面的 \\(ARMA(1,1)\\) 模型的结果来看，\\(AR(1)\\) 系数的估计值为 \\(0.9847\\)，接近于 \\(1\\)，这表明该序列可能是一个单位根序列。\n我们可以使用 statsmodels 库中的 adfuller 函数来进行单位根检验。\n\n28.6.2.1 ADF 检验\n给定一个时间序列 \\(X_t\\)，我们可以使用以下的 ADF 检验来检验 \\(X_t\\) 是否是平稳的：\n\\[\nX_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + ... + \\phi_p X_{t-p} + \\epsilon_t\\]\n其中，\\(\\epsilon_t\\) 是一个白噪声序列。\nADF 检验的原假设是：\\(X_t\\) 是一个单位根序列，即 \\(H_0: \\phi_1 = 1\\)。 如果 \\(H_0\\) 被拒绝，则说明 \\(X_t\\) 是平稳的。\nADF 检验包含几种典型的数据生成机制：\n\n纯随机游走：\\(X_t = X_{t-1} + \\epsilon_t\\)，其中 \\(\\epsilon_t\\) 是一个白噪声序列。\n随机游走加趋势：\\(X_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 t + \\epsilon_t\\)，其中 \\(\\epsilon_t\\) 是一个白噪声序列，\\(t\\) 是时间趋势项。\n随机游走加季节性：\\(X_t = \\phi_0 + \\phi_1 X_{t-1} + S_t + \\epsilon_t\\)，其中 \\(\\epsilon_t\\) 是一个白噪声序列，\\(S_t\\) 是季节性项。\n随机游走加趋势和季节性：\\(X_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 t + S_t + \\epsilon_t\\)，其中 \\(\\epsilon_t\\) 是一个白噪声序列，\\(t\\) 是时间趋势项，\\(S_t\\) 是季节性项。\n\n\n\n28.6.2.2 KPSS 检验\nKPSS 检验的原假设是：\\(X_t\\) 是平稳的，即 \\(H_0: \\phi_1 &lt; 1\\)。 如果 \\(H_0\\) 被拒绝，则说明 \\(X_t\\) 是一个单位根序列。\n\n\n28.6.2.3 PP 检验\nPP 检验的原假设是：\\(X_t\\) 是一个单位根序列，即 \\(H_0: \\phi_1 = 1\\)。 如果 \\(H_0\\) 被拒绝，则说明 \\(X_t\\) 是平稳的。\n\nfrom statsmodels.tsa.stattools import adfuller, kpss\nimport warnings\n\n# 忽略特定警告（如 InterpolationWarning）\nwarnings.filterwarnings(\"always\", category=UserWarning)\n\ndef unit_root_tests(series, series_name, regression_type='c'):\n    \"\"\"\n    对单个序列执行 ADF 和 KPSS 单位根检验，支持多种趋势设定。\n    \"\"\"\n    print(f\"单位根检验结果 ({regression_type}): {series_name}\")\n    print(\"-\" * 50)\n\n    # ===== ADF 检验 =====\n    try:\n        adf_result = adfuller(series.dropna(), regression=regression_type, autolag='AIC')\n        print(\"ADF 检验:\")\n        print(f\"ADF Statistic: {adf_result[0]:.4f}\")\n        print(f\"p-value: {adf_result[1]:.4f}\")\n        print(f\"Critical Values: {adf_result[4]}\")\n        print(f\"Conclusion: {'Reject H0 (Stationary)' if adf_result[1] &lt; 0.05 else 'Fail to Reject H0 (Non-Stationary)'}\")\n    except Exception as e:\n        print(\"ADF 检验无法执行:\", e)\n\n    print(\"-\" * 50)\n\n    # ===== KPSS 检验 =====\n    # KPSS 仅接受 'c' 或 'ct'\n    if regression_type not in ['c', 'ct']:\n        print(\"KPSS 检验跳过（只支持 regression='c' 或 'ct'）\")\n    else:\n        try:\n            with warnings.catch_warnings(record=True) as w:\n                warnings.simplefilter(\"always\")\n                kpss_result = kpss(series.dropna(), regression=regression_type, nlags=\"auto\")\n\n                print(\"KPSS 检验:\")\n                print(f\"KPSS Statistic: {kpss_result[0]:.4f}\")\n                print(f\"p-value: {kpss_result[1]:.4f}\")\n                print(f\"Critical Values: {kpss_result[3]}\")\n                print(f\"Conclusion: {'Reject H0 (Non-Stationary)' if kpss_result[1] &lt; 0.05 else 'Fail to Reject H0 (Stationary)'}\")\n\n                if w:\n                    print(\"⚠️ 警告：KPSS 统计量超出临界值范围，p-value 可能不准确。\")\n        except Exception as e:\n            print(\"KPSS 检验无法执行:\", e)\n\n    print(\"=\" * 50)\n\n# 示例调用\nunit_root_tests(df_unemp['UNRATE'], \"Unemployment Rate\", regression_type='c')\nunit_root_tests(df_unemp['UNRATE'], \"Unemployment Rate\", regression_type='ct')\n\nunit_root_tests(df_CPI['Inflation Rate'], \"Inflation Rate\", regression_type='c')\nunit_root_tests(df_CPI['Inflation Rate'], \"Inflation Rate\", regression_type='ct')\n\n单位根检验结果 (c): Unemployment Rate\n--------------------------------------------------\nADF 检验:\nADF Statistic: -3.3770\np-value: 0.0118\nCritical Values: {'1%': -3.438750669890019, '5%': -2.8652477937238703, '10%': -2.56874438754281}\nConclusion: Reject H0 (Stationary)\n--------------------------------------------------\nKPSS 检验:\nKPSS Statistic: 0.2311\np-value: 0.1000\nCritical Values: {'10%': 0.347, '5%': 0.463, '2.5%': 0.574, '1%': 0.739}\nConclusion: Fail to Reject H0 (Stationary)\n⚠️ 警告：KPSS 统计量超出临界值范围，p-value 可能不准确。\n==================================================\n单位根检验结果 (ct): Unemployment Rate\n--------------------------------------------------\nADF 检验:\nADF Statistic: -3.3937\np-value: 0.0522\nCritical Values: {'1%': -3.97040856520887, '5%': -3.416126420192948, '10%': -3.130367109217753}\nConclusion: Fail to Reject H0 (Non-Stationary)\n--------------------------------------------------\nKPSS 检验:\nKPSS Statistic: 0.2188\np-value: 0.0100\nCritical Values: {'10%': 0.119, '5%': 0.146, '2.5%': 0.176, '1%': 0.216}\nConclusion: Reject H0 (Non-Stationary)\n⚠️ 警告：KPSS 统计量超出临界值范围，p-value 可能不准确。\n==================================================\n单位根检验结果 (c): Inflation Rate\n--------------------------------------------------\nADF 检验:\nADF Statistic: -3.2255\np-value: 0.0186\nCritical Values: {'1%': -3.4390409569041207, '5%': -2.865375732701395, '10%': -2.568812543748081}\nConclusion: Reject H0 (Stationary)\n--------------------------------------------------\nKPSS 检验:\nKPSS Statistic: 0.8623\np-value: 0.0100\nCritical Values: {'10%': 0.347, '5%': 0.463, '2.5%': 0.574, '1%': 0.739}\nConclusion: Reject H0 (Non-Stationary)\n⚠️ 警告：KPSS 统计量超出临界值范围，p-value 可能不准确。\n==================================================\n单位根检验结果 (ct): Inflation Rate\n--------------------------------------------------\nADF 检验:\nADF Statistic: -3.6011\np-value: 0.0298\nCritical Values: {'1%': -3.970811044144979, '5%': -3.4163210567045534, '10%': -3.130481573426401}\nConclusion: Reject H0 (Stationary)\n--------------------------------------------------\nKPSS 检验:\nKPSS Statistic: 0.2876\np-value: 0.0100\nCritical Values: {'10%': 0.119, '5%': 0.146, '2.5%': 0.176, '1%': 0.216}\nConclusion: Reject H0 (Non-Stationary)\n⚠️ 警告：KPSS 统计量超出临界值范围，p-value 可能不准确。\n==================================================\n\n\n\n# 绘制 ACF 和 PACF 图\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nplt.figure(figsize=(6, 6))\n\n# 通胀率的 ACF 和 PACF\nplt.subplot(4, 1, 1)\nplot_acf(df_CPI['Inflation Rate'].dropna(), lags=40, ax=plt.gca())\nplt.title('ACF of Inflation Rate', fontsize=12)\n\nplt.subplot(4, 1, 2)\nplot_pacf(df_CPI['Inflation Rate'].dropna(), lags=40, ax=plt.gca())\nplt.title('PACF of Inflation Rate', fontsize=12)\n\n# 失业率的 ACF 和 PACF\nplt.subplot(4, 1, 3)\nplot_acf(df_unemp['UNRATE'].dropna(), lags=40, ax=plt.gca())\nplt.title('ACF of Unemployment Rate', fontsize=12)\n\nplt.subplot(4, 1, 4)\nplot_pacf(df_unemp['UNRATE'].dropna(), lags=40, ax=plt.gca())\nplt.title('PACF of Unemployment Rate', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n解读： 上面的图形展示了美国失业率和通货膨胀率的时间序列变化趋势。可以观察到，失业率和通货膨胀率在不同时间段内呈现出一定的波动性。失业率在经济衰退期间通常会显著上升，而通货膨胀率则可能受到多种因素的影响，包括货币政策、供需变化等。通过对比两条曲线，可以进一步分析它们之间的关系，例如是否存在菲利普斯曲线的特征。此外，结合回归分析和相关系数的计算结果，可以定量评估失业率与通货膨胀率之间的相关性。",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#var-模型",
    "href": "body/TS_FRED_US_unemploy_rate.html#var-模型",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.7 VAR 模型",
    "text": "28.7 VAR 模型\n向量自回归模型（Vector Autoregression, VAR）是一种多元时间序列模型，用于捕捉多个变量之间的动态关系。它假设每个变量不仅受自身滞后值的影响，还受到其他变量滞后值的影响。\n\n28.7.1 VAR(2) 模型的形式\n以两个变量 \\(y_t\\) 和 \\(x_t\\) 为例，VAR(2) 模型的形式如下：\n\\[\n\\begin{aligned}\ny_t &= a_{10} + a_{11} y_{t-1} + a_{12} x_{t-1} + a_{13} y_{t-2} + a_{14} x_{t-2} + \\epsilon_{y,t}, \\\\\nx_t &= a_{20} + a_{21} y_{t-1} + a_{22} x_{t-1} + a_{23} y_{t-2} + a_{24} x_{t-2} + \\epsilon_{x,t},\n\\end{aligned}\n\\]\n其中：\n\n\\(y_t\\) 和 \\(x_t\\) 是两个时间序列变量；\n\\(a_{ij}\\) 是模型系数；\n\\(\\epsilon_{y,t}\\) 和 \\(\\epsilon_{x,t}\\) 是误差项，通常假设为白噪声。\n\n\n\n28.7.2 VAR(P) 模型的扩展\nVAR(P) 模型是 VAR(2) 模型的推广形式，表示包含 \\(P\\) 阶滞后项的向量自回归模型。其一般形式为：\n\\[\nY_t = A_1 Y_{t-1} + A_2 Y_{t-2} + \\dots + A_P Y_{t-P} + \\epsilon_t,\n\\]\n其中：\n\n\\(Y_t\\) 是包含多个变量的向量（如 \\([y_t, x_t]^\\top\\)）；\n\\(A_1, A_2, \\dots, A_P\\) 是系数矩阵；\n\\(\\epsilon_t\\) 是误差项。\n\n通过增加滞后阶数 \\(P\\)，VAR 模型可以捕捉更复杂的动态关系，但也可能导致参数过多的问题。因此，选择合适的滞后阶数是建模中的关键步骤。\n\n\n28.7.3 VAR 模型的估计\n在 VAR 模型中，估计的核心任务是确定模型的滞后阶数，并对模型参数进行估计。以下是 VAR 模型估计的主要步骤：\n\n数据准备：确保时间序列数据是平稳的。如果数据非平稳，可以通过差分或其他变换使其平稳。\n滞后阶数选择：通过信息准则（如 AIC、BIC、HQIC）选择合适的滞后阶数，避免过拟合。\n模型估计：使用最小二乘法（OLS）对 VAR 模型的参数进行估计，逐个方程独立估计。\n模型诊断：检查残差是否存在自相关、异方差等问题，必要时调整模型或采用其他方法改进。\n\n接下来，我们用 statsmodels 库来估计 VAR 模型，分析失业率和通货膨胀率之间的动态关系。\n首先，需要进行模型，最核心的问题是确定滞后阶数。\n\nfrom statsmodels.tsa.api import VAR\n\n# 准备数据：将失业率和通胀率合并为一个 DataFrame\ndata = pd.concat([df_unemp['UNRATE'], df_CPI['Inflation Rate']], axis=1).dropna()\ndata.columns = ['Unemployment Rate', 'Inflation Rate']\n\n# 创建 VAR 模型\nmodel = VAR(data)\n\n# 选择滞后阶数（使用 AIC 或 BIC）\nlag_order = model.select_order(maxlags=15)\nprint(\"Lag Order Selection:\")\nprint(lag_order.summary())\n\n# 根据选择的滞后阶数拟合 VAR 模型\noptimal_lag = lag_order.aic  # 使用 AIC 选择的滞后阶数\n\nLag Order Selection:\n VAR Order Selection (* highlights the minimums)  \n==================================================\n       AIC         BIC         FPE         HQIC   \n--------------------------------------------------\n0        3.154       3.167       23.44       3.159\n1       -3.583      -3.546     0.02779      -3.569\n2       -3.721     -3.659*     0.02422      -3.697\n3       -3.718      -3.632     0.02429      -3.685\n4       -3.710      -3.600     0.02448      -3.667\n5       -3.711      -3.577     0.02444      -3.659\n6       -3.703      -3.543     0.02466      -3.641\n7       -3.698      -3.514     0.02478      -3.627\n8       -3.703      -3.495     0.02465      -3.623\n9       -3.693      -3.461     0.02489      -3.604\n10      -3.700      -3.443     0.02473      -3.601\n11      -3.693      -3.411     0.02490      -3.585\n12      -3.685      -3.379     0.02510      -3.567\n13      -3.916      -3.585     0.01992      -3.789\n14     -3.934*      -3.579    0.01957*     -3.797*\n15      -3.928      -3.548     0.01968      -3.782\n--------------------------------------------------\n\n\n由此可以看出，我们设定一个 VAR(2) 模型即可。\n\n# 拟合 VAR(2) 模型\nvar_model_2 = model.fit(2)\n\n# 输出模型结果\nprint(var_model_2.summary())\n\n  Summary of Regression Results   \n==================================\nModel:                         VAR\nMethod:                        OLS\nDate:           Wed, 07, May, 2025\nTime:                     18:30:39\n--------------------------------------------------------------------\nNo. of Equations:         2.00000    BIC:                   -3.66800\nNobs:                     769.000    HQIC:                  -3.70515\nLog likelihood:          -738.758    FPE:                  0.0240313\nAIC:                     -3.72840    Det(Omega_mle):       0.0237218\n--------------------------------------------------------------------\nResults for equation Unemployment Rate\n=======================================================================================\n                          coefficient       std. error           t-stat            prob\n---------------------------------------------------------------------------------------\nconst                        0.164239         0.058576            2.804           0.005\nL1.Unemployment Rate         0.988192         0.036480           27.089           0.000\nL1.Inflation Rate           -0.103951         0.040127           -2.591           0.010\nL2.Unemployment Rate        -0.025692         0.036293           -0.708           0.479\nL2.Inflation Rate            0.117987         0.040215            2.934           0.003\n=======================================================================================\n\nResults for equation Inflation Rate\n=======================================================================================\n                          coefficient       std. error           t-stat            prob\n---------------------------------------------------------------------------------------\nconst                        0.094596         0.050132            1.887           0.059\nL1.Unemployment Rate        -0.022818         0.031221           -0.731           0.465\nL1.Inflation Rate            1.342114         0.034342           39.080           0.000\nL2.Unemployment Rate         0.015220         0.031061            0.490           0.624\nL2.Inflation Rate           -0.355045         0.034418          -10.316           0.000\n=======================================================================================\n\nCorrelation matrix of residuals\n                     Unemployment Rate  Inflation Rate\nUnemployment Rate             1.000000       -0.142756\nInflation Rate               -0.142756        1.000000\n\n\n\n\n\n根据 VAR（向量自回归）模型的估计结果，可以对失业率与通货膨胀率之间的动态相关关系进行如下简要解释：\n\n模型设定与解释：本模型包含两个内生变量：Unemployment Rate（失业率） 与 Inflation Rate（通货膨胀率），并引入了两个滞后期，用以捕捉二者的动态交互关系。\n失业率方程\n\nL1.Inflation Rate 的系数为 -0.104，且在 1% 显著水平下显著（p = 0.010），表明通货膨胀率上期上升，会导致当期失业率下降，呈现出负相关关系。这种现象与传统的菲利普斯曲线一致，即短期内存在“以通胀换就业”的机制。\nL2.Inflation Rate 的系数为 +0.118，同样显著（p = 0.003），意味着这种负向冲击在第二期发生一定反转，提示通胀与失业的关系可能并非单调，而具有一定的动态调整路径。\n失业率自身具有较强的惯性（L1 系数为 0.988，p &lt; 0.001），说明其变化趋于缓慢，当前水平很大程度由前一期决定。\n\n通货膨胀率方程\n\nInflation Rate 的自回归项 L1 系数高达 1.342，显著性极强（p &lt; 0.001），说明通胀率具有高度的自我延续性，是一个强持久性的变量。\nUnemployment Rate 的滞后项（L1 与 L2）在该方程中均不显著（p 值远大于 0.1），表明失业率对通胀率的短期预测贡献较小。\n\n残差相关矩阵：两个方程残差间的相关系数为 -0.143，为中等程度的负相关，意味着在控制了自身滞后影响后，通胀与失业之间仍存在一定的即时负相关关系。\n\n综上，通胀率的变化对失业率存在短期的显著负向影响，但 失业率对通胀率的影响不明显，两者关系具有方向性和滞后性，表现出一定的不对称特征。这一结果对政策制定者具有重要意义：在制定货币或财政政策以影响就业时，应特别关注通胀路径对失业的动态传导。\n\n\n28.7.4 Granger 因果检验\nGranger 因果检验的核心思想是通过回归分析判断一个变量的滞后值是否能够显著提高对另一个变量的预测能力。以下是 Granger 因果检验的数学公式及其在失业率 \\(u\\) 和通胀率 \\(e\\) 上的应用。\n\n28.7.4.1 1. 单变量回归模型\n首先，构建仅包含因变量自身滞后项的回归模型： \\[\nu_t = \\alpha_0 + \\sum_{i=1}^p \\alpha_i u_{t-i} + \\epsilon_t\n\\] 其中：\\(u_t\\) 表示当前的失业率；\\(u_{t-i}\\) 表示失业率的第 \\(i\\) 阶滞后值；\\(\\epsilon_t\\) 是误差项。\n\n\n28.7.4.2 2. 多变量回归模型\n然后，构建同时包含因变量和另一个变量滞后项的回归模型：\n\\[\nu_t = \\beta_0 + \\sum_{i=1}^p \\beta_i u_{t-i} + \\sum_{j=1}^q \\gamma_j e_{t-j} + \\eta_t\n\\]\n其中：\\(e_{t-j}\\) 表示通胀率的第 \\(j\\) 阶滞后值；\\(\\eta_t\\) 是误差项。\n\n\n28.7.4.3 3. 检验假设\n通过 F 检验比较上述两个模型的拟合优度，检验以下假设：\n\n原假设 \\(H_0\\)：\\(e_{t-j}\\) 的系数 \\(\\gamma_j = 0\\)，即通胀率的滞后值对失业率没有显著影响；\n备择假设 \\(H_1\\)：\\(e_{t-j}\\) 的系数 \\(\\gamma_j \\neq 0\\)，即通胀率的滞后值对失业率有显著影响。\n\n以下是基于失业率 \\(u\\) 和通胀率 \\(e\\) 的 Granger 因果检验代码示例：\n\nfrom statsmodels.tsa.stattools import grangercausalitytests\n\n# Granger 因果检验\n# 检验失业率 (u) 是否是通胀率 (e) 的 Granger 因，以及反向关系\nmax_lag = 14  # 最大滞后阶数\ngranger_test_result_u_to_e = grangercausalitytests(data[['Inflation Rate', 'Unemployment Rate']], max_lag, verbose=False)\ngranger_test_result_e_to_u = grangercausalitytests(data[['Unemployment Rate', 'Inflation Rate']], max_lag, verbose=False)\n\n# 提取 Granger 因果检验结果并汇总成表格\ndef extract_granger_results(granger_test_result):\n    granger_summary = []\n    for lag, result in granger_test_result.items():\n        f_stat = result[0]['ssr_ftest'][0]\n        p_value = result[0]['ssr_ftest'][1]\n        granger_summary.append({'Lag': lag, 'F-statistic': f_stat, 'p-value': p_value})\n    return pd.DataFrame(granger_summary)\n\n# 汇总结果\ngranger_summary_u_to_e = extract_granger_results(granger_test_result_u_to_e)\ngranger_summary_e_to_u = extract_granger_results(granger_test_result_e_to_u)\n\n# 显示结果表格\nprint(\"Granger Causality Test Summary (u -&gt; e):\")\nprint(granger_summary_u_to_e)\nprint(\"\\nGranger Causality Test Summary (e -&gt; u):\")\nprint(granger_summary_e_to_u)\n\n# 给出最终结论\nsignificant_lags_u_to_e = granger_summary_u_to_e[granger_summary_u_to_e['p-value'] &lt; 0.05]\nsignificant_lags_e_to_u = granger_summary_e_to_u[granger_summary_e_to_u['p-value'] &lt; 0.05]\n\nif not significant_lags_u_to_e.empty:\n    print(\"\\n结论：失业率 (u) 是通胀率 (e) 的 Granger 因，显著滞后阶数如下：\")\n    print(significant_lags_u_to_e)\nelse:\n    print(\"\\n结论：失业率 (u) 不是通胀率 (e) 的 Granger 因。\")\n\nif not significant_lags_e_to_u.empty:\n    print(\"\\n结论：通胀率 (e) 是失业率 (u) 的 Granger 因，显著滞后阶数如下：\")\n    print(significant_lags_e_to_u)\nelse:\n    print(\"\\n结论：通胀率 (e) 不是失业率 (u) 的 Granger 因。\")\n\nGranger Causality Test Summary (u -&gt; e):\n    Lag  F-statistic   p-value\n0     1     5.471488  0.019585\n1     2     0.647864  0.523449\n2     3     0.436910  0.726650\n3     4     0.610716  0.655024\n4     5     0.375923  0.865353\n5     6     0.495935  0.811649\n6     7     0.557345  0.790737\n7     8     0.514758  0.845838\n8     9     0.506870  0.870126\n9    10     0.705498  0.719822\n10   11     0.685244  0.753382\n11   12     0.614399  0.831097\n12   13     0.822097  0.636812\n13   14     0.747766  0.726348\n\nGranger Causality Test Summary (e -&gt; u):\n    Lag  F-statistic   p-value\n0     1     5.450546  0.019819\n1     2     6.978787  0.000992\n2     3     5.220735  0.001427\n3     4     3.865455  0.004070\n4     5     3.254972  0.006472\n5     6     2.676468  0.014124\n6     7     2.425017  0.018447\n7     8     2.141302  0.030061\n8     9     1.867208  0.053700\n9    10     1.654286  0.087485\n10   11     1.511173  0.122295\n11   12     1.386544  0.166729\n12   13     1.357478  0.174610\n13   14     1.389306  0.151910\n\n结论：失业率 (u) 是通胀率 (e) 的 Granger 因，显著滞后阶数如下：\n   Lag  F-statistic   p-value\n0    1     5.471488  0.019585\n\n结论：通胀率 (e) 是失业率 (u) 的 Granger 因，显著滞后阶数如下：\n   Lag  F-statistic   p-value\n0    1     5.450546  0.019819\n1    2     6.978787  0.000992\n2    3     5.220735  0.001427\n3    4     3.865455  0.004070\n4    5     3.254972  0.006472\n5    6     2.676468  0.014124\n6    7     2.425017  0.018447\n7    8     2.141302  0.030061",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  },
  {
    "objectID": "body/TS_FRED_US_unemploy_rate.html#脉冲响应分析",
    "href": "body/TS_FRED_US_unemploy_rate.html#脉冲响应分析",
    "title": "28  案例：美国失业率和通胀率关系分析",
    "section": "28.8 脉冲响应分析",
    "text": "28.8 脉冲响应分析\n\n28.8.1 什么是脉冲响应分析？\n脉冲响应分析（Impulse Response Analysis）是时间序列分析中的一种重要工具，用于研究系统对外部冲击的动态反应。具体来说，在向量自回归模型（VAR）中，脉冲响应分析可以帮助我们回答以下问题：\n\n当某个变量受到一个单位冲击时，其他变量会如何反应？\n这种反应会持续多长时间？\n反应的方向和强度如何？\n\n\n\n28.8.2 数学定义\n假设我们有一个 \\(\\text{VAR}(p)\\) 模型：\n\\[\nY_t = A_1 Y_{t-1} + A_2 Y_{t-2} + \\dots + A_p Y_{t-p} + \\epsilon_t\n\\]\n其中：\n\n\\(Y_t\\) 是包含多个变量的向量；\n\\(A_i\\) 是系数矩阵；\n\\(\\epsilon_t\\) 是误差项。\n\n脉冲响应函数（Impulse Response Function, IRF）描述了 \\(Y_t\\) 中某个变量对 \\(\\epsilon_t\\) 中某个分量的单位冲击的动态反应。\n\n\n28.8.3 分析步骤\n\n拟合 VAR 模型：首先需要对时间序列数据拟合一个 VAR 模型。\n计算脉冲响应函数：基于拟合的 VAR 模型，计算各变量对冲击的响应。\n绘制脉冲响应图：将响应结果可视化，便于直观理解。\n\n\n\n28.8.4 示例：失业率与通胀率的脉冲响应分析\n以下是基于失业率和通胀率的脉冲响应分析步骤：\n\n拟合 VAR 模型：我们已经拟合了一个 VAR(2) 模型。\n计算脉冲响应函数：使用 statsmodels 提供的工具计算脉冲响应。\n绘制脉冲响应图：展示失业率和通胀率对冲击的动态反应。\n\n以下是脉冲响应分析的代码示例：\n\nfrom statsmodels.tsa.api import VAR\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# 准备数据\ndata = pd.concat([df_unemp['UNRATE'], df_CPI['Inflation Rate']], axis=1).dropna()\ndata.columns = ['U', 'E']\n\n# 拟合 VAR(2) 模型\nmodel = VAR(data)\nvar_model_2 = model.fit(2)\n\n# 计算正交化脉冲响应\nirf = var_model_2.irf(10)\n\n# 绘图（缩小图形尺寸）\nirf.plot(orth=True, figsize=(6, 4))\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n上面的图形展示了失业率和通货膨胀率的脉冲响应分析结果，具体解读如下：\n\n失业率对自身冲击的响应：\n\n失业率在受到自身冲击后，短期内会出现显著的正向反应，随后逐渐回归到长期均衡水平。\n这种现象表明失业率具有一定的惯性效应，即当前的失业率水平会受到过去水平的显著影响。\n\n通货膨胀率对自身冲击的响应：\n\n通货膨胀率在受到自身冲击后，也会出现短期的正向反应，但其回归速度较快。\n这表明通货膨胀率的波动性较高，但其长期趋势相对稳定。\n\n失业率对通货膨胀率冲击的响应：\n\n失业率在受到通货膨胀率冲击后，可能会出现短暂的负向反应，随后逐渐回归均衡。\n这种负相关性可能与菲利普斯曲线的理论一致，即在短期内失业率和通货膨胀率之间存在一定的替代关系。\n\n通货膨胀率对失业率冲击的响应：\n\n通货膨胀率在受到失业率冲击后，反应较为温和，且回归速度较快。\n这表明失业率的变化对通货膨胀率的长期影响较小，但可能会在短期内引发一定的波动。\n\n\n\n\n28.8.5 总结\n通过脉冲响应分析可以看出，失业率和通货膨胀率之间存在一定的动态关系，但这种关系在短期内更为显著，长期影响则趋于平稳。这为进一步的经济建模和政策分析提供了重要的参考依据。",
    "crumbs": [
      "**时间序列分析**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>案例：美国失业率和通胀率关系分析</span>"
    ]
  }
]